{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d05ab8a",
   "metadata": {},
   "source": [
    "# Load thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd15c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from tabulate import tabulate\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62625b21",
   "metadata": {},
   "source": [
    "# Chuẩn bị dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91ce7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = \"VNM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc88cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = web.DataReader(stock_name,data_source=\"yahoo\",start=\"01/01/2005\",end=\"01/01/2019\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c874f93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2361.000000</td>\n",
       "      <td>2361.000000</td>\n",
       "      <td>2361.000000</td>\n",
       "      <td>2361.000000</td>\n",
       "      <td>2.361000e+03</td>\n",
       "      <td>2361.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.192325</td>\n",
       "      <td>18.864125</td>\n",
       "      <td>19.041749</td>\n",
       "      <td>19.023935</td>\n",
       "      <td>2.589617e+05</td>\n",
       "      <td>16.706554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.093307</td>\n",
       "      <td>3.978572</td>\n",
       "      <td>4.043910</td>\n",
       "      <td>4.033770</td>\n",
       "      <td>2.369351e+05</td>\n",
       "      <td>2.811671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.630000</td>\n",
       "      <td>12.340000</td>\n",
       "      <td>12.580000</td>\n",
       "      <td>12.550000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>11.930043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.860000</td>\n",
       "      <td>15.560000</td>\n",
       "      <td>15.680000</td>\n",
       "      <td>15.680000</td>\n",
       "      <td>1.107000e+05</td>\n",
       "      <td>14.311843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.570000</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>18.430000</td>\n",
       "      <td>18.430000</td>\n",
       "      <td>1.857000e+05</td>\n",
       "      <td>16.286385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.450001</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>21.280001</td>\n",
       "      <td>21.290001</td>\n",
       "      <td>3.227000e+05</td>\n",
       "      <td>18.809763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32.200001</td>\n",
       "      <td>31.549999</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.070000</td>\n",
       "      <td>2.509500e+06</td>\n",
       "      <td>26.154686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              High          Low         Open        Close        Volume  \\\n",
       "count  2361.000000  2361.000000  2361.000000  2361.000000  2.361000e+03   \n",
       "mean     19.192325    18.864125    19.041749    19.023935  2.589617e+05   \n",
       "std       4.093307     3.978572     4.043910     4.033770  2.369351e+05   \n",
       "min      12.630000    12.340000    12.580000    12.550000  0.000000e+00   \n",
       "25%      15.860000    15.560000    15.680000    15.680000  1.107000e+05   \n",
       "50%      18.570000    18.250000    18.430000    18.430000  1.857000e+05   \n",
       "75%      21.450001    21.080000    21.280001    21.290001  3.227000e+05   \n",
       "max      32.200001    31.549999    32.000000    32.070000  2.509500e+06   \n",
       "\n",
       "         Adj Close  \n",
       "count  2361.000000  \n",
       "mean     16.706554  \n",
       "std       2.811671  \n",
       "min      11.930043  \n",
       "25%      14.311843  \n",
       "50%      16.286385  \n",
       "75%      18.809763  \n",
       "max      26.154686  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27453666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2361, 1)                 Close\n",
      "Date                 \n",
      "2009-08-14  26.020000\n",
      "2009-08-17  25.230000\n",
      "2009-08-18  25.750000\n",
      "2009-08-19  26.129999\n",
      "2009-08-20  26.969999\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = raw_data.dropna()\n",
    "df = df[['Close']]\n",
    "first_price = df.Close.iloc[0]\n",
    "print(df.shape, df.head())\n",
    "\n",
    "df.Close.plot()\n",
    "def create_ds(ds, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(ds)-look_back-1): \n",
    "        data = ds[i:(i+look_back), 0]      \n",
    "        dataX.append(data)\n",
    "        dataY.append(ds[i + look_back, 0]) \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "ds = df.values\n",
    "ds = ds.astype('float32')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "ds = scaler.fit_transform(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90a229de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Chia tập train và tập test theo ty lệ 0.85, 0.15\n",
    "# train_size = int(len(ds) * 0.85)\n",
    "# test_size = len(ds) - train_size\n",
    "# train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560617e4",
   "metadata": {},
   "source": [
    "# outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6323037",
   "metadata": {},
   "source": [
    "#### 1:\n",
    "#### Đầu vào: train, test, look_back, opt, epochs, batch_size, validation_split\n",
    "#### Đầu ra: Trained model\n",
    "#### 2:\n",
    "#### Đầu vào: 4 trained models\n",
    "#### Đầu ra: 4 plots + bảng so sánh độ chính xác"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ea794",
   "metadata": {},
   "source": [
    "# Xây dựng models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f28081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_data(train, test, look_back):\n",
    "    trainX, trainY = create_ds(train, look_back)\n",
    "    testX, testY = create_ds(test, look_back)\n",
    "\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21a7835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c4a1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_nodes = math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b7e608",
   "metadata": {},
   "source": [
    "## FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2713269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ffnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_ffnn = Sequential()\n",
    "    model_ffnn.add(Dense(hidden_nodes, input_shape = (trainX.shape[1],trainX.shape[2]), activation = 'relu', kernel_initializer='uniform'))\n",
    "#     model_ffnn.add(Dropout(0.4))\n",
    "#     model_ffnn.add(Dense(400, activation = 'relu', kernel_initializer='uniform' ))\n",
    "#     model_ffnn.add(Dropout(0.3))\n",
    "#     model_ffnn.add(Dense(150, activation = 'relu' ))\n",
    "#     model_ffnn.add(Dropout(0.3))\n",
    "#     model_ffnn.add(Dense(100, activation = 'hard_sigmoid' ))\n",
    "#     model_ffnn.add(Dropout(0.2))\n",
    "#     model_ffnn.add(Dense(50, activation = 'relu' ))\n",
    "#     model_ffnn.add(Dropout(0.1))\n",
    "#     model_ffnn.add(Dense(10, activation = 'relu' ))\n",
    "    model_ffnn.add(Flatten())\n",
    "    model_ffnn.add(Dense(1, activation = 'relu'))\n",
    "    # train created model\n",
    "    model_ffnn.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_ffnn.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_ffnn.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_ffnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb585959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6feb7f00",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b056c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(SimpleRNN(units = hidden_nodes, activation = \"tanh\", return_sequences = True, input_shape = (look_back,1)))\n",
    "#     model_rnn.add(Dropout(0.3))\n",
    "#     model_rnn.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True))\n",
    "#     model_rnn.add(Dropout(0.2))\n",
    "#     model_rnn.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True))\n",
    "#     model_rnn.add(Dropout(0.1))\n",
    "#     model_rnn.add(SimpleRNN(units = 50))\n",
    "    model_rnn.add(Flatten())\n",
    "    model_rnn.add(Dense(units = 1))\n",
    "    # train created model\n",
    "    model_rnn.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_rnn.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_rnn.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdadcde",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c306e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(LSTM(hidden_nodes, activation = 'tanh', input_shape=(look_back,1),return_sequences=True))\n",
    "    model_lstm.add(Flatten())\n",
    "    model_lstm.add(Dense(1, activation = 'relu'))\n",
    "    # train created model\n",
    "    model_lstm.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_lstm.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_lstm.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b222798",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fbf25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split):\n",
    "    # create model\n",
    "    hidden_nodes = int(math.sqrt(len(trainX) * 3) + 2 * math.sqrt(len(trainX) / 3))\n",
    "    model_gru = Sequential()\n",
    "    model_gru.add(GRU(hidden_nodes, activation='tanh', recurrent_activation='sigmoid', input_shape=(look_back,1), return_sequences=True)) \n",
    "    model_gru.add(Flatten())\n",
    "    model_gru.add(Dense(1, activation = 'relu'))\n",
    "    # train created model\n",
    "    model_gru.compile(optimizer= opt, loss = \"mean_squared_error\")\n",
    "    start = time.time()\n",
    "    history = model_gru.fit(trainX, trainY, epochs = epochs , batch_size= batch_size, shuffle=True ,validation_split = validation_split)\n",
    "    print('Thời gian huấn luyện: ', time.time() - start)\n",
    "    model_gru.summary()\n",
    "    delta = time.time() - start\n",
    "    return delta, model_gru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0acfa5",
   "metadata": {},
   "source": [
    "# Trực quan hóa, so sánh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb06f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def calculate_performance(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    return round(mse, 3), round(mae, 3), round(mape, 3), round(rmse, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a2452ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accuracy(trained_model, scaler, trainX, trainY, testX, testY):\n",
    "    trainPredict = trained_model.predict(trainX)\n",
    "    testPredict = trained_model.predict(testX)\n",
    "\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "\n",
    "    mse, mae, mape, rmse = calculate_performance(trainY[0],trainPredict[:, 0])\n",
    "    return mse, mae, mape, rmse, trainPredict, testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9eefe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(ds, trainPredict, testPredict, scaler, look_back, model_name, stock_name):\n",
    "    trainPredictPlot = np.empty_like(ds)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "    testPredictPlot = np.empty_like(ds)\n",
    "    testPredictPlot[:, :] = np.nan\n",
    "    testPredictPlot[len(trainPredict)+(look_back*2)+1:len(ds)-1, :] = testPredict\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(13,7), dpi=110)\n",
    "    plt.grid(color='grey', linestyle='dashed')\n",
    "    plt.xlabel(\"{0} result\".format(model_name))\n",
    "    plt.ylabel('{0}'.format(stock_name),rotation=90)\n",
    "    plt.plot(scaler.inverse_transform(ds), label = 'Actual Closing Prices', linewidth = 1.2, color = 'c')\n",
    "    plt.plot(trainPredictPlot, label = 'A.I. Train Data Price Predictions_After fit', linewidth = 0.9, color = 'k')\n",
    "    plt.plot(testPredictPlot, label = 'A.I. Test Data Price Predictions', linewidth = 0.9, color = 'r')\n",
    "    legend = plt.legend(fontsize = 12,frameon = True)\n",
    "    legend.get_frame().set_edgecolor('b')\n",
    "    legend.get_frame().set_linewidth(0.4)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116dbf09",
   "metadata": {},
   "source": [
    "# Thực nghiệm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6f7494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "import itertools\n",
    "def get_combinations(parameters):\n",
    "    return list(itertools.product(*parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d74ce315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 1s 5ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Thời gian huấn luyện:  4.184906959533691\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10, 108)           216       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,297\n",
      "Trainable params: 1,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 0.0952 - val_loss: 0.0098\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 9.3836e-04\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 8.6306e-04\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 7.7891e-04\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 9.2542e-04\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 8.4473e-04\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 6.8341e-04\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 7.1775e-04\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 6.6222e-04\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 8.1348e-04\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 4.9604e-04\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 5.6687e-04\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 5.8600e-04\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 4.6434e-04\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 6.2727e-04\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 3.8426e-04\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 6.8532e-04\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 4.2284e-04\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 3.5078e-04\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 3.1316e-04\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 3.6108e-04\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.9412e-04\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.0265e-04\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 3.4893e-04\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 3.4406e-04\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.0585e-04\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.2751e-04\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 2.8624e-04\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 2.9618e-04\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 9.9902e-04 - val_loss: 2.7087e-04\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 2.7006e-04\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 2.8220e-04\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 9.6051e-04 - val_loss: 3.1454e-04\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 9.5684e-04 - val_loss: 4.2813e-04\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 9.6690e-04 - val_loss: 2.4926e-04\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 9.4085e-04 - val_loss: 5.1715e-04\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 9.8478e-04 - val_loss: 2.4757e-04\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 9.1328e-04 - val_loss: 2.3470e-04\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 9.1814e-04 - val_loss: 2.4752e-04\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 9.1317e-04 - val_loss: 2.3275e-04\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 9.0205e-04 - val_loss: 3.4025e-04\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 8.8266e-04 - val_loss: 2.8862e-04\n",
      "Thời gian huấn luyện:  7.078172445297241\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 10, 108)           11880     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,961\n",
      "Trainable params: 12,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "40/40 [==============================] - 2s 16ms/step - loss: 0.0268 - val_loss: 9.3839e-04\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 8.4582e-04\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 9.9791e-04\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 8.2113e-04\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 8.4285e-04\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 7.8063e-04\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 7.1101e-04\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 7.7257e-04\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 8.1656e-04\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 9.9976e-04\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 7.7218e-04\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 7.1276e-04\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 7.8349e-04\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 6.1809e-04\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 7.1302e-04\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 8.2107e-04\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 6.7304e-04\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 6.7849e-04\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 7.2094e-04\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 6.2781e-04\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 7.0293e-04\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 6.0545e-04\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 8.5441e-04\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 6.4594e-04\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 7.9568e-04\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 6.2018e-04\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.6390e-04\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 5.3884e-04\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 5.9694e-04\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.1200e-04\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 6.0480e-04\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 5.0807e-04\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 4.7855e-04\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.0558e-04\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 5.9801e-04\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.5363e-04\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.6337e-04\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 4.6477e-04\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 5.6521e-04\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 4.3154e-04\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 4.7794e-04\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 4.3771e-04\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 4.0615e-04\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.2608e-04\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 3.7098e-04\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 4.8789e-04\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 4.0891e-04\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 4.8517e-04\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 3.5563e-04\n",
      "Thời gian huấn luyện:  16.401774644851685\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 108)           47520     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,601\n",
      "Trainable params: 48,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "40/40 [==============================] - 2s 18ms/step - loss: 0.0297 - val_loss: 6.7056e-04\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 9.4464e-04\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 7.9708e-04\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 7.6211e-04\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 7.8399e-04\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 7.7445e-04\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.5119e-04\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.4123e-04\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 5.4806e-04\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 6.4168e-04\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 5.9124e-04\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 6.0426e-04\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 5.0136e-04\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 7.9789e-04\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.4153e-04\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.1536e-04\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 4.7167e-04\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 6.3937e-04\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.0934e-04\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 6.1515e-04\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.0798e-04\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 4.5548e-04\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 4.6929e-04\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.3645e-04\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 4.8918e-04\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 4.8061e-04\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.4966e-04\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 3.7779e-04\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 5.3173e-04\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 4.0263e-04\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 4.4407e-04\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 3.9697e-04\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.2179e-04\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 3.7099e-04\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 3.3555e-04\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 3.4181e-04\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 3.5847e-04\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 4.1720e-04\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 3.1138e-04\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 3.5397e-04\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 9.7644e-04 - val_loss: 3.3112e-04\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 9.6635e-04 - val_loss: 3.2143e-04\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 9.4484e-04 - val_loss: 3.0236e-04\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 9.3310e-04 - val_loss: 3.3614e-04\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 9.1560e-04 - val_loss: 4.4847e-04\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 9.2394e-04 - val_loss: 2.6795e-04\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 9.1591e-04 - val_loss: 4.4845e-04\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 8.9384e-04 - val_loss: 3.3872e-04\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 8.8374e-04 - val_loss: 2.8797e-04\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 8.7656e-04 - val_loss: 2.9609e-04\n",
      "Thời gian huấn luyện:  16.03311252593994\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 10, 108)           35964     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,045\n",
      "Trainable params: 37,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "44/44 [==============================] - 0s 912us/step\n",
      "30/30 [==============================] - 0s 974us/step\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "44/44 [==============================] - 1s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 1s 6ms/step - loss: 0.1127 - val_loss: 0.0024\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0028\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0024\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 9.1121e-04\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 7.8167e-04\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 7.9918e-04\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 6.8408e-04\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 7.4895e-04\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 6.0320e-04\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 6.1972e-04\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 5.8972e-04\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 5.9360e-04\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 5.7280e-04\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 5.6982e-04\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.5431e-04\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.5957e-04\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.4775e-04\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.5102e-04\n",
      "Epoch 25/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.4685e-04\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.4142e-04\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.3579e-04\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.4861e-04\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.3701e-04\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.3747e-04\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.2184e-04\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.2100e-04\n",
      "Epoch 33/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.1635e-04\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.2881e-04\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.1223e-04\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.2183e-04\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.3508e-04\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.1321e-04\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.0667e-04\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.1505e-04\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 4.9717e-04\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 4.9446e-04\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 5.2266e-04\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 4.8150e-04\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.9798e-04\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.7433e-04\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.8874e-04\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.9163e-04\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.1948e-04\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.7179e-04\n",
      "Thời gian huấn luyện:  4.7999536991119385\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 10, 108)           216       \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,297\n",
      "Trainable params: 1,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 0.0269 - val_loss: 0.0013\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 7.9253e-04\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 6.8373e-04\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 6.7126e-04\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 5.5990e-04\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 5.1284e-04\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 4.6915e-04\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 5.3230e-04\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 4.2913e-04\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 5.8330e-04\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 4.1460e-04\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 4.6421e-04\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 3.7930e-04\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.0931e-04\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 4.3384e-04\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.1589e-04\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.1219e-04\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.0362e-04\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.9512e-04\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 3.0312e-04\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.9029e-04\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 2.8528e-04\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 3.4784e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 3.3190e-04\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.4524e-04\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.8258e-04 - val_loss: 2.8989e-04\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.4979e-04 - val_loss: 2.7074e-04\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.5697e-04 - val_loss: 2.7571e-04\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.4095e-04 - val_loss: 2.6629e-04\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.5029e-04 - val_loss: 2.9259e-04\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.7319e-04 - val_loss: 2.8460e-04\n",
      "Epoch 33/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.2012e-04 - val_loss: 3.3110e-04\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.2731e-04 - val_loss: 2.6060e-04\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.3326e-04 - val_loss: 2.7708e-04\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 8.7460e-04 - val_loss: 2.8914e-04\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.8814e-04 - val_loss: 2.5078e-04\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.7566e-04 - val_loss: 2.4953e-04\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.4870e-04 - val_loss: 3.1424e-04\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.7107e-04 - val_loss: 3.5284e-04\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.9870e-04 - val_loss: 2.8430e-04\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.4792e-04 - val_loss: 2.8966e-04\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 8.7445e-04 - val_loss: 2.5233e-04\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.6024e-04 - val_loss: 3.7611e-04\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.4816e-04 - val_loss: 2.5739e-04\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.2519e-04 - val_loss: 2.4219e-04\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.1131e-04 - val_loss: 3.3146e-04\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.2095e-04 - val_loss: 2.3107e-04\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.0231e-04 - val_loss: 2.3037e-04\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.7715e-04 - val_loss: 2.3282e-04\n",
      "Thời gian huấn luyện:  8.17699384689331\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (None, 10, 108)           11880     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,961\n",
      "Trainable params: 12,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 5s 27ms/step - loss: 0.1254 - val_loss: 0.0046\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 9.5155e-04\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 8.4847e-04\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 8.4075e-04\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 8.4942e-04\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 7.9983e-04\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 7.9691e-04\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 8.1893e-04\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 7.9991e-04\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 7.8090e-04\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 7.6927e-04\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 7.5816e-04\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 8.1916e-04\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 7.7077e-04\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 7.4353e-04\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 7.5068e-04\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 7.4129e-04\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 7.2924e-04\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 7.7169e-04\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 7.1543e-04\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 7.2489e-04\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 7.0171e-04\n",
      "Epoch 25/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 7.1558e-04\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 6.8484e-04\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 6.9478e-04\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 6.6932e-04\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 6.6718e-04\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 6.6698e-04\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 7.0937e-04\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 6.4029e-04\n",
      "Epoch 33/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 6.3113e-04\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 7.3911e-04\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 6.2405e-04\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 6.2628e-04\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 6.0627e-04\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 6.0394e-04\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 6.0589e-04\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.1000e-04\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 5.9700e-04\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 5.7701e-04\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 5.5671e-04\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.4657e-04\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 6.2376e-04\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 5.2983e-04\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.2983e-04\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 5.2174e-04\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.1959e-04\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 5.1484e-04\n",
      "Thời gian huấn luyện:  21.443925142288208\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 10, 108)           47520     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,601\n",
      "Trainable params: 48,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 3s 29ms/step - loss: 0.0531 - val_loss: 0.0022\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 7.7537e-04\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 6.9572e-04\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 6.5922e-04\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.6083e-04\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 6.8864e-04\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.2016e-04\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 5.9287e-04\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 5.7148e-04\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.0475e-04\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.0265e-04\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 6.0855e-04\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.6017e-04\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 5.4476e-04\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.2924e-04\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.1148e-04\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 5.6659e-04\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 4.9602e-04\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 4.9542e-04\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 4.8258e-04\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 5.2209e-04\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.0015 - val_loss: 4.9314e-04\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 4.7934e-04\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 4.4876e-04\n",
      "Epoch 25/50\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 4.4222e-04\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.7991e-04\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.0013 - val_loss: 4.6546e-04\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 4.1773e-04\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.2640e-04\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.7954e-04\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.1450e-04\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.0302e-04\n",
      "Epoch 33/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.9134e-04\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 3.9829e-04\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 3.7288e-04\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 3.6549e-04\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.5722e-04\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.5455e-04\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.1211e-04\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.4615e-04\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.3396e-04\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 3.4926e-04\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.8245e-04\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.2703e-04\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 3.3388e-04\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 3.4765e-04\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.3145e-04\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.9234e-04 - val_loss: 3.1148e-04\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 9.8263e-04 - val_loss: 2.9493e-04\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 9.7984e-04 - val_loss: 2.9885e-04\n",
      "Thời gian huấn luyện:  20.502046585083008\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 10, 108)           35964     \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,045\n",
      "Trainable params: 37,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "44/44 [==============================] - 0s 841us/step\n",
      "30/30 [==============================] - 0s 971us/step\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "44/44 [==============================] - 1s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "44/44 [==============================] - 1s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 1s 7ms/step - loss: 0.1141 - val_loss: 0.0023\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0035\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0025\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0019\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0017\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 9.4116e-04\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 8.5785e-04\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 8.5325e-04\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 7.1510e-04\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 7.0939e-04\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 6.9181e-04\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 6.2979e-04\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 6.4878e-04\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 6.2228e-04\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 6.1325e-04\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 6.2361e-04\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.9264e-04\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.8322e-04\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.8499e-04\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.8875e-04\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.6992e-04\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 5.8961e-04\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 5.9118e-04\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.6265e-04\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 5.7942e-04\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.7124e-04\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.5783e-04\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.5561e-04\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.5828e-04\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 6.3020e-04\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.4846e-04\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.7978e-04\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.4753e-04\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.4702e-04\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.3428e-04\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.3243e-04\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.5366e-04\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.3259e-04\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 6.0422e-04\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.3534e-04\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.2252e-04\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.1565e-04\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.4768e-04\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.0726e-04\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.1417e-04\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.3602e-04\n",
      "Thời gian huấn luyện:  4.86015772819519\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 10, 108)           216       \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,297\n",
      "Trainable params: 1,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0392 - val_loss: 0.0016\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 9.0573e-04\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 7.4211e-04\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 7.9049e-04\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 9.5245e-04\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 6.1745e-04\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 9.6281e-04\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 5.6416e-04\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 6.5866e-04\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 5.1993e-04\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 5.4657e-04\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 4.9263e-04\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 5.7351e-04\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 4.6262e-04\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 4.3507e-04\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 4.7350e-04\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 4.0829e-04\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.2414e-04\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 3.9207e-04\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.3588e-04\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.0133e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.4406e-04\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 4.9107e-04\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.0145e-04\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.1545e-04\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.6269e-04\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.7381e-04\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.9685e-04\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.6885e-04\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.3541e-04\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.6747e-04\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.9055e-04\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.3659e-04\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.2839e-04\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 4.6159e-04\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 4.5174e-04\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.2040e-04\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.8601e-04 - val_loss: 3.7450e-04\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.1134e-04\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.6422e-04 - val_loss: 3.1983e-04\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.8858e-04 - val_loss: 6.2679e-04\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.1959e-04\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.9515e-04 - val_loss: 3.1523e-04\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.7076e-04 - val_loss: 3.4591e-04\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 8.5124e-04\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.6285e-04 - val_loss: 2.9873e-04\n",
      "Thời gian huấn luyện:  7.922153949737549\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 10, 108)           11880     \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,961\n",
      "Trainable params: 12,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 3s 20ms/step - loss: 0.0380 - val_loss: 0.0016\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 9.1013e-04\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 8.7707e-04\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 8.9470e-04\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 8.8742e-04\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 8.3492e-04\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 8.5031e-04\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 9.0640e-04\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 8.1417e-04\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 8.6642e-04\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 9.0417e-04\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 7.9722e-04\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 8.1731e-04\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 7.8946e-04\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 8.6046e-04\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 7.8094e-04\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 7.9186e-04\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 7.8903e-04\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 7.5703e-04\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 7.6594e-04\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 8.0982e-04\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 7.3388e-04\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 7.3516e-04\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 7.3891e-04\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 8.0660e-04\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 7.2819e-04\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 7.5824e-04\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 6.9023e-04\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 6.9901e-04\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 6.7345e-04\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 6.7017e-04\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 7.2389e-04\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 6.6497e-04\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 7.1110e-04\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.4035e-04\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 6.5701e-04\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 6.9884e-04\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 6.1874e-04\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 6.2705e-04\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 7.4194e-04\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 5.9261e-04\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 6.4569e-04\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 6.1970e-04\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 5.7659e-04\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 6.3502e-04\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 5.5905e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 6.1782e-04\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 5.5574e-04\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 6.6366e-04\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.3264e-04\n",
      "Thời gian huấn luyện:  18.87940526008606\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 10, 108)           47520     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,601\n",
      "Trainable params: 48,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 3s 23ms/step - loss: 0.0343 - val_loss: 0.0018\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 7.7076e-04\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 7.6846e-04\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 6.9687e-04\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 6.9420e-04\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 6.7933e-04\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 7.0731e-04\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.5651e-04\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.7887e-04\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 6.4092e-04\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 6.3106e-04\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 6.6662e-04\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 6.6628e-04\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 6.0746e-04\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 5.9086e-04\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 6.0915e-04\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 5.6026e-04\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 5.5065e-04\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.6448e-04\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 5.6490e-04\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.5058e-04\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.4171e-04\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.2029e-04\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.1721e-04\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.9517e-04\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.1499e-04\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.7987e-04\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.7913e-04\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.9127e-04\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 5.0119e-04\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 5.1757e-04\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 5.0219e-04\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.9106e-04\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.4147e-04\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.6010e-04\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.1550e-04\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.2081e-04\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.9285e-04\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.9808e-04\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.9301e-04\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.2551e-04\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.9326e-04\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.7976e-04\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.8264e-04\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 3.5667e-04\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 3.4939e-04\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 3.6573e-04\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 3.6259e-04\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.8562e-04 - val_loss: 3.6102e-04\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.7812e-04 - val_loss: 3.3410e-04\n",
      "Thời gian huấn luyện:  19.010507822036743\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_2 (GRU)                 (None, 10, 108)           35964     \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,045\n",
      "Trainable params: 37,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "44/44 [==============================] - 0s 801us/step\n",
      "30/30 [==============================] - 0s 890us/step\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "44/44 [==============================] - 1s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "44/44 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - 1s 7ms/step - loss: 0.0968 - val_loss: 0.0059\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0036\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0034\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 8.1836e-04\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 7.9029e-04\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 7.1283e-04\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 6.3940e-04\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 6.3375e-04\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.8478e-04\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 6.4089e-04\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.9837e-04\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 5.3369e-04\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.3797e-04\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.4623e-04\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.4692e-04\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.6701e-04\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 4.9833e-04\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.2117e-04\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.0680e-04\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 5.6704e-04\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.1554e-04\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.0160e-04\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.8759e-04\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.8489e-04\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.4339e-04\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.0445e-04\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.0489e-04\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.1210e-04\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 5.4070e-04\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.2794e-04\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.8041e-04\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.6429e-04\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.0374e-04\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.7239e-04\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.3640e-04\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.5737e-04\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.6887e-04\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 4.4635e-04\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.4774e-04\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.0932e-04\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 5.1980e-04\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.6293e-04\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.2410e-04\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.3499e-04\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.3064e-04\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.8325e-04\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.5023e-04\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.3000e-04\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.0211e-04\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.7700e-04\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.1137e-04\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.7916e-04\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.9102e-04\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.5673e-04\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.4999e-04\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.7148e-04\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.4851e-04\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.7946e-04\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.6245e-04\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 4.2060e-04\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 4.0292e-04\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.6168e-04\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.9305e-04\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.6929e-04\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.9306e-04 - val_loss: 3.2440e-04\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.9379e-04 - val_loss: 2.9189e-04\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.8479e-04 - val_loss: 3.2996e-04\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.6177e-04 - val_loss: 3.5458e-04\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.5604e-04 - val_loss: 3.1132e-04\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.5687e-04 - val_loss: 3.6709e-04\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.3408e-04 - val_loss: 3.0908e-04\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.3093e-04 - val_loss: 3.3601e-04\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.2451e-04 - val_loss: 2.7363e-04\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.0660e-04 - val_loss: 3.4228e-04\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.1059e-04 - val_loss: 3.0136e-04\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.9930e-04 - val_loss: 3.2316e-04\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 8.8461e-04 - val_loss: 3.2144e-04\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.7605e-04 - val_loss: 3.1660e-04\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.6761e-04 - val_loss: 3.1226e-04\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.5402e-04 - val_loss: 3.3895e-04\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.5235e-04 - val_loss: 2.9043e-04\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.4226e-04 - val_loss: 3.0600e-04\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.3175e-04 - val_loss: 2.9370e-04\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.3052e-04 - val_loss: 2.9857e-04\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.1733e-04 - val_loss: 3.5505e-04\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.1564e-04 - val_loss: 3.1420e-04\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.0728e-04 - val_loss: 3.1385e-04\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.9524e-04 - val_loss: 2.4221e-04\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.9165e-04 - val_loss: 2.7394e-04\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.8123e-04 - val_loss: 3.6875e-04\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.8472e-04 - val_loss: 2.6012e-04\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.6998e-04 - val_loss: 2.5810e-04\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.6699e-04 - val_loss: 2.7814e-04\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.6379e-04 - val_loss: 2.4397e-04\n",
      "Thời gian huấn luyện:  9.609101057052612\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 10, 108)           216       \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,297\n",
      "Trainable params: 1,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - 2s 10ms/step - loss: 0.0368 - val_loss: 0.0011\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 6.4804e-04\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 8.0042e-04\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 7.2041e-04\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 5.9088e-04\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 5.3908e-04\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 4.9077e-04\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 3.9954e-04\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 4.5244e-04\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 4.7917e-04\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 5.5760e-04\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 5.5468e-04\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 5.9986e-04\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.9548e-04\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.9512e-04\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 3.8158e-04\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.5618e-04\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.8677e-04\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.0850e-04\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.1008e-04\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.6313e-04\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.7860e-04\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.9933e-04\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.9570e-04\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.7048e-04\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.9171e-04\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.8430e-04 - val_loss: 3.8778e-04\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.6603e-04 - val_loss: 3.8707e-04\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.9504e-04 - val_loss: 4.4728e-04\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.6590e-04 - val_loss: 4.8277e-04\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.5698e-04 - val_loss: 4.1635e-04\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.4076e-04 - val_loss: 3.3137e-04\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 9.1688e-04 - val_loss: 3.5437e-04\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.2348e-04 - val_loss: 2.7295e-04\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.0933e-04 - val_loss: 3.9716e-04\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.0418e-04 - val_loss: 4.6716e-04\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.1054e-04 - val_loss: 2.4174e-04\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.9381e-04 - val_loss: 3.9453e-04\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.3607e-04 - val_loss: 2.4877e-04\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.7154e-04 - val_loss: 3.0377e-04\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.8222e-04 - val_loss: 6.2531e-04\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.4685e-04 - val_loss: 2.4628e-04\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.0194e-04 - val_loss: 2.2749e-04\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.5102e-04 - val_loss: 2.6614e-04\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.5940e-04 - val_loss: 2.2598e-04\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.4224e-04 - val_loss: 2.3747e-04\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.8137e-04 - val_loss: 2.4565e-04\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step - loss: 9.2518e-04 - val_loss: 2.4476e-04\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.4676e-04 - val_loss: 3.1410e-04\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 8.1184e-04 - val_loss: 3.5483e-04\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.3129e-04 - val_loss: 5.0754e-04\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.9765e-04 - val_loss: 2.3879e-04\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.8933e-04 - val_loss: 2.5325e-04\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.8683e-04 - val_loss: 2.3887e-04\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 8.0291e-04 - val_loss: 2.9580e-04\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 8.5304e-04 - val_loss: 4.1576e-04\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.7161e-04 - val_loss: 2.0984e-04\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 8.6243e-04 - val_loss: 2.2718e-04\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.6636e-04 - val_loss: 2.0819e-04\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.6196e-04 - val_loss: 4.0644e-04\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 8.1386e-04 - val_loss: 3.5520e-04\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.5511e-04 - val_loss: 2.0983e-04\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.4602e-04 - val_loss: 3.8436e-04\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.5348e-04 - val_loss: 4.1844e-04\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.6649e-04 - val_loss: 2.0838e-04\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.4749e-04 - val_loss: 2.8455e-04\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.4868e-04 - val_loss: 2.0044e-04\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.2455e-04 - val_loss: 2.8561e-04\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.2726e-04 - val_loss: 2.4068e-04\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.5088e-04 - val_loss: 2.3111e-04\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.2871e-04 - val_loss: 2.0268e-04\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.2360e-04 - val_loss: 5.9949e-04\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.2138e-04 - val_loss: 1.9755e-04\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.1216e-04 - val_loss: 2.1594e-04\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.1579e-04 - val_loss: 1.9617e-04\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.2319e-04 - val_loss: 1.9357e-04\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.0085e-04 - val_loss: 2.8871e-04\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.8290e-04 - val_loss: 1.9122e-04\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.8420e-04 - val_loss: 2.1331e-04\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.1693e-04 - val_loss: 2.0045e-04\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.1342e-04 - val_loss: 3.0884e-04\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.0139e-04 - val_loss: 4.9365e-04\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.6466e-04 - val_loss: 2.0685e-04\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.7214e-04 - val_loss: 2.0905e-04\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.9721e-04 - val_loss: 2.7998e-04\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.5503e-04 - val_loss: 2.9478e-04\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.5693e-04 - val_loss: 1.8924e-04\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.5291e-04 - val_loss: 2.8304e-04\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.6235e-04 - val_loss: 1.8548e-04\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.6351e-04 - val_loss: 1.9960e-04\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.3962e-04 - val_loss: 3.5990e-04\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.7162e-04 - val_loss: 1.8067e-04\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.3567e-04 - val_loss: 2.6345e-04\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.5679e-04 - val_loss: 3.6955e-04\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.3586e-04 - val_loss: 5.3832e-04\n",
      "Thời gian huấn luyện:  15.954101800918579\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_3 (SimpleRNN)    (None, 10, 108)           11880     \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,961\n",
      "Trainable params: 12,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - 3s 16ms/step - loss: 0.0416 - val_loss: 9.3182e-04\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 8.9058e-04\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 8.0264e-04\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 9.8352e-04\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 7.6982e-04\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 7.9637e-04\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 8.1258e-04\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 8.9001e-04\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 7.2425e-04\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 7.8213e-04\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 8.3316e-04\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 6.1325e-04\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 6.9533e-04\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 6.8552e-04\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 7.7159e-04\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 6.9702e-04\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 6.7634e-04\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 6.6511e-04\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 7.1489e-04\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 6.9658e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 7.3968e-04\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 5.7292e-04\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 7.9068e-04\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 6.1910e-04\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 7.8494e-04\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.3495e-04\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 6.1880e-04\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 5.7469e-04\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 5.5584e-04\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 5.1481e-04\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 6.5132e-04\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 6.0866e-04\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 6.6529e-04\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 6.8623e-04\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 5.3234e-04\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 9.0451e-04\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 4.8915e-04\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.6863e-04\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 4.8664e-04\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 4.7327e-04\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 5.4366e-04\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 5.5110e-04\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 4.4322e-04\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 4.8878e-04\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 5.1759e-04\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 5.5163e-04\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.8115e-04\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 5.3255e-04\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 4.9681e-04\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.8103e-04\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.0254e-04\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 5.8136e-04\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 5.5359e-04\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.3029e-04\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 5.8372e-04\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.0673e-04\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 4.1721e-04\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.5138e-04\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.7866e-04\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.7890e-04\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.4855e-04\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.6796e-04\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.1727e-04\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.9949e-04\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.1631e-04\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.7275e-04\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.9203e-04\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.1975e-04\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.2952e-04\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.1168e-04\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.3757e-04\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.8073e-04\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.9245e-04\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.6967e-04\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.0169e-04\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.3733e-04\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 4.1088e-04\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.1412e-04\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.7037e-04\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.1194e-04\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.9884e-04 - val_loss: 3.5781e-04\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.9498e-04 - val_loss: 3.2873e-04\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 9.8694e-04 - val_loss: 5.1243e-04\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.9103e-04 - val_loss: 2.9969e-04\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.9634e-04 - val_loss: 3.4722e-04\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.8120e-04 - val_loss: 4.0480e-04\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.8413e-04 - val_loss: 2.7747e-04\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 4.7926e-04\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.9087e-04 - val_loss: 2.9616e-04\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.7443e-04 - val_loss: 4.1395e-04\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.5343e-04 - val_loss: 4.5855e-04\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 9.6225e-04 - val_loss: 3.7565e-04\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.6693e-04 - val_loss: 6.8302e-04\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.7350e-04 - val_loss: 2.8207e-04\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.5675e-04 - val_loss: 5.1758e-04\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.3624e-04 - val_loss: 2.7683e-04\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.4584e-04 - val_loss: 3.2449e-04\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 9.3125e-04 - val_loss: 3.2808e-04\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 9ms/step - loss: 9.4786e-04 - val_loss: 2.9985e-04\n",
      "Thời gian huấn luyện:  36.8007538318634\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 10, 108)           47520     \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,601\n",
      "Trainable params: 48,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - 3s 20ms/step - loss: 0.0263 - val_loss: 9.5701e-04\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 7.0973e-04\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 8.6034e-04\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 7.3461e-04\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 8.5523e-04\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 5.7776e-04\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 6.7244e-04\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 6.3885e-04\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 6.1771e-04\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 6.2794e-04\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 7.2190e-04\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 7.1826e-04\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 6.3553e-04\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.4353e-04\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.5578e-04\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 6.6022e-04\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.6628e-04\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 5.3367e-04\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 4.6481e-04\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 4.7689e-04\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 6.0361e-04\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 4.7921e-04\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 5.2067e-04\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 5.1471e-04\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 4.2698e-04\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 4.4816e-04\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 4.2114e-04\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 4.6421e-04\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.8042e-04\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.0263e-04\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.5079e-04\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.5290e-04\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.5882e-04\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.6008e-04\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 5.2719e-04\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 3.1134e-04\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 4.0171e-04\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 9.9933e-04 - val_loss: 3.0399e-04\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.8979e-04 - val_loss: 3.3776e-04\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 9.6039e-04 - val_loss: 3.7893e-04\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 9.6314e-04 - val_loss: 3.3057e-04\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.3794e-04 - val_loss: 2.8293e-04\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.3908e-04 - val_loss: 3.3054e-04\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 9.1104e-04 - val_loss: 3.6556e-04\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 9.0135e-04 - val_loss: 3.3078e-04\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.9187e-04 - val_loss: 3.2784e-04\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 9.0495e-04 - val_loss: 3.5760e-04\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 8.9019e-04 - val_loss: 3.0362e-04\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.5848e-04 - val_loss: 3.0445e-04\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 8.7010e-04 - val_loss: 3.3852e-04\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 8.5951e-04 - val_loss: 4.1699e-04\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.3927e-04 - val_loss: 3.1294e-04\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 8.4105e-04 - val_loss: 5.0987e-04\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 8.5464e-04 - val_loss: 2.9461e-04\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.2760e-04 - val_loss: 2.8886e-04\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 8.0804e-04 - val_loss: 2.4122e-04\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 8.2029e-04 - val_loss: 3.3675e-04\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.3201e-04 - val_loss: 3.1300e-04\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.2348e-04 - val_loss: 2.3488e-04\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.9827e-04 - val_loss: 3.2459e-04\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 8.0107e-04 - val_loss: 3.2250e-04\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.9777e-04 - val_loss: 3.9994e-04\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.8884e-04 - val_loss: 3.3395e-04\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.8736e-04 - val_loss: 2.7769e-04\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.8980e-04 - val_loss: 3.2350e-04\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.7313e-04 - val_loss: 3.5457e-04\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.9403e-04 - val_loss: 3.2339e-04\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.6190e-04 - val_loss: 2.9938e-04\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.0028e-04 - val_loss: 2.1545e-04\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.8174e-04 - val_loss: 4.5039e-04\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.6191e-04 - val_loss: 2.9677e-04\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.4445e-04 - val_loss: 3.3550e-04\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.5771e-04 - val_loss: 2.9607e-04\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.5337e-04 - val_loss: 3.1673e-04\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.5293e-04 - val_loss: 2.9415e-04\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.4079e-04 - val_loss: 2.5070e-04\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.4109e-04 - val_loss: 2.1178e-04\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.7316e-04 - val_loss: 2.5787e-04\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.2649e-04 - val_loss: 2.7507e-04\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.2163e-04 - val_loss: 2.1499e-04\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.3830e-04 - val_loss: 2.2511e-04\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.1435e-04 - val_loss: 2.6284e-04\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.1962e-04 - val_loss: 3.9179e-04\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.1731e-04 - val_loss: 2.4295e-04\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.0083e-04 - val_loss: 2.5812e-04\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.0439e-04 - val_loss: 2.0462e-04\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.1840e-04 - val_loss: 2.7868e-04\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.1266e-04 - val_loss: 2.0500e-04\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 7.0214e-04 - val_loss: 2.2314e-04\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.9377e-04 - val_loss: 3.7929e-04\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.9802e-04 - val_loss: 3.1010e-04\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.9814e-04 - val_loss: 3.2269e-04\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.8833e-04 - val_loss: 3.4834e-04\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 6.9172e-04 - val_loss: 2.0150e-04\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 6.8262e-04 - val_loss: 2.9740e-04\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 6.8126e-04 - val_loss: 2.4898e-04\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 6.7787e-04 - val_loss: 2.8701e-04\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 6.7236e-04 - val_loss: 2.9592e-04\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 7.0192e-04 - val_loss: 1.9515e-04\n",
      "Thời gian huấn luyện:  36.058592796325684\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_3 (GRU)                 (None, 10, 108)           35964     \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,045\n",
      "Trainable params: 37,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "44/44 [==============================] - 0s 882us/step\n",
      "30/30 [==============================] - 0s 848us/step\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "44/44 [==============================] - 1s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1098 - val_loss: 0.0024\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0029\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0029\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0023\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 9.4209e-04\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 7.6713e-04\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 7.1430e-04\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 6.6345e-04\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 6.2400e-04\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 6.3299e-04\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.9274e-04\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.6721e-04\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.4565e-04\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.4416e-04\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.3042e-04\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.2519e-04\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.3690e-04\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.1363e-04\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.1412e-04\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.0620e-04\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.0925e-04\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.1696e-04\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 4.9727e-04\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 4.9454e-04\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 4.9191e-04\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 4.9566e-04\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 4.9656e-04\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.8290e-04\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.8015e-04\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.8031e-04\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.7421e-04\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.8669e-04\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.6910e-04\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.7105e-04\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.6226e-04\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.7973e-04\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.9938e-04\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.6226e-04\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.6637e-04\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.5046e-04\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.4530e-04\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.4038e-04\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.3818e-04\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.5087e-04\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.3370e-04\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.2835e-04\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.6002e-04\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.3387e-04\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.1956e-04\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.4679e-04\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.1157e-04\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.1262e-04\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.0509e-04\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.0368e-04\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.9843e-04\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.0161e-04\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.0558e-04\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.1041e-04\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.9269e-04\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.0345e-04\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.7910e-04\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.8296e-04\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.7281e-04\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.8766e-04\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.7675e-04\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.7212e-04\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.7876e-04\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.5491e-04\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.5190e-04\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.5384e-04\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.7732e-04\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.4271e-04\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.3965e-04\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.5781e-04\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.3576e-04\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.5945e-04\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.2780e-04\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.2178e-04\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.9408e-04 - val_loss: 3.2010e-04\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.7909e-04 - val_loss: 3.3753e-04\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.7247e-04 - val_loss: 3.1971e-04\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.6471e-04 - val_loss: 3.0907e-04\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.5387e-04 - val_loss: 3.0606e-04\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.4770e-04 - val_loss: 3.1015e-04\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.3458e-04 - val_loss: 3.3060e-04\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.2804e-04 - val_loss: 3.0803e-04\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.2116e-04 - val_loss: 3.0247e-04\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.1852e-04 - val_loss: 2.9088e-04\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.0366e-04 - val_loss: 2.9466e-04\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.9094e-04 - val_loss: 2.9700e-04\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.8845e-04 - val_loss: 2.9647e-04\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.7882e-04 - val_loss: 2.9834e-04\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.7053e-04 - val_loss: 3.0290e-04\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.7009e-04 - val_loss: 2.7899e-04\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.6161e-04 - val_loss: 2.6933e-04\n",
      "Thời gian huấn luyện:  8.00942063331604\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 10, 108)           216       \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,297\n",
      "Trainable params: 1,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 6.6492e-04\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 6.1753e-04\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 5.6012e-04\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 3.9383e-04\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.1974e-04\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.0191e-04\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.9288e-04\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.7321e-04 - val_loss: 5.1137e-04\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.2780e-04 - val_loss: 2.7225e-04\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.9956e-04\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.9307e-04 - val_loss: 3.3630e-04\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 2.6163e-04\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.6585e-04 - val_loss: 2.4196e-04\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.5692e-04 - val_loss: 2.5457e-04\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.4748e-04 - val_loss: 2.3506e-04\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.2334e-04 - val_loss: 3.7109e-04\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.9918e-04 - val_loss: 3.8153e-04\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.0752e-04 - val_loss: 2.4270e-04\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.9210e-04 - val_loss: 2.8442e-04\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.4376e-04 - val_loss: 3.6269e-04\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.7612e-04 - val_loss: 3.1451e-04\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.7352e-04 - val_loss: 2.3410e-04\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.5865e-04 - val_loss: 2.4642e-04\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.5792e-04 - val_loss: 2.3144e-04\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.7340e-04 - val_loss: 2.1029e-04\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.0673e-04 - val_loss: 2.2934e-04\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.1749e-04 - val_loss: 3.2625e-04\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.4098e-04 - val_loss: 2.6768e-04\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.1289e-04 - val_loss: 2.1159e-04\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.8331e-04 - val_loss: 2.0227e-04\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.4776e-04 - val_loss: 2.1978e-04\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.8717e-04 - val_loss: 1.9711e-04\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.4288e-04 - val_loss: 2.0275e-04\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.9997e-04 - val_loss: 3.0863e-04\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.9418e-04 - val_loss: 2.0461e-04\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.4067e-04 - val_loss: 2.2123e-04\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.4941e-04 - val_loss: 1.9493e-04\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.7046e-04 - val_loss: 2.0701e-04\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.9203e-04 - val_loss: 1.9377e-04\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.4261e-04 - val_loss: 2.0379e-04\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.4634e-04 - val_loss: 2.2569e-04\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.4489e-04 - val_loss: 1.8787e-04\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.2841e-04 - val_loss: 3.0303e-04\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.3431e-04 - val_loss: 2.0107e-04\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.1658e-04 - val_loss: 1.8470e-04\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.9897e-04 - val_loss: 1.8895e-04\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.9638e-04 - val_loss: 1.8385e-04\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.8020e-04 - val_loss: 2.0862e-04\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.7008e-04 - val_loss: 1.8849e-04\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.0436e-04 - val_loss: 1.8051e-04\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.3721e-04 - val_loss: 1.8911e-04\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.0202e-04 - val_loss: 2.3725e-04\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.1898e-04 - val_loss: 1.8305e-04\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.8551e-04 - val_loss: 1.8922e-04\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.2190e-04 - val_loss: 2.8665e-04\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.1412e-04 - val_loss: 3.1843e-04\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.2868e-04 - val_loss: 1.8804e-04\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.9568e-04 - val_loss: 2.0818e-04\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.2776e-04 - val_loss: 2.1853e-04\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.1700e-04 - val_loss: 1.7196e-04\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.9055e-04 - val_loss: 2.0860e-04\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.8161e-04 - val_loss: 1.7659e-04\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.8213e-04 - val_loss: 2.4156e-04\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.7040e-04 - val_loss: 1.7593e-04\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.8075e-04 - val_loss: 1.8037e-04\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.8286e-04 - val_loss: 1.6876e-04\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.1020e-04 - val_loss: 4.1290e-04\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.7269e-04 - val_loss: 1.6869e-04\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.6232e-04 - val_loss: 2.6245e-04\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.0989e-04 - val_loss: 1.8564e-04\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.7937e-04 - val_loss: 1.6697e-04\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.5949e-04 - val_loss: 1.9951e-04\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.5166e-04 - val_loss: 1.6551e-04\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.5083e-04 - val_loss: 2.7894e-04\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.9290e-04 - val_loss: 1.6464e-04\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 6.0341e-04 - val_loss: 1.6529e-04\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.0734e-04 - val_loss: 1.8299e-04\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4347e-04 - val_loss: 1.6513e-04\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4311e-04 - val_loss: 1.7544e-04\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.3419e-04 - val_loss: 1.6637e-04\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.4788e-04 - val_loss: 2.7646e-04\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.6234e-04 - val_loss: 2.2383e-04\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.5208e-04 - val_loss: 1.5996e-04\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4988e-04 - val_loss: 1.7121e-04\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.3385e-04 - val_loss: 1.7731e-04\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 5.2143e-04 - val_loss: 1.9997e-04\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 5.3539e-04 - val_loss: 2.4309e-04\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 5.7934e-04 - val_loss: 1.6380e-04\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.6111e-04 - val_loss: 1.6634e-04\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4204e-04 - val_loss: 1.6046e-04\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4234e-04 - val_loss: 2.7529e-04\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.7486e-04 - val_loss: 1.5905e-04\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.3909e-04 - val_loss: 1.7975e-04\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.1131e-04 - val_loss: 1.6795e-04\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.3480e-04 - val_loss: 1.6346e-04\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.5268e-04 - val_loss: 2.1285e-04\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.3870e-04 - val_loss: 1.6677e-04\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.3226e-04 - val_loss: 1.5440e-04\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.3852e-04 - val_loss: 1.8014e-04\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4339e-04 - val_loss: 1.6832e-04\n",
      "Thời gian huấn luyện:  15.082785606384277\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_4 (SimpleRNN)    (None, 10, 108)           11880     \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,961\n",
      "Trainable params: 12,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 3s 20ms/step - loss: 0.0432 - val_loss: 0.0013\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 9.6639e-04\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 9.1332e-04\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 7.8667e-04\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 7.7845e-04\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 7.6819e-04\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 7.8213e-04\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 7.6032e-04\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 7.6949e-04\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 7.6636e-04\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 7.3760e-04\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 7.4358e-04\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 7.3324e-04\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 7.2584e-04\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 7.4535e-04\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 7.3796e-04\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 7.0569e-04\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 7.4572e-04\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 6.9422e-04\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 6.8956e-04\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 7.6068e-04\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 7.0008e-04\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 6.7368e-04\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 6.8318e-04\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 6.6198e-04\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 6.5738e-04\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 6.4876e-04\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 7.1083e-04\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 6.3431e-04\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 6.2914e-04\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 6.5381e-04\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 6.3042e-04\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 6.2765e-04\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 6.0624e-04\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 6.1296e-04\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 5.9126e-04\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 6.2095e-04\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 6.4091e-04\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 5.8449e-04\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 5.6414e-04\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 5.7744e-04\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 5.6711e-04\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 5.9445e-04\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 5.8033e-04\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 5.7231e-04\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.3874e-04\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 6.5117e-04\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 5.6011e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.1507e-04\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 5.4402e-04\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 4.8637e-04\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 4.8793e-04\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 4.7546e-04\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 4.6650e-04\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 4.6159e-04\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 5.1511e-04\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 4.8816e-04\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.4046e-04\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 4.3278e-04\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.2183e-04\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.2442e-04\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 4.6701e-04\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 4.3107e-04\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.0014e-04\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.9463e-04\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 3.9261e-04\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.1586e-04\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.0616e-04\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.2697e-04\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.5071e-04\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.8971e-04\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 3.7477e-04\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 3.8471e-04\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 3.5313e-04\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 3.8379e-04\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 3.9445e-04\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.5502e-04\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.4757e-04\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 3.6507e-04\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 3.4627e-04\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.4150e-04\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.3978e-04\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 3.3585e-04\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.4992e-04\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 3.3033e-04\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 3.2730e-04\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.3397e-04\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 3.7070e-04\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.2220e-04\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.1997e-04\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.3848e-04\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.5099e-04\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.1586e-04\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.0126e-04\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.1973e-04\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.1355e-04\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.8830e-04\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.5839e-04\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.0911e-04\n",
      "Thời gian huấn luyện:  34.366658449172974\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 10, 108)           47520     \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,601\n",
      "Trainable params: 48,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 4s 23ms/step - loss: 0.0338 - val_loss: 0.0015\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 7.4882e-04\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 7.9884e-04\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 6.4361e-04\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 6.0259e-04\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 5.9978e-04\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 6.3180e-04\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 6.1275e-04\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 5.5964e-04\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.4589e-04\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 5.3907e-04\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.4671e-04\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.2081e-04\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 5.3181e-04\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.0521e-04\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 4.9542e-04\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 5.0239e-04\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 4.9296e-04\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.8187e-04\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 4.5997e-04\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 4.7415e-04\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.4472e-04\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.4779e-04\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.4384e-04\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.2061e-04\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.2568e-04\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.1564e-04\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.9353e-04\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.8774e-04\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 4.2535e-04\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.7712e-04\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.2675e-04\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.7704e-04\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.4975e-04\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.9997e-04\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.3730e-04\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 3.2864e-04\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 3.6691e-04\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.2370e-04\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.9376e-04 - val_loss: 3.0748e-04\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 9.8049e-04 - val_loss: 3.3758e-04\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.5744e-04 - val_loss: 3.0098e-04\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 9.4861e-04 - val_loss: 3.5733e-04\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 9.3376e-04 - val_loss: 2.8733e-04\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 9.2848e-04 - val_loss: 2.9000e-04\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 9.2061e-04 - val_loss: 2.8753e-04\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 8.9540e-04 - val_loss: 2.7601e-04\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 8.9357e-04 - val_loss: 2.7405e-04\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.1245e-04 - val_loss: 3.8355e-04\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 8.7463e-04 - val_loss: 2.6232e-04\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 8.8074e-04 - val_loss: 2.6804e-04\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.8672e-04 - val_loss: 2.9666e-04\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 8.5334e-04 - val_loss: 2.5365e-04\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 8.5300e-04 - val_loss: 3.1023e-04\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.7254e-04 - val_loss: 2.5294e-04\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 8.4346e-04 - val_loss: 3.1879e-04\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 8.6363e-04 - val_loss: 2.5327e-04\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.6176e-04 - val_loss: 3.2325e-04\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.2927e-04 - val_loss: 2.6015e-04\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.3620e-04 - val_loss: 3.2822e-04\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 8.2545e-04 - val_loss: 2.3808e-04\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.0796e-04 - val_loss: 2.4407e-04\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.9958e-04 - val_loss: 2.6584e-04\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.9554e-04 - val_loss: 2.3684e-04\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.8937e-04 - val_loss: 2.3524e-04\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.9166e-04 - val_loss: 2.3209e-04\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.7441e-04 - val_loss: 2.2994e-04\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 8.1050e-04 - val_loss: 2.4770e-04\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.7610e-04 - val_loss: 2.3075e-04\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.7115e-04 - val_loss: 2.2590e-04\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.7134e-04 - val_loss: 2.3810e-04\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.6639e-04 - val_loss: 2.3302e-04\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.8791e-04 - val_loss: 2.2927e-04\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.7109e-04 - val_loss: 3.0570e-04\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.7529e-04 - val_loss: 2.2247e-04\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.4845e-04 - val_loss: 2.2014e-04\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.5815e-04 - val_loss: 2.1981e-04\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.6909e-04 - val_loss: 2.2153e-04\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.4575e-04 - val_loss: 2.3677e-04\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.4308e-04 - val_loss: 2.7186e-04\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.4815e-04 - val_loss: 2.3243e-04\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.4414e-04 - val_loss: 2.3502e-04\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.3014e-04 - val_loss: 2.6234e-04\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.3342e-04 - val_loss: 2.1346e-04\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.3875e-04 - val_loss: 2.2468e-04\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.1834e-04 - val_loss: 2.1282e-04\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.3665e-04 - val_loss: 2.1368e-04\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.1763e-04 - val_loss: 2.1021e-04\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.1663e-04 - val_loss: 2.1585e-04\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.0398e-04 - val_loss: 2.6574e-04\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.2501e-04 - val_loss: 2.8020e-04\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.3468e-04 - val_loss: 2.3154e-04\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.0003e-04 - val_loss: 2.3229e-04\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 7.0120e-04 - val_loss: 2.0605e-04\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.9488e-04 - val_loss: 2.2776e-04\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 8ms/step - loss: 7.1065e-04 - val_loss: 3.0739e-04\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.9764e-04 - val_loss: 2.0657e-04\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.9438e-04 - val_loss: 2.2661e-04\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.8263e-04 - val_loss: 2.7626e-04\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 6.9899e-04 - val_loss: 2.0960e-04\n",
      "Thời gian huấn luyện:  35.79609775543213\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_4 (GRU)                 (None, 10, 108)           35964     \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,045\n",
      "Trainable params: 37,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "44/44 [==============================] - 1s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "44/44 [==============================] - 1s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 1s 5ms/step - loss: 0.1073 - val_loss: 0.0020\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0030\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0025\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0022\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0020\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0014\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 9.1450e-04\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 8.8101e-04\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 7.4348e-04\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 7.3448e-04\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 6.5328e-04\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 6.7240e-04\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 6.4012e-04\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 6.5798e-04\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 6.1113e-04\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 6.0917e-04\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 6.1190e-04\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 6.0594e-04\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 5.9898e-04\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 6.0201e-04\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 6.1526e-04\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 6.1415e-04\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.9095e-04\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.7444e-04\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.7406e-04\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.9276e-04\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.8689e-04\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.7136e-04\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 5.8081e-04\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.6582e-04\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.6965e-04\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.6318e-04\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 5.4805e-04\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.7945e-04\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.7327e-04\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.5492e-04\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.4542e-04\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.4263e-04\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.5870e-04\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.4719e-04\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.4759e-04\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 5.3034e-04\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.1782e-04\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 5.6095e-04\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 5.2277e-04\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.2130e-04\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.6359e-04\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.0910e-04\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.3886e-04\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.3360e-04\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.9364e-04\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.1974e-04\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 4.9488e-04\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 4.8104e-04\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 5.0761e-04\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 4.7645e-04\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.7191e-04\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.7284e-04\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.7005e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.0442e-04\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.5882e-04\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.9877e-04\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.5157e-04\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.4837e-04\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.1265e-04\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.4772e-04\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 4.6309e-04\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.4518e-04\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.4294e-04\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.5293e-04\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.3791e-04\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.6253e-04\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.1853e-04\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.1608e-04\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.4023e-04\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.2597e-04\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.0465e-04\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.1672e-04\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.0640e-04\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.1206e-04\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.9286e-04\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.0082e-04\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.0496e-04\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.2928e-04\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.7961e-04\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.7653e-04\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.7346e-04\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.7077e-04\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 3.9028e-04\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.8399e-04\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.6106e-04\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 3.6567e-04\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 3.5553e-04\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.6174e-04\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.4979e-04\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.5985e-04\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.4356e-04\n",
      "Thời gian huấn luyện:  8.799660921096802\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 10, 108)           216       \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,297\n",
      "Trainable params: 1,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 1s 10ms/step - loss: 0.0191 - val_loss: 0.0022\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 8.9475e-04\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 8.6960e-04\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 7.1515e-04\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 7.1282e-04\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 7.1257e-04\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 6.5999e-04\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 9.1686e-04\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 6.3732e-04\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 4.8931e-04\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 4.5988e-04\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 7.3735e-04\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 4.2864e-04\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 4.9891e-04\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 4.0809e-04\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 4.3692e-04\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.5466e-04\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 6.3366e-04\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 4.7775e-04\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.4859e-04\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 3.6590e-04\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.2145e-04\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.6515e-04\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.8450e-04\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.4545e-04\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 3.8544e-04\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.3976e-04\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.6042e-04\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.4500e-04\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.3771e-04\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.7132e-04\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 3.5365e-04\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.6638e-04\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.7340e-04 - val_loss: 3.3226e-04\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.6870e-04 - val_loss: 3.4917e-04\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.6522e-04 - val_loss: 8.4889e-04\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.7575e-04\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.4722e-04 - val_loss: 2.9934e-04\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.3309e-04 - val_loss: 3.4416e-04\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.6128e-04 - val_loss: 2.9537e-04\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.3542e-04 - val_loss: 3.7599e-04\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.5072e-04 - val_loss: 2.9030e-04\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.0980e-04 - val_loss: 2.9655e-04\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.9203e-04 - val_loss: 3.3921e-04\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.3827e-04 - val_loss: 3.0813e-04\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.8315e-04 - val_loss: 2.9579e-04\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.9087e-04 - val_loss: 2.7796e-04\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.6595e-04 - val_loss: 3.5847e-04\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.1740e-04 - val_loss: 3.2715e-04\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.5012e-04 - val_loss: 2.7593e-04\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.2460e-04 - val_loss: 2.9994e-04\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.5013e-04 - val_loss: 2.7505e-04\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.6552e-04 - val_loss: 2.6596e-04\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.9148e-04 - val_loss: 3.9531e-04\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.3443e-04 - val_loss: 2.8741e-04\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.6096e-04 - val_loss: 2.6141e-04\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.9148e-04 - val_loss: 2.8940e-04\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.9447e-04 - val_loss: 2.5767e-04\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.9239e-04 - val_loss: 2.8004e-04\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.8636e-04 - val_loss: 4.3342e-04\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.5012e-04 - val_loss: 2.5810e-04\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.0083e-04 - val_loss: 2.5122e-04\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.4405e-04 - val_loss: 2.5100e-04\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.6866e-04 - val_loss: 2.5342e-04\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.7510e-04 - val_loss: 2.5742e-04\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.5766e-04 - val_loss: 2.6123e-04\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.3928e-04 - val_loss: 4.3640e-04\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.9253e-04 - val_loss: 2.5550e-04\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.4185e-04 - val_loss: 3.3105e-04\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.8172e-04 - val_loss: 2.4574e-04\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.6198e-04 - val_loss: 2.5276e-04\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.5497e-04 - val_loss: 2.7623e-04\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.9391e-04 - val_loss: 2.5571e-04\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.2771e-04 - val_loss: 2.5977e-04\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.6670e-04 - val_loss: 3.9637e-04\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.3083e-04 - val_loss: 3.0500e-04\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.4981e-04 - val_loss: 4.2951e-04\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.1048e-04 - val_loss: 2.4950e-04\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.0794e-04 - val_loss: 2.3385e-04\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.0411e-04 - val_loss: 3.8264e-04\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.8605e-04 - val_loss: 2.5416e-04\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.2404e-04 - val_loss: 3.4177e-04\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.8265e-04 - val_loss: 2.2809e-04\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.1479e-04 - val_loss: 2.2559e-04\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.8414e-04 - val_loss: 2.3072e-04\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7528e-04 - val_loss: 2.3642e-04\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.1676e-04 - val_loss: 3.2753e-04\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.1389e-04 - val_loss: 2.7254e-04\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.8605e-04 - val_loss: 2.3374e-04\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.5925e-04 - val_loss: 3.1380e-04\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.0286e-04 - val_loss: 2.2306e-04\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.3650e-04 - val_loss: 2.7586e-04\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.1128e-04 - val_loss: 2.9402e-04\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.5582e-04 - val_loss: 2.6858e-04\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.7143e-04 - val_loss: 2.2801e-04\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.0069e-04 - val_loss: 2.3062e-04\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.5293e-04 - val_loss: 2.2741e-04\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.8656e-04 - val_loss: 2.1555e-04\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.4581e-04 - val_loss: 2.3394e-04\n",
      "Thời gian huấn luyện:  16.12658667564392\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_5 (SimpleRNN)    (None, 10, 108)           11880     \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,961\n",
      "Trainable params: 12,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 3s 26ms/step - loss: 0.0473 - val_loss: 0.0023\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 9.3945e-04\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 9.0470e-04\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 8.7244e-04\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 8.5155e-04\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 8.4095e-04\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 9.0336e-04\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 8.4174e-04\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 8.2200e-04\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 8.2452e-04\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 8.4148e-04\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 8.0857e-04\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 8.0012e-04\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 7.9581e-04\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 8.0584e-04\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 7.9809e-04\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 8.1231e-04\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 7.7393e-04\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 8.4467e-04\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 8.1258e-04\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 7.5952e-04\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 7.6265e-04\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 7.4813e-04\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 7.4801e-04\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 7.3873e-04\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 7.7839e-04\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 7.6166e-04\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 7.2159e-04\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 7.3642e-04\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 7.0991e-04\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 7.0867e-04\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 7.1090e-04\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 6.9492e-04\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 6.9514e-04\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 8.2340e-04\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 6.8518e-04\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 6.7053e-04\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 6.6450e-04\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 6.6058e-04\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 6.5715e-04\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.7122e-04\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.6606e-04\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.5297e-04\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.3447e-04\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.4851e-04\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.1618e-04\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 6.2669e-04\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 6.4919e-04\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 5.9676e-04\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 6.6642e-04\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 5.8744e-04\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 5.8047e-04\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 6.9271e-04\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 6.0452e-04\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 5.6320e-04\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 5.7081e-04\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.5455e-04\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.4164e-04\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 6.3215e-04\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.3668e-04\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 6.3039e-04\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.2522e-04\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 5.1592e-04\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.0225e-04\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.1066e-04\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.1071e-04\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.0807e-04\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.7962e-04\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.8902e-04\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.7456e-04\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.9363e-04\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.6007e-04\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.6458e-04\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.3896e-04\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.3354e-04\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.3043e-04\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 5.1914e-04\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.2332e-04\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.3296e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.3041e-04\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.4906e-04\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.0084e-04\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.2346e-04\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.0819e-04\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 8.3585e-04\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.9102e-04\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.8767e-04\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 4.5335e-04\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.0090e-04\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 5.0822e-04\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 6.3255e-04\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 4.1808e-04\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.7181e-04\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.7454e-04\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.6989e-04\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.6365e-04\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.8616e-04\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 3.6356e-04\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.3223e-04\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 5.0361e-04\n",
      "Thời gian huấn luyện:  34.564709424972534\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 10, 108)           47520     \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,601\n",
      "Trainable params: 48,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 2s 17ms/step - loss: 0.0417 - val_loss: 0.0019\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 9.0194e-04\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 8.0896e-04\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 8.1839e-04\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 8.4860e-04\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 7.4489e-04\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 7.6523e-04\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 7.3254e-04\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 7.1575e-04\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 7.2922e-04\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 7.1193e-04\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 7.1210e-04\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 6.7064e-04\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 6.7374e-04\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 6.4888e-04\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 6.7714e-04\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 6.2164e-04\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.1465e-04\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 7.2246e-04\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.5246e-04\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 6.0835e-04\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.8136e-04\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.7071e-04\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 5.8373e-04\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.5728e-04\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 5.4325e-04\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.9206e-04\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 5.1778e-04\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.9331e-04\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.1046e-04\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 5.0581e-04\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 4.8136e-04\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 4.7138e-04\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 5.2909e-04\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 5.0440e-04\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 5.5279e-04\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 4.6033e-04\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 4.7888e-04\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 4.4354e-04\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 4.5277e-04\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 4.4917e-04\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.9739e-04\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.1270e-04\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.1575e-04\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.0563e-04\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.7471e-04\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.9465e-04\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 3.5826e-04\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 3.6894e-04\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 3.4666e-04\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.8512e-04 - val_loss: 3.6748e-04\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.8132e-04 - val_loss: 3.5769e-04\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.6440e-04 - val_loss: 3.3814e-04\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.9975e-04 - val_loss: 3.4204e-04\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.4978e-04 - val_loss: 3.3370e-04\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.4017e-04 - val_loss: 3.2908e-04\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.4986e-04 - val_loss: 3.3016e-04\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.1603e-04 - val_loss: 3.4720e-04\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.2216e-04 - val_loss: 4.0488e-04\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.1660e-04 - val_loss: 3.5127e-04\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.0220e-04 - val_loss: 3.2386e-04\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.9679e-04 - val_loss: 3.7430e-04\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.8548e-04 - val_loss: 3.1715e-04\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.8338e-04 - val_loss: 3.4933e-04\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.7930e-04 - val_loss: 3.0675e-04\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.9931e-04 - val_loss: 4.1593e-04\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.5928e-04 - val_loss: 4.0338e-04\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.7991e-04 - val_loss: 3.1249e-04\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.5806e-04 - val_loss: 3.0961e-04\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.5758e-04 - val_loss: 4.1617e-04\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.3466e-04 - val_loss: 2.9172e-04\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.5123e-04 - val_loss: 2.8760e-04\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.4136e-04 - val_loss: 3.6048e-04\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.4587e-04 - val_loss: 3.1718e-04\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.3910e-04 - val_loss: 3.0894e-04\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.3014e-04 - val_loss: 2.8609e-04\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.1826e-04 - val_loss: 3.6736e-04\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.1628e-04 - val_loss: 3.2497e-04\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.1875e-04 - val_loss: 3.1122e-04\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.1668e-04 - val_loss: 2.9862e-04\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.0548e-04 - val_loss: 3.6129e-04\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.1048e-04 - val_loss: 3.0916e-04\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.1320e-04 - val_loss: 3.2673e-04\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.9869e-04 - val_loss: 2.9632e-04\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.1031e-04 - val_loss: 2.8871e-04\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.8687e-04 - val_loss: 3.3120e-04\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.0162e-04 - val_loss: 2.6759e-04\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 8.0988e-04 - val_loss: 2.6714e-04\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.9502e-04 - val_loss: 2.8349e-04\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.7700e-04 - val_loss: 3.8163e-04\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.7158e-04 - val_loss: 2.9104e-04\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.6103e-04 - val_loss: 3.4895e-04\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.7456e-04 - val_loss: 2.6018e-04\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.6862e-04 - val_loss: 2.7348e-04\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.5862e-04 - val_loss: 2.9496e-04\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.4958e-04 - val_loss: 2.9253e-04\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.5793e-04 - val_loss: 2.6591e-04\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.7992e-04 - val_loss: 2.5584e-04\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.5915e-04 - val_loss: 2.5502e-04\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.3632e-04 - val_loss: 2.6258e-04\n",
      "Thời gian huấn luyện:  29.431843280792236\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_5 (GRU)                 (None, 10, 108)           35964     \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,045\n",
      "Trainable params: 37,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "44/44 [==============================] - 0s 937us/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "44/44 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "40/40 [==============================] - 1s 5ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Thời gian huấn luyện:  18.86833906173706\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 10, 108)           216       \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,297\n",
      "Trainable params: 1,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "40/40 [==============================] - 1s 11ms/step - loss: 0.0386 - val_loss: 9.6343e-04\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 8.6695e-04\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 9.9306e-04\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 7.5961e-04\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 9.5893e-04\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 8.1271e-04\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 5.9844e-04\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 5.5926e-04\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 8.6528e-04\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 4.9233e-04\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 5.4246e-04\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 4.9843e-04\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 5.2258e-04\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 3.8491e-04\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.6599e-04\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.0147e-04\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.8342e-04\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.2623e-04\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.8785e-04\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.4435e-04\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.8812e-04 - val_loss: 4.3730e-04\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.8735e-04 - val_loss: 3.4592e-04\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.6670e-04 - val_loss: 3.2628e-04\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.5105e-04 - val_loss: 2.5410e-04\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.5377e-04\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.2265e-04 - val_loss: 2.4106e-04\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.8870e-04 - val_loss: 2.5167e-04\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.3597e-04 - val_loss: 3.6457e-04\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.6228e-04 - val_loss: 2.2868e-04\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.5111e-04 - val_loss: 2.2643e-04\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.1688e-04 - val_loss: 2.2421e-04\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.6125e-04 - val_loss: 2.6286e-04\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.4743e-04 - val_loss: 2.4080e-04\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.2178e-04 - val_loss: 3.6827e-04\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.0565e-04 - val_loss: 2.8697e-04\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.3848e-04 - val_loss: 4.3911e-04\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.0274e-04 - val_loss: 2.7079e-04\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.9168e-04 - val_loss: 2.4107e-04\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.7253e-04 - val_loss: 3.8694e-04\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.8860e-04 - val_loss: 2.2385e-04\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.7214e-04 - val_loss: 2.1091e-04\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.4830e-04 - val_loss: 2.5516e-04\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.4936e-04 - val_loss: 3.2358e-04\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.7092e-04 - val_loss: 3.8830e-04\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step - loss: 7.8326e-04 - val_loss: 3.5271e-04\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 7.4223e-04 - val_loss: 2.6136e-04\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.6350e-04 - val_loss: 2.8453e-04\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.3598e-04 - val_loss: 2.0334e-04\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.4555e-04 - val_loss: 4.4118e-04\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.5795e-04 - val_loss: 2.1705e-04\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.0804e-04 - val_loss: 2.4947e-04\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.7892e-04 - val_loss: 2.2159e-04\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.8750e-04 - val_loss: 2.2007e-04\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.9448e-04 - val_loss: 1.8900e-04\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.0447e-04 - val_loss: 2.0274e-04\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.8384e-04 - val_loss: 1.9256e-04\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.2706e-04 - val_loss: 2.7526e-04\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.0211e-04 - val_loss: 1.9330e-04\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.1904e-04 - val_loss: 2.7660e-04\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.5617e-04 - val_loss: 2.5605e-04\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.8009e-04 - val_loss: 2.0025e-04\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.8542e-04 - val_loss: 4.4054e-04\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.4573e-04 - val_loss: 2.5904e-04\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.9280e-04 - val_loss: 2.1176e-04\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.2770e-04 - val_loss: 2.0690e-04\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 6.4563e-04 - val_loss: 1.7633e-04\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.3232e-04 - val_loss: 3.1297e-04\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.4177e-04 - val_loss: 1.8193e-04\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.1238e-04 - val_loss: 1.9054e-04\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.0260e-04 - val_loss: 2.6370e-04\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.4229e-04 - val_loss: 2.1261e-04\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 6.2116e-04 - val_loss: 1.7450e-04\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.2083e-04 - val_loss: 1.8014e-04\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.0290e-04 - val_loss: 2.0582e-04\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.0537e-04 - val_loss: 1.7653e-04\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.2564e-04 - val_loss: 1.7615e-04\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.2323e-04 - val_loss: 2.9684e-04\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.0703e-04 - val_loss: 1.8958e-04\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.9957e-04 - val_loss: 1.7729e-04\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.8267e-04 - val_loss: 2.1626e-04\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.8427e-04 - val_loss: 1.6761e-04\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.9386e-04 - val_loss: 1.9332e-04\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.9150e-04 - val_loss: 2.5738e-04\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.1872e-04 - val_loss: 1.7865e-04\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.7006e-04 - val_loss: 2.8844e-04\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.6145e-04 - val_loss: 2.1509e-04\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.7863e-04 - val_loss: 1.8249e-04\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.5925e-04 - val_loss: 2.3680e-04\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.8403e-04 - val_loss: 1.8418e-04\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.7102e-04 - val_loss: 1.6959e-04\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.5329e-04 - val_loss: 2.4712e-04\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.0628e-04 - val_loss: 1.6373e-04\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.6848e-04 - val_loss: 2.0896e-04\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.6918e-04 - val_loss: 1.7236e-04\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.6357e-04 - val_loss: 1.7726e-04\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.5567e-04 - val_loss: 1.7922e-04\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.6227e-04 - val_loss: 1.7137e-04\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.3973e-04 - val_loss: 2.2420e-04\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.5525e-04 - val_loss: 2.3896e-04\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.9481e-04 - val_loss: 2.5880e-04\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.3688e-04 - val_loss: 1.6751e-04\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 5.4227e-04 - val_loss: 2.5536e-04\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.7078e-04 - val_loss: 1.5984e-04\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.3269e-04 - val_loss: 1.6237e-04\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.3082e-04 - val_loss: 1.5829e-04\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.2419e-04 - val_loss: 1.5693e-04\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.6062e-04 - val_loss: 1.6000e-04\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.6904e-04 - val_loss: 3.3320e-04\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.6397e-04 - val_loss: 2.5135e-04\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.4564e-04 - val_loss: 1.6356e-04\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.2543e-04 - val_loss: 1.7521e-04\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 6.1536e-04 - val_loss: 1.9127e-04\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.3229e-04 - val_loss: 1.6307e-04\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.3986e-04 - val_loss: 1.6024e-04\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.3874e-04 - val_loss: 1.6030e-04\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.2365e-04 - val_loss: 1.6083e-04\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.2623e-04 - val_loss: 1.9217e-04\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.1986e-04 - val_loss: 1.5313e-04\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.1689e-04 - val_loss: 1.7339e-04\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.0680e-04 - val_loss: 1.6880e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.0800e-04 - val_loss: 1.9898e-04\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.2404e-04 - val_loss: 2.6225e-04\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.2092e-04 - val_loss: 1.7616e-04\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.4234e-04 - val_loss: 1.5189e-04\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.0213e-04 - val_loss: 4.7983e-04\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.2842e-04 - val_loss: 1.9141e-04\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 5.0904e-04 - val_loss: 1.5405e-04\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.1936e-04 - val_loss: 3.1070e-04\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.7609e-04 - val_loss: 1.7856e-04\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.2148e-04 - val_loss: 1.4991e-04\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.1737e-04 - val_loss: 1.6516e-04\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.9043e-04 - val_loss: 1.5977e-04\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.8892e-04 - val_loss: 1.7898e-04\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.8896e-04 - val_loss: 1.5916e-04\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.8862e-04 - val_loss: 1.5272e-04\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.8812e-04 - val_loss: 1.7866e-04\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.0915e-04 - val_loss: 2.7056e-04\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.0800e-04 - val_loss: 2.2041e-04\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.8889e-04 - val_loss: 1.8629e-04\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.9297e-04 - val_loss: 1.4933e-04\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7675e-04 - val_loss: 1.5229e-04\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.1772e-04 - val_loss: 1.4730e-04\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.7122e-04 - val_loss: 1.5030e-04\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.1837e-04 - val_loss: 1.5382e-04\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.2089e-04 - val_loss: 1.5327e-04\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.0296e-04 - val_loss: 2.0212e-04\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.8694e-04 - val_loss: 1.5629e-04\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.8550e-04 - val_loss: 1.5336e-04\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.8841e-04 - val_loss: 1.8805e-04\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.1845e-04 - val_loss: 1.7437e-04\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7967e-04 - val_loss: 2.1093e-04\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7266e-04 - val_loss: 1.9997e-04\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 4.6707e-04 - val_loss: 1.4498e-04\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7507e-04 - val_loss: 1.5833e-04\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6782e-04 - val_loss: 1.5898e-04\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6402e-04 - val_loss: 1.4766e-04\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7601e-04 - val_loss: 2.0289e-04\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7286e-04 - val_loss: 1.6150e-04\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7899e-04 - val_loss: 1.4276e-04\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6663e-04 - val_loss: 1.6349e-04\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7261e-04 - val_loss: 1.4620e-04\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.9350e-04 - val_loss: 1.4247e-04\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7903e-04 - val_loss: 2.0137e-04\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6119e-04 - val_loss: 2.3735e-04\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7553e-04 - val_loss: 1.5615e-04\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7227e-04 - val_loss: 1.4204e-04\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6455e-04 - val_loss: 2.6306e-04\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.8345e-04 - val_loss: 1.4458e-04\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6867e-04 - val_loss: 1.8997e-04\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6697e-04 - val_loss: 1.4395e-04\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7611e-04 - val_loss: 1.4441e-04\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 4.6238e-04 - val_loss: 1.4060e-04\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6793e-04 - val_loss: 1.6269e-04\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.5863e-04 - val_loss: 2.4605e-04\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6959e-04 - val_loss: 1.5469e-04\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6080e-04 - val_loss: 1.6611e-04\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.8615e-04 - val_loss: 1.4738e-04\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.5172e-04 - val_loss: 1.4710e-04\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.5561e-04 - val_loss: 1.3962e-04\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.5792e-04 - val_loss: 2.2866e-04\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.5099e-04 - val_loss: 1.6796e-04\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6372e-04 - val_loss: 1.6209e-04\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6285e-04 - val_loss: 1.3933e-04\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.4796e-04 - val_loss: 1.4839e-04\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.4705e-04 - val_loss: 1.4084e-04\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.4524e-04 - val_loss: 1.4012e-04\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.4938e-04 - val_loss: 1.4141e-04\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 4.7936e-04 - val_loss: 2.0465e-04\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.5828e-04 - val_loss: 1.4144e-04\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.4854e-04 - val_loss: 2.3398e-04\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.5024e-04 - val_loss: 2.1873e-04\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7435e-04 - val_loss: 1.7741e-04\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 4.5576e-04 - val_loss: 1.4162e-04\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6196e-04 - val_loss: 1.9597e-04\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6609e-04 - val_loss: 1.3763e-04\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6562e-04 - val_loss: 2.3181e-04\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.5366e-04 - val_loss: 1.8120e-04\n",
      "Thời gian huấn luyện:  34.07444739341736\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_6 (SimpleRNN)    (None, 10, 108)           11880     \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,961\n",
      "Trainable params: 12,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "40/40 [==============================] - 2s 19ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - val_loss: 0.1529\n",
      "Thời gian huấn luyện:  76.54458856582642\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 10, 108)           47520     \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,601\n",
      "Trainable params: 48,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "40/40 [==============================] - 3s 21ms/step - loss: 0.0273 - val_loss: 6.9175e-04\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 9.8052e-04\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 7.9433e-04\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 8.0767e-04\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 7.3914e-04\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 6.4577e-04\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 5.8652e-04\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 5.8814e-04\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 6.4414e-04\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 5.6402e-04\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.7331e-04\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 5.8038e-04\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 5.5159e-04\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 8.3341e-04\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 5.0180e-04\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 7.3195e-04\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.3797e-04\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 4.7633e-04\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 7.1985e-04\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 5.0360e-04\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.5142e-04\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.4850e-04\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.5064e-04\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.6382e-04\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 5.0537e-04\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 3.8470e-04\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.4315e-04\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 4.4454e-04\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.4837e-04\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 4.6784e-04\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.8154e-04\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 5.0835e-04\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 4.4821e-04\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 4.8081e-04\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.9570e-04\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.4080e-04\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.3357e-04\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.6193e-04\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 5.6598e-04\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 4.9505e-04\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 4.6315e-04\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 9.7594e-04 - val_loss: 2.7995e-04\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 9.8249e-04 - val_loss: 4.8209e-04\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 9.4599e-04 - val_loss: 3.2025e-04\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 9.5765e-04 - val_loss: 3.0176e-04\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 9.3669e-04 - val_loss: 3.2859e-04\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 9.1319e-04 - val_loss: 2.8561e-04\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 9.0304e-04 - val_loss: 3.3088e-04\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 8.8764e-04 - val_loss: 5.7767e-04\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 8.9514e-04 - val_loss: 3.2277e-04\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 8.6980e-04 - val_loss: 3.5740e-04\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.6270e-04 - val_loss: 3.3459e-04\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 8.5319e-04 - val_loss: 3.6856e-04\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 8.4094e-04 - val_loss: 2.9917e-04\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.3713e-04 - val_loss: 4.0016e-04\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.2655e-04 - val_loss: 2.8389e-04\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.2003e-04 - val_loss: 2.9028e-04\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.2399e-04 - val_loss: 3.1372e-04\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 8.1192e-04 - val_loss: 3.1896e-04\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.0331e-04 - val_loss: 3.8347e-04\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 8.1091e-04 - val_loss: 2.5984e-04\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 7.9088e-04 - val_loss: 2.8521e-04\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.8721e-04 - val_loss: 2.8062e-04\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.9430e-04 - val_loss: 3.2937e-04\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.8676e-04 - val_loss: 3.9088e-04\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.6848e-04 - val_loss: 2.2081e-04\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.8170e-04 - val_loss: 3.5607e-04\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.6352e-04 - val_loss: 2.8751e-04\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.6342e-04 - val_loss: 2.8605e-04\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.6616e-04 - val_loss: 2.2621e-04\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 7.6548e-04 - val_loss: 2.6427e-04\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 7.4854e-04 - val_loss: 3.7796e-04\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.5108e-04 - val_loss: 2.8210e-04\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.3887e-04 - val_loss: 2.0870e-04\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.5696e-04 - val_loss: 2.0456e-04\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.3099e-04 - val_loss: 2.0382e-04\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.5820e-04 - val_loss: 4.0263e-04\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.2662e-04 - val_loss: 2.0909e-04\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.2162e-04 - val_loss: 2.3324e-04\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 7.1541e-04 - val_loss: 2.2036e-04\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 7.1479e-04 - val_loss: 2.5122e-04\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.9995e-04 - val_loss: 2.0231e-04\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.2413e-04 - val_loss: 2.0553e-04\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.1104e-04 - val_loss: 1.9702e-04\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.1444e-04 - val_loss: 1.9636e-04\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.3551e-04 - val_loss: 4.0517e-04\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.9815e-04 - val_loss: 2.0781e-04\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 7.0045e-04 - val_loss: 2.9550e-04\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 6.8558e-04 - val_loss: 2.2819e-04\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.8547e-04 - val_loss: 2.3137e-04\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.9069e-04 - val_loss: 3.6637e-04\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.7241e-04 - val_loss: 2.6068e-04\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.6675e-04 - val_loss: 2.4820e-04\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.6588e-04 - val_loss: 2.4515e-04\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 6.6505e-04 - val_loss: 2.1203e-04\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.7040e-04 - val_loss: 3.2270e-04\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.6993e-04 - val_loss: 2.5767e-04\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 6.5644e-04 - val_loss: 2.0707e-04\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.5433e-04 - val_loss: 2.1561e-04\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.4517e-04 - val_loss: 2.1328e-04\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.4344e-04 - val_loss: 3.0755e-04\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.4136e-04 - val_loss: 3.0329e-04\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.4297e-04 - val_loss: 2.8588e-04\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 6.3953e-04 - val_loss: 1.8915e-04\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.4876e-04 - val_loss: 2.2603e-04\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.3266e-04 - val_loss: 2.1645e-04\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 6.3016e-04 - val_loss: 2.3592e-04\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.6856e-04 - val_loss: 2.8492e-04\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.4723e-04 - val_loss: 1.9475e-04\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.2151e-04 - val_loss: 2.2460e-04\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.1510e-04 - val_loss: 2.1062e-04\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.1972e-04 - val_loss: 1.7808e-04\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 6.0802e-04 - val_loss: 2.5959e-04\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.0760e-04 - val_loss: 1.8529e-04\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.1162e-04 - val_loss: 1.8706e-04\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 6.1062e-04 - val_loss: 2.0326e-04\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.9787e-04 - val_loss: 2.3052e-04\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.9953e-04 - val_loss: 2.8256e-04\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.1208e-04 - val_loss: 2.5745e-04\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.9351e-04 - val_loss: 2.0121e-04\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.9528e-04 - val_loss: 1.8443e-04\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.8534e-04 - val_loss: 1.8137e-04\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.8977e-04 - val_loss: 2.0080e-04\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.0864e-04 - val_loss: 1.9715e-04\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.7892e-04 - val_loss: 1.9548e-04\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.9866e-04 - val_loss: 2.1810e-04\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.8480e-04 - val_loss: 2.0563e-04\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.9776e-04 - val_loss: 1.8381e-04\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.8956e-04 - val_loss: 2.3520e-04\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.8166e-04 - val_loss: 2.7192e-04\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.7502e-04 - val_loss: 1.8668e-04\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.6924e-04 - val_loss: 1.7010e-04\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.6476e-04 - val_loss: 1.8554e-04\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.7127e-04 - val_loss: 1.7450e-04\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.6758e-04 - val_loss: 1.6731e-04\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.6453e-04 - val_loss: 2.2832e-04\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.6209e-04 - val_loss: 2.6286e-04\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.6685e-04 - val_loss: 1.9363e-04\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.5433e-04 - val_loss: 1.8510e-04\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.5675e-04 - val_loss: 1.9290e-04\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.5659e-04 - val_loss: 2.0681e-04\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.4883e-04 - val_loss: 2.0280e-04\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.6670e-04 - val_loss: 1.6347e-04\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 6.0255e-04 - val_loss: 2.3638e-04\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.5551e-04 - val_loss: 2.2019e-04\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.7080e-04 - val_loss: 1.8038e-04\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.4814e-04 - val_loss: 2.0909e-04\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.3779e-04 - val_loss: 1.7406e-04\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.4100e-04 - val_loss: 2.3516e-04\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.4065e-04 - val_loss: 2.3071e-04\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.4610e-04 - val_loss: 1.7313e-04\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.3182e-04 - val_loss: 2.6673e-04\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.4163e-04 - val_loss: 2.0889e-04\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 5.4238e-04 - val_loss: 1.6053e-04\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 5.3470e-04 - val_loss: 1.5964e-04\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 5.3076e-04 - val_loss: 1.8392e-04\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.2740e-04 - val_loss: 1.9166e-04\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.2455e-04 - val_loss: 2.1362e-04\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.3461e-04 - val_loss: 1.5886e-04\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 5.2324e-04 - val_loss: 1.6256e-04\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.2886e-04 - val_loss: 1.5747e-04\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.2827e-04 - val_loss: 2.9186e-04\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.3519e-04 - val_loss: 1.8309e-04\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.4864e-04 - val_loss: 1.6185e-04\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 5.2955e-04 - val_loss: 1.8539e-04\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.3659e-04 - val_loss: 1.5708e-04\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.4339e-04 - val_loss: 2.6273e-04\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 5.5346e-04 - val_loss: 1.6726e-04\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.1144e-04 - val_loss: 1.6157e-04\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.0853e-04 - val_loss: 1.6299e-04\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.0800e-04 - val_loss: 2.2211e-04\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.0220e-04 - val_loss: 2.0353e-04\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.6256e-04 - val_loss: 1.5871e-04\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.4528e-04 - val_loss: 2.4864e-04\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.1746e-04 - val_loss: 1.9171e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.1043e-04 - val_loss: 1.6473e-04\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.0390e-04 - val_loss: 1.5267e-04\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.0608e-04 - val_loss: 2.0239e-04\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 4.9504e-04 - val_loss: 1.5614e-04\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.3239e-04 - val_loss: 1.7971e-04\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.2811e-04 - val_loss: 1.6733e-04\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 4.9829e-04 - val_loss: 2.0509e-04\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 4.8971e-04 - val_loss: 1.7756e-04\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 4.9428e-04 - val_loss: 1.5152e-04\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 4.9555e-04 - val_loss: 2.0304e-04\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.0013e-04 - val_loss: 1.6049e-04\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 4.9819e-04 - val_loss: 1.7335e-04\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 4.9130e-04 - val_loss: 1.9873e-04\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.0718e-04 - val_loss: 1.5709e-04\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 4.8946e-04 - val_loss: 1.9105e-04\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 4.8694e-04 - val_loss: 1.5095e-04\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 4.8703e-04 - val_loss: 2.1260e-04\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 4.9280e-04 - val_loss: 1.8874e-04\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.0133e-04 - val_loss: 1.4916e-04\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 4.9850e-04 - val_loss: 1.4919e-04\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 4.8879e-04 - val_loss: 1.5386e-04\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 4.8503e-04 - val_loss: 2.1239e-04\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 4.7851e-04 - val_loss: 1.5318e-04\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 5.0345e-04 - val_loss: 1.8219e-04\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 4.8460e-04 - val_loss: 1.6665e-04\n",
      "Thời gian huấn luyện:  77.55080676078796\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_6 (GRU)                 (None, 10, 108)           35964     \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,045\n",
      "Trainable params: 37,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "44/44 [==============================] - 1s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "44/44 [==============================] - 1s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "38/38 [==============================] - 1s 7ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 61/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 65/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 73/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 75/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 80/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 81/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 82/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 83/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 84/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 85/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 86/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 87/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 88/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 89/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 90/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 91/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 92/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 93/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 94/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 95/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 96/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 97/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 98/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 99/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 100/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 101/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 102/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 103/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 104/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 105/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 106/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 107/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 108/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 109/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 110/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 111/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 112/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 113/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 114/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 115/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 116/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 117/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 118/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 119/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 120/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 121/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 122/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 123/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 124/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 125/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 126/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 127/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 128/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 129/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 130/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 131/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 132/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 133/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 134/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 135/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 136/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 137/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 138/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 139/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 140/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 141/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 142/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 143/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 144/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 145/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 146/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 147/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 148/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 149/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 150/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 151/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 152/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 153/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 154/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 155/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 156/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 157/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 158/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 159/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 160/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 161/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 162/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 163/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 164/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 165/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 166/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 167/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 168/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 169/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 170/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 171/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 172/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 173/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 174/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 175/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 176/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 177/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 178/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 179/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 180/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 181/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 182/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 183/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 184/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 185/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 186/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 187/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 188/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 189/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 190/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 191/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 192/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 193/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 194/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 195/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 196/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 197/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 198/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 199/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Epoch 200/200\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1711\n",
      "Thời gian huấn luyện:  19.28488326072693\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_35 (Dense)            (None, 10, 108)           216       \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 1080)              0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,297\n",
      "Trainable params: 1,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "38/38 [==============================] - 1s 10ms/step - loss: 0.0621 - val_loss: 0.0038\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 8.0451e-04\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 9.0065e-04\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 7.9003e-04\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 7.6672e-04\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 6.7235e-04\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 6.9217e-04\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 5.8492e-04\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 6.6919e-04\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 5.4197e-04\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 6.1240e-04\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 5.5441e-04\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 4.8686e-04\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 4.6611e-04\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 4.7462e-04\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 5.5045e-04\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 4.1765e-04\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 4.3554e-04\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 4.4777e-04\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 3.8714e-04\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 4.3043e-04\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 3.9313e-04\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 3.9390e-04\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 3.8291e-04\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 4.2427e-04\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 3.6357e-04\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 3.3893e-04\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 3.3351e-04\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 3.7314e-04\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 3.2698e-04\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 3.4646e-04\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 3.1771e-04\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.4025e-04\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.1240e-04\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.1262e-04\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.3377e-04\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.9542e-04\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.1771e-04\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.1494e-04\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.0313e-04\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.2796e-04\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.8523e-04\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.7510e-04\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 9.8972e-04 - val_loss: 2.8466e-04\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.6425e-04 - val_loss: 2.7469e-04\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.7115e-04 - val_loss: 2.9997e-04\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 4.2240e-04\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.0067e-04\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.4467e-04 - val_loss: 2.7641e-04\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.3709e-04 - val_loss: 2.8906e-04\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 9.3099e-04 - val_loss: 3.2313e-04\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.5367e-04 - val_loss: 3.5677e-04\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.1877e-04 - val_loss: 2.9520e-04\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.4340e-04 - val_loss: 2.5680e-04\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.9473e-04 - val_loss: 2.5891e-04\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.8041e-04 - val_loss: 2.5625e-04\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.8590e-04 - val_loss: 2.7408e-04\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.6666e-04 - val_loss: 4.0880e-04\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.0899e-04 - val_loss: 2.4807e-04\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.8806e-04 - val_loss: 2.5491e-04\n",
      "Epoch 61/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.4984e-04 - val_loss: 2.5473e-04\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.4405e-04 - val_loss: 2.4346e-04\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.5837e-04 - val_loss: 3.4031e-04\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.5824e-04 - val_loss: 3.1942e-04\n",
      "Epoch 65/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.3226e-04 - val_loss: 2.4086e-04\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.7444e-04 - val_loss: 2.6035e-04\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.3624e-04 - val_loss: 3.0416e-04\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.1974e-04 - val_loss: 3.2558e-04\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.2550e-04 - val_loss: 2.5042e-04\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.0444e-04 - val_loss: 3.1730e-04\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.0748e-04 - val_loss: 2.3564e-04\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.8664e-04 - val_loss: 2.2973e-04\n",
      "Epoch 73/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.9534e-04 - val_loss: 2.2870e-04\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.8505e-04 - val_loss: 2.4099e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.7109e-04 - val_loss: 2.5785e-04\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.9617e-04 - val_loss: 2.2348e-04\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.9588e-04 - val_loss: 2.2147e-04\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.6650e-04 - val_loss: 2.2137e-04\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.8358e-04 - val_loss: 2.3908e-04\n",
      "Epoch 80/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.4803e-04 - val_loss: 2.7652e-04\n",
      "Epoch 81/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.2703e-04 - val_loss: 3.4107e-04\n",
      "Epoch 82/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.7857e-04 - val_loss: 3.8649e-04\n",
      "Epoch 83/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.9669e-04 - val_loss: 2.4722e-04\n",
      "Epoch 84/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.1551e-04 - val_loss: 2.1236e-04\n",
      "Epoch 85/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.3825e-04 - val_loss: 2.2563e-04\n",
      "Epoch 86/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.2560e-04 - val_loss: 2.1345e-04\n",
      "Epoch 87/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.1482e-04 - val_loss: 2.1179e-04\n",
      "Epoch 88/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.6858e-04 - val_loss: 2.0789e-04\n",
      "Epoch 89/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.3885e-04 - val_loss: 2.3715e-04\n",
      "Epoch 90/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.0666e-04 - val_loss: 2.0626e-04\n",
      "Epoch 91/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.0246e-04 - val_loss: 3.4112e-04\n",
      "Epoch 92/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.0978e-04 - val_loss: 2.3018e-04\n",
      "Epoch 93/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.0547e-04 - val_loss: 2.0252e-04\n",
      "Epoch 94/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.8270e-04 - val_loss: 2.7928e-04\n",
      "Epoch 95/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.0439e-04 - val_loss: 2.0374e-04\n",
      "Epoch 96/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.9643e-04 - val_loss: 2.0040e-04\n",
      "Epoch 97/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.7800e-04 - val_loss: 2.3427e-04\n",
      "Epoch 98/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.7066e-04 - val_loss: 2.4593e-04\n",
      "Epoch 99/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.9278e-04 - val_loss: 2.0314e-04\n",
      "Epoch 100/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.8605e-04 - val_loss: 2.5424e-04\n",
      "Epoch 101/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.7577e-04 - val_loss: 1.9604e-04\n",
      "Epoch 102/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.8049e-04 - val_loss: 2.0779e-04\n",
      "Epoch 103/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.5969e-04 - val_loss: 2.0188e-04\n",
      "Epoch 104/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.5367e-04 - val_loss: 3.0289e-04\n",
      "Epoch 105/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.5406e-04 - val_loss: 1.9702e-04\n",
      "Epoch 106/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.4214e-04 - val_loss: 4.0271e-04\n",
      "Epoch 107/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.6504e-04 - val_loss: 3.3295e-04\n",
      "Epoch 108/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.5475e-04 - val_loss: 1.9249e-04\n",
      "Epoch 109/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.8026e-04 - val_loss: 1.9705e-04\n",
      "Epoch 110/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.2620e-04 - val_loss: 2.0690e-04\n",
      "Epoch 111/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.4798e-04 - val_loss: 2.0672e-04\n",
      "Epoch 112/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.4865e-04 - val_loss: 1.9036e-04\n",
      "Epoch 113/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.3107e-04 - val_loss: 1.8619e-04\n",
      "Epoch 114/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.3007e-04 - val_loss: 2.0010e-04\n",
      "Epoch 115/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.2742e-04 - val_loss: 2.0063e-04\n",
      "Epoch 116/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.8276e-04 - val_loss: 2.0629e-04\n",
      "Epoch 117/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.4607e-04 - val_loss: 2.0375e-04\n",
      "Epoch 118/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.3050e-04 - val_loss: 1.9358e-04\n",
      "Epoch 119/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.1020e-04 - val_loss: 1.8100e-04\n",
      "Epoch 120/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.0496e-04 - val_loss: 2.3643e-04\n",
      "Epoch 121/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.4028e-04 - val_loss: 2.2855e-04\n",
      "Epoch 122/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.1955e-04 - val_loss: 3.2051e-04\n",
      "Epoch 123/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.7326e-04 - val_loss: 2.1038e-04\n",
      "Epoch 124/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.1578e-04 - val_loss: 2.0191e-04\n",
      "Epoch 125/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.2830e-04 - val_loss: 1.9282e-04\n",
      "Epoch 126/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.0565e-04 - val_loss: 1.7681e-04\n",
      "Epoch 127/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.8475e-04 - val_loss: 1.7582e-04\n",
      "Epoch 128/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 5.9610e-04 - val_loss: 1.8812e-04\n",
      "Epoch 129/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.8114e-04 - val_loss: 1.9205e-04\n",
      "Epoch 130/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.8569e-04 - val_loss: 2.1867e-04\n",
      "Epoch 131/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.1929e-04 - val_loss: 1.8689e-04\n",
      "Epoch 132/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.9891e-04 - val_loss: 1.8033e-04\n",
      "Epoch 133/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.8643e-04 - val_loss: 1.7802e-04\n",
      "Epoch 134/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.7695e-04 - val_loss: 2.2521e-04\n",
      "Epoch 135/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.1255e-04 - val_loss: 2.0953e-04\n",
      "Epoch 136/200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 6.2934e-04 - val_loss: 2.1576e-04\n",
      "Epoch 137/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.6894e-04 - val_loss: 1.7041e-04\n",
      "Epoch 138/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.7431e-04 - val_loss: 1.7481e-04\n",
      "Epoch 139/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.9508e-04 - val_loss: 1.7346e-04\n",
      "Epoch 140/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.7352e-04 - val_loss: 1.7474e-04\n",
      "Epoch 141/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.6769e-04 - val_loss: 2.1746e-04\n",
      "Epoch 142/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.7219e-04 - val_loss: 2.0445e-04\n",
      "Epoch 143/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.8736e-04 - val_loss: 2.1146e-04\n",
      "Epoch 144/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.9451e-04 - val_loss: 1.9730e-04\n",
      "Epoch 145/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.3472e-04 - val_loss: 1.8301e-04\n",
      "Epoch 146/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.7117e-04 - val_loss: 1.7120e-04\n",
      "Epoch 147/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.5864e-04 - val_loss: 1.6538e-04\n",
      "Epoch 148/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.5138e-04 - val_loss: 1.8304e-04\n",
      "Epoch 149/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.5200e-04 - val_loss: 1.7641e-04\n",
      "Epoch 150/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.8480e-04 - val_loss: 1.7151e-04\n",
      "Epoch 151/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4908e-04 - val_loss: 1.9237e-04\n",
      "Epoch 152/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.8197e-04 - val_loss: 3.9432e-04\n",
      "Epoch 153/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.8850e-04 - val_loss: 1.7199e-04\n",
      "Epoch 154/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.6002e-04 - val_loss: 1.6315e-04\n",
      "Epoch 155/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.6039e-04 - val_loss: 1.6434e-04\n",
      "Epoch 156/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.0049e-04 - val_loss: 1.6786e-04\n",
      "Epoch 157/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4263e-04 - val_loss: 1.5972e-04\n",
      "Epoch 158/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2556e-04 - val_loss: 1.6419e-04\n",
      "Epoch 159/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.6977e-04 - val_loss: 1.6102e-04\n",
      "Epoch 160/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2780e-04 - val_loss: 2.8613e-04\n",
      "Epoch 161/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.5248e-04 - val_loss: 1.6059e-04\n",
      "Epoch 162/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.6493e-04 - val_loss: 3.1190e-04\n",
      "Epoch 163/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4774e-04 - val_loss: 1.5925e-04\n",
      "Epoch 164/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2004e-04 - val_loss: 1.7324e-04\n",
      "Epoch 165/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.1781e-04 - val_loss: 1.6454e-04\n",
      "Epoch 166/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.3297e-04 - val_loss: 1.8521e-04\n",
      "Epoch 167/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2230e-04 - val_loss: 1.6719e-04\n",
      "Epoch 168/200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.1970e-04 - val_loss: 1.8056e-04\n",
      "Epoch 169/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.1360e-04 - val_loss: 1.5684e-04\n",
      "Epoch 170/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.1469e-04 - val_loss: 1.8098e-04\n",
      "Epoch 171/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2255e-04 - val_loss: 2.4225e-04\n",
      "Epoch 172/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4956e-04 - val_loss: 1.7044e-04\n",
      "Epoch 173/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2592e-04 - val_loss: 1.5441e-04\n",
      "Epoch 174/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4138e-04 - val_loss: 1.5413e-04\n",
      "Epoch 175/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.0979e-04 - val_loss: 1.5770e-04\n",
      "Epoch 176/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.9835e-04 - val_loss: 1.6056e-04\n",
      "Epoch 177/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.1542e-04 - val_loss: 1.5884e-04\n",
      "Epoch 178/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.1037e-04 - val_loss: 1.5228e-04\n",
      "Epoch 179/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.0921e-04 - val_loss: 1.6614e-04\n",
      "Epoch 180/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2620e-04 - val_loss: 1.6030e-04\n",
      "Epoch 181/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.1005e-04 - val_loss: 1.8104e-04\n",
      "Epoch 182/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.1740e-04 - val_loss: 1.6829e-04\n",
      "Epoch 183/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.0270e-04 - val_loss: 1.9789e-04\n",
      "Epoch 184/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.9948e-04 - val_loss: 1.6512e-04\n",
      "Epoch 185/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.1324e-04 - val_loss: 1.5948e-04\n",
      "Epoch 186/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.8750e-04 - val_loss: 3.0141e-04\n",
      "Epoch 187/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4455e-04 - val_loss: 1.8228e-04\n",
      "Epoch 188/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.8510e-04 - val_loss: 1.8702e-04\n",
      "Epoch 189/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.9377e-04 - val_loss: 1.5958e-04\n",
      "Epoch 190/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2268e-04 - val_loss: 1.4903e-04\n",
      "Epoch 191/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.8535e-04 - val_loss: 1.8822e-04\n",
      "Epoch 192/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.0911e-04 - val_loss: 1.5199e-04\n",
      "Epoch 193/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2686e-04 - val_loss: 1.5239e-04\n",
      "Epoch 194/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.8330e-04 - val_loss: 1.6432e-04\n",
      "Epoch 195/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.0374e-04 - val_loss: 2.4835e-04\n",
      "Epoch 196/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.1473e-04 - val_loss: 1.4592e-04\n",
      "Epoch 197/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.8938e-04 - val_loss: 2.0673e-04\n",
      "Epoch 198/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.1931e-04 - val_loss: 1.8976e-04\n",
      "Epoch 199/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.0052e-04 - val_loss: 1.6113e-04\n",
      "Epoch 200/200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.8281e-04 - val_loss: 1.5290e-04\n",
      "Thời gian huấn luyện:  32.557565689086914\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_7 (SimpleRNN)    (None, 10, 108)           11880     \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,961\n",
      "Trainable params: 12,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "38/38 [==============================] - 3s 22ms/step - loss: 0.0404 - val_loss: 0.0014\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 8.8389e-04\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 8.1590e-04\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 7.5941e-04\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 7.6805e-04\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 7.3231e-04\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 7.2078e-04\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 7.1343e-04\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 7.2811e-04\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 7.0523e-04\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 7.4106e-04\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 7.5830e-04\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 6.8909e-04\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 6.8112e-04\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 6.7477e-04\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 6.6894e-04\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 6.6365e-04\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 7.4695e-04\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 6.5952e-04\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 6.5712e-04\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 6.4888e-04\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 6.3550e-04\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 6.4811e-04\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 6.4229e-04\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 6.1577e-04\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 6.0599e-04\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 6.0104e-04\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 5.9407e-04\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 6.1244e-04\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 5.8346e-04\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 6.0231e-04\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 5.7564e-04\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 5.5868e-04\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 5.5188e-04\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 5.4206e-04\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 5.4814e-04\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 5.4330e-04\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 5.2284e-04\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 5.0964e-04\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.0201e-04\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.2480e-04\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 5.2112e-04\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 4.8049e-04\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.7070e-04\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 4.7468e-04\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 4.5553e-04\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.3915e-04\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.2986e-04\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.2696e-04\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.2716e-04\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.0894e-04\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.2444e-04\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.8962e-04\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.1076e-04\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 3.9321e-04\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 6.2995e-04\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.5649e-04\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 3.8463e-04\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 3.7821e-04\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.6976e-04\n",
      "Epoch 61/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.1777e-04\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.6013e-04\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.7416e-04\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 3.6906e-04\n",
      "Epoch 65/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.3385e-04\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.5304e-04\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.7516e-04\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.0648e-04\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 3.3523e-04\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.5350e-04\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.2028e-04\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.2217e-04\n",
      "Epoch 73/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.1741e-04\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.1574e-04\n",
      "Epoch 75/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.4435e-04\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.1353e-04\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 4.3368e-04\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.1471e-04\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.3070e-04\n",
      "Epoch 80/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.1443e-04\n",
      "Epoch 81/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.8753e-04\n",
      "Epoch 82/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.7189e-04\n",
      "Epoch 83/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 3.0299e-04\n",
      "Epoch 84/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.3325e-04\n",
      "Epoch 85/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.5953e-04\n",
      "Epoch 86/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 2.9932e-04\n",
      "Epoch 87/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 3.5116e-04\n",
      "Epoch 88/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 3.1347e-04\n",
      "Epoch 89/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.9297e-04 - val_loss: 3.2763e-04\n",
      "Epoch 90/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.9605e-04 - val_loss: 2.9794e-04\n",
      "Epoch 91/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 3.2906e-04\n",
      "Epoch 92/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.7766e-04 - val_loss: 2.9445e-04\n",
      "Epoch 93/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.1187e-04\n",
      "Epoch 94/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 3.2251e-04\n",
      "Epoch 95/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.8664e-04 - val_loss: 3.1039e-04\n",
      "Epoch 96/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.7682e-04 - val_loss: 2.9357e-04\n",
      "Epoch 97/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.3992e-04\n",
      "Epoch 98/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 4.2960e-04\n",
      "Epoch 99/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 9.8743e-04 - val_loss: 3.6513e-04\n",
      "Epoch 100/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.7271e-04 - val_loss: 2.8899e-04\n",
      "Epoch 101/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.6202e-04 - val_loss: 3.1953e-04\n",
      "Epoch 102/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.6556e-04 - val_loss: 3.1604e-04\n",
      "Epoch 103/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.4990e-04 - val_loss: 3.7319e-04\n",
      "Epoch 104/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.5887e-04 - val_loss: 2.9124e-04\n",
      "Epoch 105/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.8598e-04 - val_loss: 3.3257e-04\n",
      "Epoch 106/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.4174e-04 - val_loss: 3.8482e-04\n",
      "Epoch 107/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.4677e-04 - val_loss: 2.8123e-04\n",
      "Epoch 108/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.3346e-04 - val_loss: 2.8741e-04\n",
      "Epoch 109/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.3610e-04 - val_loss: 2.8249e-04\n",
      "Epoch 110/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.5951e-04 - val_loss: 2.8015e-04\n",
      "Epoch 111/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.8421e-04 - val_loss: 3.1328e-04\n",
      "Epoch 112/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.2381e-04 - val_loss: 3.2130e-04\n",
      "Epoch 113/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.3692e-04 - val_loss: 2.7926e-04\n",
      "Epoch 114/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.2266e-04 - val_loss: 2.8259e-04\n",
      "Epoch 115/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.3323e-04 - val_loss: 2.7784e-04\n",
      "Epoch 116/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.1522e-04 - val_loss: 2.7611e-04\n",
      "Epoch 117/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.0793e-04 - val_loss: 2.7822e-04\n",
      "Epoch 118/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.1881e-04 - val_loss: 2.7569e-04\n",
      "Epoch 119/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.1435e-04 - val_loss: 2.9434e-04\n",
      "Epoch 120/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.1159e-04 - val_loss: 2.8866e-04\n",
      "Epoch 121/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.3986e-04 - val_loss: 2.7079e-04\n",
      "Epoch 122/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.9809e-04 - val_loss: 2.8640e-04\n",
      "Epoch 123/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 8.8717e-04 - val_loss: 3.0024e-04\n",
      "Epoch 124/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.0455e-04 - val_loss: 2.6802e-04\n",
      "Epoch 125/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.0769e-04 - val_loss: 2.7732e-04\n",
      "Epoch 126/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 9.0619e-04 - val_loss: 2.7355e-04\n",
      "Epoch 127/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.9528e-04 - val_loss: 3.9668e-04\n",
      "Epoch 128/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.0370e-04 - val_loss: 2.6780e-04\n",
      "Epoch 129/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.8121e-04 - val_loss: 2.6520e-04\n",
      "Epoch 130/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.8668e-04 - val_loss: 3.3626e-04\n",
      "Epoch 131/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.8076e-04 - val_loss: 3.0776e-04\n",
      "Epoch 132/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 8.6940e-04 - val_loss: 2.8932e-04\n",
      "Epoch 133/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.7847e-04 - val_loss: 2.9808e-04\n",
      "Epoch 134/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.9468e-04 - val_loss: 2.7556e-04\n",
      "Epoch 135/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.7672e-04 - val_loss: 3.2486e-04\n",
      "Epoch 136/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.5826e-04 - val_loss: 2.6027e-04\n",
      "Epoch 137/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.4857e-04 - val_loss: 3.5373e-04\n",
      "Epoch 138/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.8575e-04 - val_loss: 2.7064e-04\n",
      "Epoch 139/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.4951e-04 - val_loss: 3.0116e-04\n",
      "Epoch 140/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.1724e-04 - val_loss: 2.9629e-04\n",
      "Epoch 141/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.8252e-04 - val_loss: 2.6841e-04\n",
      "Epoch 142/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.4705e-04 - val_loss: 2.5671e-04\n",
      "Epoch 143/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.6209e-04 - val_loss: 2.6268e-04\n",
      "Epoch 144/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.4024e-04 - val_loss: 2.5613e-04\n",
      "Epoch 145/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.6231e-04 - val_loss: 2.5809e-04\n",
      "Epoch 146/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.3942e-04 - val_loss: 4.4683e-04\n",
      "Epoch 147/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.8429e-04 - val_loss: 2.7238e-04\n",
      "Epoch 148/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.4249e-04 - val_loss: 2.7068e-04\n",
      "Epoch 149/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.7834e-04 - val_loss: 2.8801e-04\n",
      "Epoch 150/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 8.2427e-04 - val_loss: 2.5286e-04\n",
      "Epoch 151/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.3185e-04 - val_loss: 2.7601e-04\n",
      "Epoch 152/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.1222e-04 - val_loss: 2.6079e-04\n",
      "Epoch 153/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.2876e-04 - val_loss: 2.5007e-04\n",
      "Epoch 154/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.4643e-04 - val_loss: 2.7073e-04\n",
      "Epoch 155/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.3417e-04 - val_loss: 3.2054e-04\n",
      "Epoch 156/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.1638e-04 - val_loss: 2.5533e-04\n",
      "Epoch 157/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.1985e-04 - val_loss: 2.5581e-04\n",
      "Epoch 158/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.2493e-04 - val_loss: 2.6613e-04\n",
      "Epoch 159/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 8.3203e-04 - val_loss: 3.0803e-04\n",
      "Epoch 160/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.9872e-04 - val_loss: 2.4583e-04\n",
      "Epoch 161/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.0141e-04 - val_loss: 2.4583e-04\n",
      "Epoch 162/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.8349e-04 - val_loss: 2.5191e-04\n",
      "Epoch 163/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.9170e-04 - val_loss: 2.7718e-04\n",
      "Epoch 164/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.9636e-04 - val_loss: 2.7019e-04\n",
      "Epoch 165/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.8459e-04 - val_loss: 2.4170e-04\n",
      "Epoch 166/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.7674e-04 - val_loss: 2.7890e-04\n",
      "Epoch 167/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.9490e-04 - val_loss: 2.4189e-04\n",
      "Epoch 168/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.8598e-04 - val_loss: 4.0893e-04\n",
      "Epoch 169/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.8892e-04 - val_loss: 2.4340e-04\n",
      "Epoch 170/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.8065e-04 - val_loss: 2.4001e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.8500e-04 - val_loss: 2.4503e-04\n",
      "Epoch 172/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.7846e-04 - val_loss: 2.5618e-04\n",
      "Epoch 173/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.7033e-04 - val_loss: 2.9401e-04\n",
      "Epoch 174/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.9178e-04 - val_loss: 2.6119e-04\n",
      "Epoch 175/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.6680e-04 - val_loss: 2.6609e-04\n",
      "Epoch 176/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.0881e-04 - val_loss: 2.3807e-04\n",
      "Epoch 177/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 7.9580e-04 - val_loss: 2.3557e-04\n",
      "Epoch 178/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.8725e-04 - val_loss: 2.7395e-04\n",
      "Epoch 179/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.7061e-04 - val_loss: 2.4414e-04\n",
      "Epoch 180/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.5299e-04 - val_loss: 2.6951e-04\n",
      "Epoch 181/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.6470e-04 - val_loss: 2.5822e-04\n",
      "Epoch 182/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.4908e-04 - val_loss: 2.5195e-04\n",
      "Epoch 183/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.4376e-04 - val_loss: 2.4510e-04\n",
      "Epoch 184/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.5445e-04 - val_loss: 2.5470e-04\n",
      "Epoch 185/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.5279e-04 - val_loss: 2.3196e-04\n",
      "Epoch 186/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.4759e-04 - val_loss: 2.5382e-04\n",
      "Epoch 187/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.4655e-04 - val_loss: 2.3095e-04\n",
      "Epoch 188/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 7.2928e-04 - val_loss: 2.2929e-04\n",
      "Epoch 189/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.3432e-04 - val_loss: 2.3152e-04\n",
      "Epoch 190/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.3943e-04 - val_loss: 2.5694e-04\n",
      "Epoch 191/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.4645e-04 - val_loss: 2.3953e-04\n",
      "Epoch 192/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.5501e-04 - val_loss: 2.2941e-04\n",
      "Epoch 193/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.7900e-04 - val_loss: 2.3244e-04\n",
      "Epoch 194/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.7822e-04 - val_loss: 2.7725e-04\n",
      "Epoch 195/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.1654e-04 - val_loss: 2.4467e-04\n",
      "Epoch 196/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.3741e-04 - val_loss: 2.6299e-04\n",
      "Epoch 197/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.2115e-04 - val_loss: 2.2521e-04\n",
      "Epoch 198/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.2726e-04 - val_loss: 2.2820e-04\n",
      "Epoch 199/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.0730e-04 - val_loss: 2.6015e-04\n",
      "Epoch 200/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.0870e-04 - val_loss: 2.2276e-04\n",
      "Thời gian huấn luyện:  77.09855127334595\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 10, 108)           47520     \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,601\n",
      "Trainable params: 48,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "38/38 [==============================] - 2s 21ms/step - loss: 0.0353 - val_loss: 0.0012\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 8.4728e-04\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 7.7879e-04\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 7.2619e-04\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 6.7647e-04\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 6.4199e-04\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.2373e-04\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 6.0639e-04\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 5.9489e-04\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 5.8717e-04\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 6.3542e-04\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 5.6780e-04\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 5.8140e-04\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 5.5874e-04\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 5.5628e-04\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 5.8013e-04\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 5.2500e-04\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 5.1350e-04\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.0833e-04\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 5.1977e-04\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 5.0197e-04\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 4.7834e-04\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 4.7538e-04\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 4.8817e-04\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.6565e-04\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 5.5422e-04\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 4.3303e-04\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 4.2357e-04\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.3798e-04\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.2061e-04\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 4.0790e-04\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.1957e-04\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 3.8245e-04\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.7659e-04\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 3.6930e-04\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 3.7949e-04\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.9605e-04\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.4616e-04\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.4152e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.7003e-04\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.6499e-04\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 3.1838e-04\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.2000e-04\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 3.0697e-04\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.3489e-04\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.9076e-04 - val_loss: 2.9555e-04\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 2.9322e-04\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.8662e-04\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.6371e-04 - val_loss: 2.8423e-04\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.8025e-04 - val_loss: 3.2641e-04\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.3658e-04 - val_loss: 3.0632e-04\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.3736e-04 - val_loss: 2.7540e-04\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.3997e-04 - val_loss: 2.7273e-04\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.2584e-04 - val_loss: 3.6650e-04\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.2300e-04 - val_loss: 2.7373e-04\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.2501e-04 - val_loss: 3.0298e-04\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.5057e-04 - val_loss: 4.0478e-04\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.9654e-04 - val_loss: 2.8402e-04\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.8505e-04 - val_loss: 2.5969e-04\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 9.0903e-04 - val_loss: 2.5564e-04\n",
      "Epoch 61/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.7329e-04 - val_loss: 2.6912e-04\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.7207e-04 - val_loss: 2.6627e-04\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.6789e-04 - val_loss: 2.8610e-04\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.5589e-04 - val_loss: 2.4959e-04\n",
      "Epoch 65/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.5197e-04 - val_loss: 2.6330e-04\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.4424e-04 - val_loss: 2.5097e-04\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.4455e-04 - val_loss: 2.4913e-04\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.4493e-04 - val_loss: 2.5628e-04\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 8.3406e-04 - val_loss: 2.5744e-04\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.3954e-04 - val_loss: 3.0325e-04\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.3661e-04 - val_loss: 3.0186e-04\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.3142e-04 - val_loss: 2.3784e-04\n",
      "Epoch 73/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.1113e-04 - val_loss: 3.6767e-04\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.2830e-04 - val_loss: 3.1820e-04\n",
      "Epoch 75/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.3189e-04 - val_loss: 2.3470e-04\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 8.1256e-04 - val_loss: 2.6919e-04\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.0672e-04 - val_loss: 2.3207e-04\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.9615e-04 - val_loss: 2.3226e-04\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.8858e-04 - val_loss: 2.5393e-04\n",
      "Epoch 80/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.8313e-04 - val_loss: 2.3504e-04\n",
      "Epoch 81/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.8022e-04 - val_loss: 3.1522e-04\n",
      "Epoch 82/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.7233e-04 - val_loss: 3.1360e-04\n",
      "Epoch 83/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.8646e-04 - val_loss: 2.9801e-04\n",
      "Epoch 84/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.9095e-04 - val_loss: 2.7141e-04\n",
      "Epoch 85/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.6752e-04 - val_loss: 3.1251e-04\n",
      "Epoch 86/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.6021e-04 - val_loss: 2.2133e-04\n",
      "Epoch 87/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.6472e-04 - val_loss: 2.6236e-04\n",
      "Epoch 88/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.6059e-04 - val_loss: 2.8223e-04\n",
      "Epoch 89/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.6439e-04 - val_loss: 2.4394e-04\n",
      "Epoch 90/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.4467e-04 - val_loss: 2.7103e-04\n",
      "Epoch 91/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.6847e-04 - val_loss: 2.6354e-04\n",
      "Epoch 92/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.4223e-04 - val_loss: 2.9375e-04\n",
      "Epoch 93/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.2802e-04 - val_loss: 2.2642e-04\n",
      "Epoch 94/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.3472e-04 - val_loss: 2.8061e-04\n",
      "Epoch 95/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.3462e-04 - val_loss: 2.4444e-04\n",
      "Epoch 96/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 7.4424e-04 - val_loss: 2.1285e-04\n",
      "Epoch 97/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.0914e-04 - val_loss: 2.9068e-04\n",
      "Epoch 98/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.2556e-04 - val_loss: 2.2698e-04\n",
      "Epoch 99/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.2577e-04 - val_loss: 2.1284e-04\n",
      "Epoch 100/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.0571e-04 - val_loss: 2.2375e-04\n",
      "Epoch 101/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.0764e-04 - val_loss: 2.8104e-04\n",
      "Epoch 102/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.1473e-04 - val_loss: 2.6356e-04\n",
      "Epoch 103/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.0625e-04 - val_loss: 3.4437e-04\n",
      "Epoch 104/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.3762e-04 - val_loss: 2.2790e-04\n",
      "Epoch 105/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.6848e-04 - val_loss: 2.0826e-04\n",
      "Epoch 106/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 7.1663e-04 - val_loss: 2.2306e-04\n",
      "Epoch 107/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 6.8844e-04 - val_loss: 2.0368e-04\n",
      "Epoch 108/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 7.0047e-04 - val_loss: 2.7510e-04\n",
      "Epoch 109/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.9167e-04 - val_loss: 2.9027e-04\n",
      "Epoch 110/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.8690e-04 - val_loss: 2.1115e-04\n",
      "Epoch 111/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.7587e-04 - val_loss: 2.4609e-04\n",
      "Epoch 112/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.6949e-04 - val_loss: 2.5099e-04\n",
      "Epoch 113/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.5706e-04 - val_loss: 1.9898e-04\n",
      "Epoch 114/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.5710e-04 - val_loss: 2.0572e-04\n",
      "Epoch 115/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.5806e-04 - val_loss: 2.1952e-04\n",
      "Epoch 116/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 6.6201e-04 - val_loss: 1.9738e-04\n",
      "Epoch 117/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.6312e-04 - val_loss: 2.2048e-04\n",
      "Epoch 118/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.6280e-04 - val_loss: 1.9522e-04\n",
      "Epoch 119/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.6115e-04 - val_loss: 1.9801e-04\n",
      "Epoch 120/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.5222e-04 - val_loss: 2.0189e-04\n",
      "Epoch 121/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.4787e-04 - val_loss: 2.0622e-04\n",
      "Epoch 122/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.3472e-04 - val_loss: 1.9448e-04\n",
      "Epoch 123/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 6.4442e-04 - val_loss: 1.9754e-04\n",
      "Epoch 124/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.4440e-04 - val_loss: 2.9285e-04\n",
      "Epoch 125/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.4854e-04 - val_loss: 1.9026e-04\n",
      "Epoch 126/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.3821e-04 - val_loss: 1.8973e-04\n",
      "Epoch 127/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.3635e-04 - val_loss: 2.0002e-04\n",
      "Epoch 128/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.2353e-04 - val_loss: 1.9112e-04\n",
      "Epoch 129/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.3842e-04 - val_loss: 1.9477e-04\n",
      "Epoch 130/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.4346e-04 - val_loss: 2.0095e-04\n",
      "Epoch 131/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.2541e-04 - val_loss: 1.9809e-04\n",
      "Epoch 132/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 6.1483e-04 - val_loss: 1.8759e-04\n",
      "Epoch 133/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.2293e-04 - val_loss: 2.3592e-04\n",
      "Epoch 134/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.2197e-04 - val_loss: 1.8496e-04\n",
      "Epoch 135/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.1358e-04 - val_loss: 2.0538e-04\n",
      "Epoch 136/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.1036e-04 - val_loss: 1.8877e-04\n",
      "Epoch 137/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.9902e-04 - val_loss: 1.9081e-04\n",
      "Epoch 138/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 6.0212e-04 - val_loss: 1.9952e-04\n",
      "Epoch 139/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.1582e-04 - val_loss: 1.8802e-04\n",
      "Epoch 140/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.1684e-04 - val_loss: 1.9791e-04\n",
      "Epoch 141/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.0893e-04 - val_loss: 2.1731e-04\n",
      "Epoch 142/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.2148e-04 - val_loss: 1.8151e-04\n",
      "Epoch 143/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.9272e-04 - val_loss: 1.7899e-04\n",
      "Epoch 144/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.9333e-04 - val_loss: 2.5627e-04\n",
      "Epoch 145/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.9852e-04 - val_loss: 1.9564e-04\n",
      "Epoch 146/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.9624e-04 - val_loss: 1.9342e-04\n",
      "Epoch 147/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.2507e-04 - val_loss: 1.7799e-04\n",
      "Epoch 148/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.7581e-04 - val_loss: 2.0134e-04\n",
      "Epoch 149/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.7154e-04 - val_loss: 1.7599e-04\n",
      "Epoch 150/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 5.7351e-04 - val_loss: 2.0587e-04\n",
      "Epoch 151/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.8886e-04 - val_loss: 1.9201e-04\n",
      "Epoch 152/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.9312e-04 - val_loss: 1.8390e-04\n",
      "Epoch 153/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.7717e-04 - val_loss: 2.1705e-04\n",
      "Epoch 154/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.7320e-04 - val_loss: 1.7205e-04\n",
      "Epoch 155/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.6648e-04 - val_loss: 1.7236e-04\n",
      "Epoch 156/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.7633e-04 - val_loss: 1.7182e-04\n",
      "Epoch 157/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.6563e-04 - val_loss: 2.2664e-04\n",
      "Epoch 158/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.6875e-04 - val_loss: 1.8170e-04\n",
      "Epoch 159/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.6203e-04 - val_loss: 1.7016e-04\n",
      "Epoch 160/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.7045e-04 - val_loss: 1.8410e-04\n",
      "Epoch 161/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 5.4910e-04 - val_loss: 1.7143e-04\n",
      "Epoch 162/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.5747e-04 - val_loss: 1.7107e-04\n",
      "Epoch 163/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.5692e-04 - val_loss: 2.1139e-04\n",
      "Epoch 164/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 6.3093e-04 - val_loss: 2.2812e-04\n",
      "Epoch 165/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.8454e-04 - val_loss: 1.9337e-04\n",
      "Epoch 166/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.4589e-04 - val_loss: 1.7807e-04\n",
      "Epoch 167/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.4143e-04 - val_loss: 1.7174e-04\n",
      "Epoch 168/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 5.9998e-04 - val_loss: 2.4745e-04\n",
      "Epoch 169/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.6406e-04 - val_loss: 1.7041e-04\n",
      "Epoch 170/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.5617e-04 - val_loss: 1.6504e-04\n",
      "Epoch 171/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.7881e-04 - val_loss: 2.1383e-04\n",
      "Epoch 172/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.3860e-04 - val_loss: 1.8896e-04\n",
      "Epoch 173/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.3948e-04 - val_loss: 1.8418e-04\n",
      "Epoch 174/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.3181e-04 - val_loss: 1.6327e-04\n",
      "Epoch 175/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.3722e-04 - val_loss: 2.1718e-04\n",
      "Epoch 176/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.4600e-04 - val_loss: 2.1249e-04\n",
      "Epoch 177/200\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 5.3489e-04 - val_loss: 1.8109e-04\n",
      "Epoch 178/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.3473e-04 - val_loss: 1.6954e-04\n",
      "Epoch 179/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.2539e-04 - val_loss: 1.8838e-04\n",
      "Epoch 180/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.4664e-04 - val_loss: 2.2152e-04\n",
      "Epoch 181/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.4671e-04 - val_loss: 1.6959e-04\n",
      "Epoch 182/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.2620e-04 - val_loss: 1.8645e-04\n",
      "Epoch 183/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.3492e-04 - val_loss: 1.6113e-04\n",
      "Epoch 184/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.2302e-04 - val_loss: 1.6077e-04\n",
      "Epoch 185/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.1830e-04 - val_loss: 1.6061e-04\n",
      "Epoch 186/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.1816e-04 - val_loss: 1.8129e-04\n",
      "Epoch 187/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.1950e-04 - val_loss: 1.6269e-04\n",
      "Epoch 188/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.1188e-04 - val_loss: 1.5727e-04\n",
      "Epoch 189/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.1631e-04 - val_loss: 1.6885e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.2468e-04 - val_loss: 1.5674e-04\n",
      "Epoch 191/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.2030e-04 - val_loss: 1.6296e-04\n",
      "Epoch 192/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.1213e-04 - val_loss: 1.6660e-04\n",
      "Epoch 193/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.2481e-04 - val_loss: 1.5925e-04\n",
      "Epoch 194/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.1742e-04 - val_loss: 1.5772e-04\n",
      "Epoch 195/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.0916e-04 - val_loss: 1.6115e-04\n",
      "Epoch 196/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.0475e-04 - val_loss: 1.6755e-04\n",
      "Epoch 197/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.2327e-04 - val_loss: 1.5592e-04\n",
      "Epoch 198/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.4039e-04 - val_loss: 1.6224e-04\n",
      "Epoch 199/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.1108e-04 - val_loss: 1.6987e-04\n",
      "Epoch 200/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 5.2441e-04 - val_loss: 1.9552e-04\n",
      "Thời gian huấn luyện:  76.03443431854248\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_7 (GRU)                 (None, 10, 108)           35964     \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,045\n",
      "Trainable params: 37,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "44/44 [==============================] - 1s 4ms/step\n",
      "30/30 [==============================] - 0s 4ms/step\n",
      "44/44 [==============================] - 1s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 6ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Thời gian huấn luyện:  18.633789539337158\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 10, 108)           216       \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,297\n",
      "Trainable params: 1,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 11ms/step - loss: 0.0443 - val_loss: 0.0015\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 9.2218e-04\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 8.8990e-04\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 7.1665e-04\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 8.1321e-04\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 7.2533e-04\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 5.7906e-04\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 6.1193e-04\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 6.1880e-04\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 4.8894e-04\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 4.9625e-04\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 4.7176e-04\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 4.9681e-04\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.1653e-04\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.1859e-04\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 4.0170e-04\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 3.9634e-04\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.9935e-04\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 3.8301e-04\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.6629e-04\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.7635e-04\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.4779e-04\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 3.6787e-04\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.8862e-04\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.9933e-04\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.8945e-04\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.5984e-04\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 3.4063e-04\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 4.7557e-04\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 4.2087e-04\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8917e-04 - val_loss: 3.7325e-04\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 9.9145e-04 - val_loss: 3.1815e-04\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 3.4152e-04\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.6793e-04 - val_loss: 4.3662e-04\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.5556e-04 - val_loss: 3.2093e-04\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8380e-04 - val_loss: 3.1755e-04\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.5495e-04 - val_loss: 3.2176e-04\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.7052e-04 - val_loss: 3.1198e-04\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.2646e-04 - val_loss: 3.0954e-04\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.1747e-04 - val_loss: 3.5341e-04\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.3994e-04 - val_loss: 3.7111e-04\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.2944e-04 - val_loss: 3.0882e-04\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 9.4224e-04 - val_loss: 2.9467e-04\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.9915e-04 - val_loss: 3.2416e-04\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.0222e-04 - val_loss: 3.1183e-04\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.7776e-04 - val_loss: 3.3855e-04\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.3441e-04 - val_loss: 3.0045e-04\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.2150e-04 - val_loss: 3.5436e-04\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 9.1173e-04 - val_loss: 2.8444e-04\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.6486e-04 - val_loss: 3.2473e-04\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.7152e-04 - val_loss: 2.9780e-04\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.9784e-04 - val_loss: 2.8673e-04\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.7365e-04 - val_loss: 3.4152e-04\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.5975e-04 - val_loss: 3.0938e-04\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.2968e-04 - val_loss: 3.0196e-04\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.3405e-04 - val_loss: 2.7846e-04\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.3815e-04 - val_loss: 3.3362e-04\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.2866e-04 - val_loss: 3.0830e-04\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.3261e-04 - val_loss: 2.7157e-04\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.4108e-04 - val_loss: 2.6764e-04\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.3722e-04 - val_loss: 3.4249e-04\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.4825e-04 - val_loss: 3.3135e-04\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.2845e-04 - val_loss: 3.1913e-04\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.2114e-04 - val_loss: 2.8850e-04\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.7264e-04 - val_loss: 3.6226e-04\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.3162e-04 - val_loss: 2.8594e-04\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.9269e-04 - val_loss: 3.0603e-04\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.1352e-04 - val_loss: 2.6669e-04\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.3134e-04 - val_loss: 2.5704e-04\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.2222e-04 - val_loss: 3.1853e-04\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.7193e-04 - val_loss: 3.7978e-04\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.9583e-04 - val_loss: 2.5505e-04\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.9341e-04 - val_loss: 2.5406e-04\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.3097e-04 - val_loss: 4.7771e-04\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.6547e-04 - val_loss: 3.9727e-04\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.1396e-04 - val_loss: 4.2106e-04\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 8.1887e-04 - val_loss: 2.6437e-04\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.0813e-04 - val_loss: 2.8663e-04\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.4445e-04 - val_loss: 3.1219e-04\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.7286e-04 - val_loss: 2.9410e-04\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.8869e-04 - val_loss: 2.5172e-04\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.3401e-04 - val_loss: 2.9266e-04\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.4698e-04 - val_loss: 2.8889e-04\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.7339e-04 - val_loss: 2.7007e-04\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.9688e-04 - val_loss: 3.1290e-04\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.4785e-04 - val_loss: 2.5329e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.5284e-04 - val_loss: 2.4376e-04\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.3088e-04 - val_loss: 2.3812e-04\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.2247e-04 - val_loss: 4.2374e-04\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 8.0950e-04 - val_loss: 2.4631e-04\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.2619e-04 - val_loss: 2.7244e-04\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.0801e-04 - val_loss: 2.3781e-04\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.0451e-04 - val_loss: 2.3218e-04\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.2198e-04 - val_loss: 2.3691e-04\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.2032e-04 - val_loss: 2.4136e-04\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 7.0634e-04 - val_loss: 2.8004e-04\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.9245e-04 - val_loss: 2.3116e-04\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.1088e-04 - val_loss: 2.6660e-04\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.9672e-04 - val_loss: 2.2857e-04\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.9562e-04 - val_loss: 2.2655e-04\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.7337e-04 - val_loss: 2.9435e-04\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.3474e-04 - val_loss: 2.3084e-04\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.7770e-04 - val_loss: 3.4967e-04\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.3159e-04 - val_loss: 2.3327e-04\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.9127e-04 - val_loss: 2.7862e-04\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.1043e-04 - val_loss: 2.2171e-04\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.6725e-04 - val_loss: 2.2871e-04\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.5845e-04 - val_loss: 2.1999e-04\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.5972e-04 - val_loss: 2.6897e-04\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.6991e-04 - val_loss: 3.1923e-04\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 7.1191e-04 - val_loss: 4.2674e-04\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.8837e-04 - val_loss: 2.2725e-04\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.5115e-04 - val_loss: 2.4487e-04\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.4520e-04 - val_loss: 2.1700e-04\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.4527e-04 - val_loss: 2.8022e-04\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.4578e-04 - val_loss: 3.1382e-04\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.5444e-04 - val_loss: 2.3846e-04\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.6334e-04 - val_loss: 2.8400e-04\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.3980e-04 - val_loss: 2.4137e-04\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.4541e-04 - val_loss: 2.4355e-04\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.3504e-04 - val_loss: 2.1241e-04\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.9585e-04 - val_loss: 2.5564e-04\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.9130e-04 - val_loss: 4.2393e-04\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.6262e-04 - val_loss: 2.4611e-04\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1892e-04 - val_loss: 2.3583e-04\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.3158e-04 - val_loss: 2.1704e-04\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.2210e-04 - val_loss: 2.1464e-04\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1042e-04 - val_loss: 2.0634e-04\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.3846e-04 - val_loss: 2.0842e-04\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.2646e-04 - val_loss: 2.3829e-04\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.5707e-04 - val_loss: 2.3211e-04\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.4233e-04 - val_loss: 2.0746e-04\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1957e-04 - val_loss: 2.1307e-04\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1269e-04 - val_loss: 2.0468e-04\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.0869e-04 - val_loss: 2.0382e-04\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.5718e-04 - val_loss: 2.4546e-04\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.0839e-04 - val_loss: 2.2610e-04\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1389e-04 - val_loss: 2.5675e-04\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.2155e-04 - val_loss: 2.6709e-04\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.0934e-04 - val_loss: 1.9870e-04\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.0082e-04 - val_loss: 2.2341e-04\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.0960e-04 - val_loss: 2.3250e-04\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8627e-04 - val_loss: 1.9745e-04\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7881e-04 - val_loss: 2.8115e-04\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8259e-04 - val_loss: 2.0721e-04\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.0579e-04 - val_loss: 2.1951e-04\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7060e-04 - val_loss: 2.0039e-04\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 5.6959e-04 - val_loss: 1.9669e-04\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7718e-04 - val_loss: 3.2450e-04\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.9218e-04 - val_loss: 1.9807e-04\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7052e-04 - val_loss: 1.9428e-04\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5786e-04 - val_loss: 1.9927e-04\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7489e-04 - val_loss: 1.9252e-04\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.7155e-04 - val_loss: 3.6284e-04\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.7137e-04 - val_loss: 2.0875e-04\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 6.0521e-04 - val_loss: 1.9395e-04\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7574e-04 - val_loss: 2.1826e-04\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.8815e-04 - val_loss: 2.1294e-04\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5504e-04 - val_loss: 2.0840e-04\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5549e-04 - val_loss: 2.3175e-04\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.4750e-04 - val_loss: 2.6289e-04\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7883e-04 - val_loss: 1.9238e-04\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4913e-04 - val_loss: 1.8950e-04\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4216e-04 - val_loss: 1.9378e-04\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.6399e-04 - val_loss: 1.8680e-04\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1181e-04 - val_loss: 1.8645e-04\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5955e-04 - val_loss: 1.8669e-04\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.3612e-04 - val_loss: 1.8735e-04\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5240e-04 - val_loss: 1.9440e-04\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4702e-04 - val_loss: 1.8501e-04\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5284e-04 - val_loss: 2.9616e-04\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5212e-04 - val_loss: 2.0216e-04\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4542e-04 - val_loss: 1.9063e-04\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5248e-04 - val_loss: 2.2280e-04\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5195e-04 - val_loss: 1.9766e-04\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4938e-04 - val_loss: 2.2894e-04\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4112e-04 - val_loss: 1.8602e-04\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4808e-04 - val_loss: 1.8225e-04\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5925e-04 - val_loss: 2.1657e-04\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.2299e-04 - val_loss: 2.3178e-04\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.5488e-04 - val_loss: 1.8974e-04\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1501e-04 - val_loss: 2.5232e-04\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4233e-04 - val_loss: 2.3153e-04\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2727e-04 - val_loss: 2.0576e-04\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2405e-04 - val_loss: 2.5762e-04\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.7169e-04 - val_loss: 6.9484e-04\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 6.1722e-04 - val_loss: 1.9186e-04\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.5849e-04 - val_loss: 1.7962e-04\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2481e-04 - val_loss: 1.8026e-04\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4071e-04 - val_loss: 2.2048e-04\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.6214e-04 - val_loss: 2.1911e-04\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1917e-04 - val_loss: 2.1284e-04\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2027e-04 - val_loss: 1.7869e-04\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2151e-04 - val_loss: 1.8741e-04\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4428e-04 - val_loss: 1.8389e-04\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.4891e-04 - val_loss: 2.5601e-04\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.1092e-04 - val_loss: 1.7663e-04\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.2036e-04 - val_loss: 2.9057e-04\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 5.6623e-04 - val_loss: 2.2526e-04\n",
      "Thời gian huấn luyện:  33.05959463119507\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_8 (SimpleRNN)    (None, 10, 108)           11880     \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,961\n",
      "Trainable params: 12,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 2s 26ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Thời gian huấn luyện:  72.88359904289246\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 10, 108)           47520     \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,601\n",
      "Trainable params: 48,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 4s 26ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1756\n",
      "Thời gian huấn luyện:  70.11777544021606\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_8 (GRU)                 (None, 10, 108)           35964     \n",
      "                                                                 \n",
      " flatten_35 (Flatten)        (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,045\n",
      "Trainable params: 37,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "44/44 [==============================] - 0s 946us/step\n",
      "30/30 [==============================] - 0s 865us/step\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "44/44 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "44/44 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0972 - val_loss: 0.0308\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0201\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0182\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0141\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0112\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0084\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0064\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.8214e-04\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.8766e-04\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.5884e-04\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 9.7768e-04\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Thời gian huấn luyện:  4.910778999328613\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0023\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 9.0389e-04\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 9.1303e-04\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 8.1879e-04\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 7.4684e-04\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 8.0533e-04\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 7.4823e-04\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.8240e-04\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 7.2012e-04\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 6.9772e-04\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.7257e-04 - val_loss: 7.0204e-04\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.8229e-04 - val_loss: 6.5973e-04\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.3629e-04\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 9.8438e-04 - val_loss: 8.1312e-04\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 6.1140e-04\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.3618e-04 - val_loss: 8.7501e-04\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.7449e-04 - val_loss: 7.0309e-04\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.9872e-04 - val_loss: 5.9388e-04\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.0439e-04 - val_loss: 6.6817e-04\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 8.4981e-04 - val_loss: 6.4052e-04\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.3275e-04 - val_loss: 6.4473e-04\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.4919e-04 - val_loss: 6.1880e-04\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.1009e-04 - val_loss: 7.1406e-04\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.3000e-04 - val_loss: 5.7457e-04\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 8.1287e-04 - val_loss: 7.1656e-04\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.7305e-04 - val_loss: 5.9596e-04\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.7635e-04 - val_loss: 6.3001e-04\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.6996e-04 - val_loss: 5.2001e-04\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.1296e-04 - val_loss: 5.7381e-04\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.6123e-04 - val_loss: 5.8458e-04\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.5176e-04 - val_loss: 5.8280e-04\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.3884e-04 - val_loss: 5.5653e-04\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.3624e-04 - val_loss: 5.7188e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 7.5671e-04 - val_loss: 5.1119e-04\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.1789e-04 - val_loss: 7.1171e-04\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.9459e-04 - val_loss: 5.6281e-04\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.2297e-04 - val_loss: 5.1608e-04\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.0587e-04 - val_loss: 4.9551e-04\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.1412e-04 - val_loss: 5.4841e-04\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.8465e-04 - val_loss: 5.4974e-04\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.8865e-04 - val_loss: 5.0141e-04\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.8470e-04 - val_loss: 5.2294e-04\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.7284e-04 - val_loss: 4.5053e-04\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.9483e-04 - val_loss: 4.5733e-04\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.1078e-04 - val_loss: 5.0025e-04\n",
      "Thời gian huấn luyện:  9.7267324924469\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_9 (SimpleRNN)    (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 3s 18ms/step - loss: 0.0251 - val_loss: 0.0037\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 9.8197e-04\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 9.6470e-04\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 9.6478e-04\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 8.7382e-04\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 8.2861e-04\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 9.3659e-04\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 8.5160e-04\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.2628e-04\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 9.3756e-04\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 8.1546e-04\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.8605e-04\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.3408e-04\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 8.6205e-04\n",
      "Thời gian huấn luyện:  22.844000339508057\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 3s 16ms/step - loss: 0.0256 - val_loss: 0.0041\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 9.8238e-04\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 9.2353e-04\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 9.5875e-04\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 9.2468e-04\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 9.4463e-04\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 9.6390e-04\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.9055e-04\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.6005e-04\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 9.7070e-04\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 8.7806e-04\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 8.2485e-04\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 8.2026e-04\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 8.4172e-04\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 8.5278e-04\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.7011e-04\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 7.5457e-04\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.0617e-04\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 7.6565e-04\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 7.3477e-04\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 9.8070e-04 - val_loss: 7.3169e-04\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 9.5795e-04 - val_loss: 6.8831e-04\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 9.6802e-04 - val_loss: 6.9850e-04\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 9.2209e-04 - val_loss: 7.2922e-04\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 9.2987e-04 - val_loss: 7.0878e-04\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 9.0785e-04 - val_loss: 7.0063e-04\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 9.3556e-04 - val_loss: 6.6372e-04\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 8.8233e-04 - val_loss: 6.8959e-04\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 8.7100e-04 - val_loss: 6.5965e-04\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.6051e-04 - val_loss: 6.7693e-04\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.4727e-04 - val_loss: 6.8188e-04\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 8.4025e-04 - val_loss: 6.2376e-04\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.3907e-04 - val_loss: 6.4062e-04\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.2084e-04 - val_loss: 6.3311e-04\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.1288e-04 - val_loss: 6.9488e-04\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.3742e-04 - val_loss: 6.6926e-04\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.0934e-04 - val_loss: 6.6957e-04\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.8765e-04 - val_loss: 6.3207e-04\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.8213e-04 - val_loss: 6.2929e-04\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.8211e-04 - val_loss: 6.1970e-04\n",
      "Thời gian huấn luyện:  20.54366970062256\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_9 (GRU)                 (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 1s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 1s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 0.0902 - val_loss: 0.0266\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0161\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0138\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0107\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0082\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0065\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 9.8544e-04\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 9.8935e-04\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.9335e-04\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.6179e-04\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 9.8331e-04\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.2919e-04\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.6324e-04\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.6065e-04\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.3550e-04\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.3079e-04\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.2342e-04\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.9737e-04\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.9782e-04\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.4150e-04\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.2076e-04\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.4116e-04\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.2355e-04\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.3848e-04\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.1924e-04\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.1594e-04\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 8.4791e-04\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 8.0307e-04\n",
      "Thời gian huấn luyện:  5.551271438598633\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 10ms/step - loss: 0.0374 - val_loss: 0.0013\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 9.7166e-04\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 9.1443e-04\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 8.6779e-04\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 8.3231e-04\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 8.0049e-04\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 7.7291e-04\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 9.3321e-04\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 7.4030e-04\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 7.3747e-04\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 6.8300e-04\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.8716e-04\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.7327e-04\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.3855e-04\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.5990e-04\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.3268e-04\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 6.0843e-04\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 6.4022e-04\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 6.0830e-04\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.8026e-04 - val_loss: 5.9693e-04\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.7108e-04 - val_loss: 5.8568e-04\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 5.7434e-04\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 9.6171e-04 - val_loss: 5.9988e-04\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.4437e-04 - val_loss: 5.9498e-04\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.1874e-04 - val_loss: 5.7100e-04\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 9.0901e-04 - val_loss: 5.7489e-04\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.0652e-04 - val_loss: 5.7943e-04\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.9173e-04 - val_loss: 6.4411e-04\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.6697e-04 - val_loss: 7.2499e-04\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.0364e-04 - val_loss: 5.8018e-04\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.9718e-04 - val_loss: 6.9188e-04\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.1477e-04 - val_loss: 5.7339e-04\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.6855e-04 - val_loss: 5.2869e-04\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.6537e-04 - val_loss: 5.3351e-04\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 4ms/step - loss: 8.5794e-04 - val_loss: 5.5206e-04\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.5508e-04 - val_loss: 5.2360e-04\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.3658e-04 - val_loss: 5.6009e-04\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.2706e-04 - val_loss: 4.9878e-04\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.5543e-04 - val_loss: 5.0440e-04\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 8.1639e-04 - val_loss: 5.4314e-04\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 8.9984e-04 - val_loss: 6.5087e-04\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.1480e-04 - val_loss: 4.9577e-04\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.9906e-04 - val_loss: 4.8022e-04\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.3451e-04 - val_loss: 5.0378e-04\n",
      "Thời gian huấn luyện:  10.543816566467285\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_10 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 3s 22ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Thời gian huấn luyện:  25.18368434906006\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_42 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 3s 24ms/step - loss: 0.0322 - val_loss: 0.0026\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 9.7391e-04\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 9.2006e-04\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 9.3218e-04\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 9.3690e-04\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 8.8081e-04\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 9.2030e-04\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 8.8130e-04\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 8.2773e-04\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 8.4655e-04\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 7.9155e-04\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 7.8733e-04\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 7.5379e-04\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 7.6149e-04\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 8.2195e-04\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 7.5944e-04\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 7.3437e-04\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 7.9717e-04\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 7.2406e-04\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.9642e-04\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 6.4974e-04\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.7946e-04\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.8782e-04\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.7371e-04\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 0.0010 - val_loss: 6.2514e-04\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 6.3986e-04\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 9.9907e-04 - val_loss: 5.9451e-04\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.7986e-04 - val_loss: 6.6996e-04\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 9.5550e-04 - val_loss: 6.8376e-04\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.3064e-04 - val_loss: 6.3125e-04\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 9.2249e-04 - val_loss: 6.2848e-04\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 9.1594e-04 - val_loss: 6.3470e-04\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.0095e-04 - val_loss: 6.2120e-04\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.9169e-04 - val_loss: 5.5817e-04\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.8619e-04 - val_loss: 6.1187e-04\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.6722e-04 - val_loss: 5.6866e-04\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.3984e-04 - val_loss: 5.6580e-04\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.3899e-04 - val_loss: 5.4078e-04\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.3198e-04 - val_loss: 5.2772e-04\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.1115e-04 - val_loss: 5.6411e-04\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.9694e-04 - val_loss: 5.3434e-04\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.9709e-04 - val_loss: 5.3118e-04\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.8981e-04 - val_loss: 5.1585e-04\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.7437e-04 - val_loss: 5.3165e-04\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.9343e-04 - val_loss: 5.0475e-04\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.6759e-04 - val_loss: 5.0731e-04\n",
      "Thời gian huấn luyện:  23.9672691822052\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_10 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_43 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 967us/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 1s 4ms/step\n",
      "22/22 [==============================] - 0s 5ms/step\n",
      "52/52 [==============================] - 1s 5ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 6ms/step - loss: 0.0734 - val_loss: 0.0257\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0121\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0096\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0083\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 9.6252e-04\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 8.7279e-04\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 8.5510e-04\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 8.3568e-04\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 8.0994e-04\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.9135e-04\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.7298e-04\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.7411e-04\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.8197e-04\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.8395e-04\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.1828e-04\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.8770e-04\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.3729e-04\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.0711e-04\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.6615e-04\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.7776e-04\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.1666e-04\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.4856e-04\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8733e-04\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.7974e-04\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.7172e-04\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.0630e-04\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.5632e-04\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8946e-04\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.4162e-04\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.8553e-04\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.7898e-04\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.0061e-04\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.3289e-04\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.3446e-04\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.1748e-04\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.0252e-04\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.1822e-04\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.4243e-04\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2642e-04\n",
      "Thời gian huấn luyện:  5.287541627883911\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_55 (Dense)            (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_44 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 10ms/step - loss: 0.0155 - val_loss: 0.0025\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 9.7247e-04\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 8.2370e-04\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 8.0485e-04\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 6.9802e-04\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 6.9140e-04\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 7.0974e-04\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 6.9164e-04\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 6.3879e-04\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.1461e-04\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 5.1323e-04\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 5.4334e-04\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 4.9795e-04\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.9426e-04 - val_loss: 5.7981e-04\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.9318e-04 - val_loss: 4.6063e-04\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 5.3178e-04\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.5618e-04 - val_loss: 5.5921e-04\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 9.1277e-04 - val_loss: 5.1377e-04\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.2781e-04 - val_loss: 4.8473e-04\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.8021e-04 - val_loss: 4.2890e-04\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.6345e-04 - val_loss: 4.5404e-04\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.5947e-04 - val_loss: 4.1617e-04\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.8501e-04 - val_loss: 6.2613e-04\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.6057e-04 - val_loss: 3.9766e-04\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.2045e-04 - val_loss: 5.4736e-04\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.4149e-04 - val_loss: 3.9911e-04\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.9056e-04 - val_loss: 4.9624e-04\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.1024e-04 - val_loss: 3.9402e-04\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.7404e-04 - val_loss: 3.8427e-04\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.7717e-04 - val_loss: 4.3699e-04\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.6546e-04 - val_loss: 3.6891e-04\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.7276e-04 - val_loss: 4.1307e-04\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.9238e-04 - val_loss: 3.6315e-04\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.2448e-04 - val_loss: 3.5929e-04\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.2394e-04 - val_loss: 3.6788e-04\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.4148e-04 - val_loss: 4.9264e-04\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 8.6721e-04 - val_loss: 3.4259e-04\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.2750e-04 - val_loss: 4.1285e-04\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.7735e-04 - val_loss: 3.6324e-04\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.6910e-04 - val_loss: 3.3370e-04\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.2827e-04 - val_loss: 3.4968e-04\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.8486e-04 - val_loss: 3.2779e-04\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.8703e-04 - val_loss: 3.4132e-04\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.0896e-04 - val_loss: 3.2255e-04\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.2340e-04 - val_loss: 4.3808e-04\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.6693e-04 - val_loss: 3.1778e-04\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.5618e-04 - val_loss: 3.1570e-04\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.9696e-04 - val_loss: 3.1361e-04\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.7245e-04 - val_loss: 3.3426e-04\n",
      "Thời gian huấn luyện:  9.52903127670288\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_11 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_45 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 3s 23ms/step - loss: 0.0302 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 9.9721e-04\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 9.8318e-04\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 9.6092e-04\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 9.2103e-04\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 9.2365e-04\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 8.9706e-04\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 8.5802e-04\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 8.7291e-04\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 9.1700e-04\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 9.0999e-04\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 9.9628e-04\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 8.4360e-04\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 8.8254e-04\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 9.0890e-04\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 8.6261e-04\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 9.4639e-04\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 7.7698e-04\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 7.4392e-04\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 9.1841e-04\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 7.2556e-04\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 7.0619e-04\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 7.6333e-04\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 7.3265e-04\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 8.6240e-04\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 8.2676e-04\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 7.3438e-04\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 7.3121e-04\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 6.6766e-04\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.7260e-04\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 6.7761e-04\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.4608e-04\n",
      "Thời gian huấn luyện:  23.01760983467102\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_11 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 3s 22ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 10ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Thời gian huấn luyện:  20.21441626548767\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_11 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_47 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 1s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 1s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 1s 5ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Thời gian huấn luyện:  10.567171573638916\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_48 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_61 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 2s 9ms/step - loss: 0.0138 - val_loss: 0.0015\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 9.0081e-04\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 9.4039e-04\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 8.0122e-04\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 8.5235e-04\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 7.5431e-04\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 7.9927e-04\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 7.0902e-04\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 6.9405e-04\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.5153e-04 - val_loss: 6.7592e-04\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.4762e-04 - val_loss: 7.0925e-04\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.2303e-04 - val_loss: 6.8821e-04\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 8.9653e-04 - val_loss: 6.8087e-04\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.8461e-04 - val_loss: 6.7981e-04\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.7391e-04 - val_loss: 7.4825e-04\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.6573e-04 - val_loss: 6.3392e-04\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.3494e-04 - val_loss: 6.3073e-04\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.3107e-04 - val_loss: 5.8955e-04\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.9791e-04 - val_loss: 5.8686e-04\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.9596e-04 - val_loss: 6.1331e-04\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.3115e-04 - val_loss: 6.3359e-04\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.7766e-04 - val_loss: 6.5681e-04\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.5787e-04 - val_loss: 5.6885e-04\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.6173e-04 - val_loss: 5.4109e-04\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.4415e-04 - val_loss: 5.0605e-04\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.4036e-04 - val_loss: 5.3962e-04\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.0530e-04 - val_loss: 5.0144e-04\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.1623e-04 - val_loss: 5.0336e-04\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.0979e-04 - val_loss: 4.7888e-04\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.4591e-04 - val_loss: 5.6870e-04\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.7749e-04 - val_loss: 5.2947e-04\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.6737e-04 - val_loss: 4.8688e-04\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.6247e-04 - val_loss: 4.4950e-04\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.0066e-04 - val_loss: 4.7160e-04\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.4193e-04 - val_loss: 4.9289e-04\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.3572e-04 - val_loss: 5.0808e-04\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.4498e-04 - val_loss: 4.6344e-04\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.2774e-04 - val_loss: 5.2718e-04\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.5587e-04 - val_loss: 4.2479e-04\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.1492e-04 - val_loss: 4.7504e-04\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.2551e-04 - val_loss: 4.2679e-04\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.9982e-04 - val_loss: 4.9029e-04\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.1126e-04 - val_loss: 4.0703e-04\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.1424e-04 - val_loss: 4.1684e-04\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.1064e-04 - val_loss: 4.1182e-04\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.9113e-04 - val_loss: 4.1848e-04\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.3779e-04 - val_loss: 3.9210e-04\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.0550e-04 - val_loss: 4.7747e-04\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.1527e-04 - val_loss: 3.9138e-04\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.2111e-04 - val_loss: 3.7164e-04\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.7480e-04 - val_loss: 4.1524e-04\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.5990e-04 - val_loss: 4.9712e-04\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.7448e-04 - val_loss: 4.1330e-04\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.6593e-04 - val_loss: 3.7231e-04\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.7693e-04 - val_loss: 3.6063e-04\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.6157e-04 - val_loss: 4.3469e-04\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.0616e-04 - val_loss: 3.5691e-04\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.6885e-04 - val_loss: 3.6106e-04\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.4128e-04 - val_loss: 3.5854e-04\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.3075e-04 - val_loss: 3.7530e-04\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.2959e-04 - val_loss: 4.0325e-04\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.3038e-04 - val_loss: 3.3471e-04\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.1831e-04 - val_loss: 4.6423e-04\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.4961e-04 - val_loss: 3.6626e-04\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.3793e-04 - val_loss: 3.3292e-04\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 5.0656e-04 - val_loss: 4.0050e-04\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.6291e-04 - val_loss: 3.2249e-04\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.0924e-04 - val_loss: 3.5207e-04\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.0406e-04 - val_loss: 3.2385e-04\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.9756e-04 - val_loss: 3.1616e-04\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.0365e-04 - val_loss: 3.1577e-04\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.0042e-04 - val_loss: 3.1402e-04\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.5061e-04 - val_loss: 3.2957e-04\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.2338e-04 - val_loss: 3.2190e-04\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8964e-04 - val_loss: 4.0177e-04\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.3180e-04 - val_loss: 3.2297e-04\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8074e-04 - val_loss: 3.0110e-04\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.0034e-04 - val_loss: 3.3642e-04\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.7877e-04 - val_loss: 2.9717e-04\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.7811e-04 - val_loss: 3.3181e-04\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.9078e-04 - val_loss: 3.6844e-04\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8643e-04 - val_loss: 2.9511e-04\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.7339e-04 - val_loss: 3.0437e-04\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.8631e-04 - val_loss: 3.6189e-04\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6984e-04 - val_loss: 3.4418e-04\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8162e-04 - val_loss: 2.8470e-04\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8443e-04 - val_loss: 3.0213e-04\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5951e-04 - val_loss: 3.0808e-04\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6184e-04 - val_loss: 3.3277e-04\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6994e-04 - val_loss: 3.2112e-04\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6321e-04 - val_loss: 2.8018e-04\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5585e-04 - val_loss: 2.9849e-04\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.7875e-04 - val_loss: 3.3905e-04\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.7466e-04 - val_loss: 3.1359e-04\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6658e-04 - val_loss: 2.8978e-04\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8185e-04 - val_loss: 2.7298e-04\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6050e-04 - val_loss: 2.8459e-04\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5885e-04 - val_loss: 3.1729e-04\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6602e-04 - val_loss: 2.7439e-04\n",
      "Thời gian huấn luyện:  20.361613750457764\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_12 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_49 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 3s 23ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2228 - val_loss: 0.0352\n",
      "Thời gian huấn luyện:  49.072768449783325\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_50 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 4s 24ms/step - loss: 0.0236 - val_loss: 0.0038\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 9.5764e-04\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 9.7085e-04\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 9.0549e-04\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 9.2359e-04\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.9056e-04\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 8.8553e-04\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 8.4500e-04\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 8.1632e-04\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.5514e-04\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 8.0465e-04\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 8.1288e-04\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.8904e-04\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.8742e-04\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 8.4046e-04\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.9451e-04\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 7.5879e-04\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 9.7230e-04 - val_loss: 7.1093e-04\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 9.5166e-04 - val_loss: 7.1277e-04\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.5412e-04 - val_loss: 7.1097e-04\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 9.1143e-04 - val_loss: 6.7407e-04\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.9672e-04 - val_loss: 6.7658e-04\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.8969e-04 - val_loss: 6.6442e-04\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.7166e-04 - val_loss: 7.1590e-04\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.7418e-04 - val_loss: 7.1181e-04\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.7753e-04 - val_loss: 6.6763e-04\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.7016e-04 - val_loss: 6.8710e-04\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.7443e-04 - val_loss: 7.0655e-04\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.4973e-04 - val_loss: 6.5721e-04\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.1603e-04 - val_loss: 6.3378e-04\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.2416e-04 - val_loss: 6.3636e-04\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.2207e-04 - val_loss: 6.5084e-04\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.1190e-04 - val_loss: 6.2992e-04\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.1829e-04 - val_loss: 6.7189e-04\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.9720e-04 - val_loss: 6.1017e-04\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.9126e-04 - val_loss: 6.2558e-04\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.9379e-04 - val_loss: 6.3030e-04\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.9053e-04 - val_loss: 6.0338e-04\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.7305e-04 - val_loss: 6.5898e-04\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.9448e-04 - val_loss: 6.0924e-04\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.6347e-04 - val_loss: 6.0642e-04\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.5337e-04 - val_loss: 5.8157e-04\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.5442e-04 - val_loss: 5.8686e-04\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.5717e-04 - val_loss: 5.9457e-04\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.3982e-04 - val_loss: 6.0138e-04\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.3978e-04 - val_loss: 5.7266e-04\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.2697e-04 - val_loss: 5.8867e-04\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.2280e-04 - val_loss: 5.9146e-04\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.1224e-04 - val_loss: 5.7041e-04\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.1668e-04 - val_loss: 5.5818e-04\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.2025e-04 - val_loss: 5.8337e-04\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.2165e-04 - val_loss: 5.4688e-04\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.9831e-04 - val_loss: 5.6473e-04\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.9201e-04 - val_loss: 5.5618e-04\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.9087e-04 - val_loss: 5.3744e-04\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.8698e-04 - val_loss: 5.2888e-04\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.9064e-04 - val_loss: 5.6562e-04\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.9530e-04 - val_loss: 5.2441e-04\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.7020e-04 - val_loss: 5.8293e-04\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.7857e-04 - val_loss: 5.7642e-04\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.7818e-04 - val_loss: 5.3831e-04\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.7036e-04 - val_loss: 5.2275e-04\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.5444e-04 - val_loss: 5.3598e-04\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.6264e-04 - val_loss: 5.0360e-04\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.5895e-04 - val_loss: 5.0447e-04\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.4747e-04 - val_loss: 4.9152e-04\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.3972e-04 - val_loss: 5.1233e-04\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.3664e-04 - val_loss: 4.8513e-04\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.5110e-04 - val_loss: 4.9883e-04\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.2461e-04 - val_loss: 5.1827e-04\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.4749e-04 - val_loss: 4.8679e-04\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.1591e-04 - val_loss: 5.2823e-04\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.7024e-04 - val_loss: 4.7434e-04\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.1099e-04 - val_loss: 4.8518e-04\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.2067e-04 - val_loss: 4.7109e-04\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.1788e-04 - val_loss: 4.8370e-04\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.2683e-04 - val_loss: 5.1321e-04\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.9914e-04 - val_loss: 4.9019e-04\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.9915e-04 - val_loss: 4.5877e-04\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.9506e-04 - val_loss: 4.6833e-04\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.9276e-04 - val_loss: 4.9476e-04\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.8989e-04 - val_loss: 4.6030e-04\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.8053e-04 - val_loss: 4.8989e-04\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.8541e-04 - val_loss: 4.5009e-04\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.8108e-04 - val_loss: 4.3684e-04\n",
      "Thời gian huấn luyện:  44.91447901725769\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_12 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_51 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 935us/step\n",
      "22/22 [==============================] - 0s 942us/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 1s 3ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 1s 4ms/step\n",
      "22/22 [==============================] - 0s 5ms/step\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 1s 5ms/step - loss: 0.0768 - val_loss: 0.0282\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0140\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0121\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0076\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.7876e-04\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.7968e-04\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.9331e-04\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.7538e-04\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 9.4031e-04\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.0015e-04\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.2699e-04\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.4106e-04\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.6790e-04\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.0636e-04\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.9308e-04\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.5189e-04\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.2560e-04\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.3598e-04\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.9826e-04\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.8870e-04\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.0956e-04\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 8.0107e-04\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 8.1316e-04\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.7196e-04\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.4594e-04\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.4108e-04\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.8676e-04\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 8.2242e-04\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.9111e-04\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.3052e-04\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.5850e-04\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.5389e-04\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.4313e-04\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 6.9270e-04\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.1928e-04\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.2751e-04\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 9.9116e-04 - val_loss: 7.0358e-04\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 9.9509e-04 - val_loss: 6.6192e-04\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 9.7654e-04 - val_loss: 6.6011e-04\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 9.6649e-04 - val_loss: 6.6036e-04\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 2ms/step - loss: 9.6361e-04 - val_loss: 6.2330e-04\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 9.5543e-04 - val_loss: 7.3499e-04\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 9.5268e-04 - val_loss: 6.4333e-04\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 9.3066e-04 - val_loss: 6.1541e-04\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 9.3029e-04 - val_loss: 6.5129e-04\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 9.1050e-04 - val_loss: 6.4649e-04\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 9.0196e-04 - val_loss: 6.3642e-04\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 9.0595e-04 - val_loss: 5.9256e-04\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 9.0135e-04 - val_loss: 6.1378e-04\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 8.7894e-04 - val_loss: 6.0205e-04\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 8.7202e-04 - val_loss: 6.4398e-04\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 8.5762e-04 - val_loss: 6.3895e-04\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 8.5522e-04 - val_loss: 5.9798e-04\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 8.4213e-04 - val_loss: 5.7757e-04\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 8.4092e-04 - val_loss: 5.4680e-04\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 8.2560e-04 - val_loss: 5.7125e-04\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 8.2229e-04 - val_loss: 5.8473e-04\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 8.2067e-04 - val_loss: 5.2885e-04\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 8.0355e-04 - val_loss: 5.8866e-04\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.9229e-04 - val_loss: 5.4556e-04\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.9010e-04 - val_loss: 5.3535e-04\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.7968e-04 - val_loss: 5.3424e-04\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.7008e-04 - val_loss: 5.3876e-04\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.6484e-04 - val_loss: 5.2973e-04\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.6462e-04 - val_loss: 4.9812e-04\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.5127e-04 - val_loss: 5.2989e-04\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.4128e-04 - val_loss: 5.1150e-04\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.4127e-04 - val_loss: 5.6724e-04\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.4736e-04 - val_loss: 4.9109e-04\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.2260e-04 - val_loss: 5.0508e-04\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.1510e-04 - val_loss: 4.6352e-04\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 7.0874e-04 - val_loss: 4.8947e-04\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 6.9963e-04 - val_loss: 5.3198e-04\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 6.9697e-04 - val_loss: 4.9808e-04\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 6.9333e-04 - val_loss: 4.6677e-04\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 6.8674e-04 - val_loss: 4.7990e-04\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 6.7933e-04 - val_loss: 4.4594e-04\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 6.7747e-04 - val_loss: 4.5294e-04\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 6.7145e-04 - val_loss: 4.6494e-04\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 6.6618e-04 - val_loss: 4.6125e-04\n",
      "Thời gian huấn luyện:  9.531043767929077\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_65 (Dense)            (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_52 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 1s 8ms/step - loss: 0.0107 - val_loss: 0.0013\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 9.3742e-04\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 8.8230e-04\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 8.7525e-04\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 9.7794e-04\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 7.8689e-04\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 7.3265e-04\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 7.1693e-04\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 7.2943e-04\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 7.7161e-04\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.2447e-04\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 6.5725e-04\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 6.6770e-04\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.3938e-04\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 6.1458e-04\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.7275e-04 - val_loss: 6.1922e-04\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.7513e-04 - val_loss: 6.7628e-04\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.4085e-04 - val_loss: 6.2925e-04\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.1889e-04 - val_loss: 5.9129e-04\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.1270e-04 - val_loss: 5.6134e-04\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.8806e-04 - val_loss: 5.3954e-04\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.7733e-04 - val_loss: 5.6236e-04\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.6872e-04 - val_loss: 5.5606e-04\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.7662e-04 - val_loss: 6.0495e-04\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.4222e-04 - val_loss: 5.1017e-04\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.4247e-04 - val_loss: 6.2564e-04\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.4640e-04 - val_loss: 4.9000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.2724e-04 - val_loss: 4.8151e-04\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.0882e-04 - val_loss: 6.0618e-04\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 7.8431e-04 - val_loss: 5.3385e-04\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.0789e-04 - val_loss: 4.8211e-04\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.5067e-04 - val_loss: 4.9880e-04\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.5137e-04 - val_loss: 4.5542e-04\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4615e-04 - val_loss: 4.5523e-04\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.3316e-04 - val_loss: 4.4195e-04\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.6439e-04 - val_loss: 4.3260e-04\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.8275e-04 - val_loss: 4.2592e-04\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.1547e-04 - val_loss: 4.2639e-04\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.7489e-04 - val_loss: 4.1546e-04\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.3325e-04 - val_loss: 4.4716e-04\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.2241e-04 - val_loss: 4.7735e-04\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.8330e-04 - val_loss: 4.2301e-04\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.6755e-04 - val_loss: 5.5057e-04\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.0136e-04 - val_loss: 4.1550e-04\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.7905e-04 - val_loss: 4.1135e-04\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.0366e-04 - val_loss: 3.9721e-04\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.7080e-04 - val_loss: 3.8132e-04\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.3835e-04 - val_loss: 3.9887e-04\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 6.2799e-04 - val_loss: 4.4007e-04\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.4764e-04 - val_loss: 3.6900e-04\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.4285e-04 - val_loss: 3.7302e-04\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.3349e-04 - val_loss: 4.2868e-04\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.3314e-04 - val_loss: 3.9547e-04\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.2163e-04 - val_loss: 4.1931e-04\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.3997e-04 - val_loss: 3.5146e-04\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.9957e-04 - val_loss: 4.0639e-04\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.5146e-04 - val_loss: 3.6451e-04\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.0944e-04 - val_loss: 3.8109e-04\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.7243e-04 - val_loss: 3.8365e-04\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.1170e-04 - val_loss: 3.3559e-04\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.0705e-04 - val_loss: 3.5073e-04\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.7700e-04 - val_loss: 3.5923e-04\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.0767e-04 - val_loss: 4.0144e-04\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.3844e-04 - val_loss: 3.5064e-04\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.7680e-04 - val_loss: 3.5193e-04\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.9777e-04 - val_loss: 3.2998e-04\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.5846e-04 - val_loss: 3.8417e-04\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 5.7934e-04 - val_loss: 3.2960e-04\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4607e-04 - val_loss: 3.1936e-04\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.6787e-04 - val_loss: 3.1149e-04\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.7564e-04 - val_loss: 3.0697e-04\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4385e-04 - val_loss: 3.1100e-04\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4800e-04 - val_loss: 3.0469e-04\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.5163e-04 - val_loss: 3.3403e-04\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.3645e-04 - val_loss: 3.0781e-04\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2420e-04 - val_loss: 2.9951e-04\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.6448e-04 - val_loss: 3.1136e-04\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4130e-04 - val_loss: 3.0356e-04\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2020e-04 - val_loss: 2.9419e-04\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2887e-04 - val_loss: 3.0448e-04\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2171e-04 - val_loss: 2.8848e-04\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.0860e-04 - val_loss: 2.8707e-04\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1256e-04 - val_loss: 2.8376e-04\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.0884e-04 - val_loss: 3.0230e-04\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.5036e-04 - val_loss: 2.8307e-04\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9990e-04 - val_loss: 3.2094e-04\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 5.1688e-04 - val_loss: 3.1040e-04\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2162e-04 - val_loss: 3.1842e-04\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1683e-04 - val_loss: 2.7664e-04\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1180e-04 - val_loss: 3.1248e-04\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2739e-04 - val_loss: 2.7423e-04\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9935e-04 - val_loss: 3.0829e-04\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.0792e-04 - val_loss: 2.7421e-04\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1057e-04 - val_loss: 3.1394e-04\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1066e-04 - val_loss: 2.7629e-04\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7797e-04 - val_loss: 2.9047e-04\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1103e-04 - val_loss: 2.6542e-04\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9246e-04 - val_loss: 3.0339e-04\n",
      "Thời gian huấn luyện:  18.50840950012207\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_13 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_53 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_67 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 3s 19ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Thời gian huấn luyện:  46.049445152282715\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_13 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_54 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 3s 21ms/step - loss: 0.0311 - val_loss: 0.0028\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 8.9390e-04\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 9.6250e-04\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 9.2506e-04\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 8.6616e-04\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 9.4703e-04\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 9.0687e-04\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.8482e-04\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 8.4973e-04\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 8.3800e-04\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 8.2453e-04\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.0363e-04\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 8.1947e-04\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0013 - val_loss: 8.1555e-04\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0013 - val_loss: 7.6806e-04\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 8.1281e-04\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 7.9394e-04\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 7.7016e-04\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 7.4827e-04\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 7.2123e-04\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.3590e-04\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 7.3393e-04\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.0827e-04\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.9498e-04\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.0363e-04\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.7069e-04\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 7.0432e-04\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 7.4027e-04\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 6.8673e-04\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 9.8433e-04 - val_loss: 7.2661e-04\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 9.6428e-04 - val_loss: 6.1815e-04\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.5865e-04 - val_loss: 6.0473e-04\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.3631e-04 - val_loss: 5.9562e-04\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.3556e-04 - val_loss: 5.8965e-04\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 9.1105e-04 - val_loss: 5.8240e-04\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.0253e-04 - val_loss: 5.9459e-04\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.8513e-04 - val_loss: 6.4772e-04\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.9029e-04 - val_loss: 5.8360e-04\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.7169e-04 - val_loss: 6.6225e-04\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.7202e-04 - val_loss: 5.7905e-04\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 8.6738e-04 - val_loss: 5.5921e-04\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 8ms/step - loss: 8.5503e-04 - val_loss: 5.6041e-04\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.5611e-04 - val_loss: 5.6249e-04\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 8.4708e-04 - val_loss: 5.7626e-04\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 8.3317e-04 - val_loss: 5.5326e-04\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.2330e-04 - val_loss: 5.4486e-04\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.2722e-04 - val_loss: 5.7293e-04\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 8.1026e-04 - val_loss: 5.8369e-04\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.1054e-04 - val_loss: 5.6424e-04\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.0480e-04 - val_loss: 5.5646e-04\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.9253e-04 - val_loss: 5.8249e-04\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.0668e-04 - val_loss: 5.3880e-04\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.9406e-04 - val_loss: 5.3584e-04\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.8610e-04 - val_loss: 5.2253e-04\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.9007e-04 - val_loss: 5.2409e-04\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.8098e-04 - val_loss: 5.4629e-04\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.6307e-04 - val_loss: 5.3173e-04\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.6577e-04 - val_loss: 5.3515e-04\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.5433e-04 - val_loss: 5.1019e-04\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.5727e-04 - val_loss: 5.0312e-04\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.5448e-04 - val_loss: 5.2658e-04\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.4087e-04 - val_loss: 5.2749e-04\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.3454e-04 - val_loss: 4.9440e-04\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.6063e-04 - val_loss: 4.9465e-04\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.4881e-04 - val_loss: 5.3393e-04\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.2267e-04 - val_loss: 4.8378e-04\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.3923e-04 - val_loss: 5.5505e-04\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.1844e-04 - val_loss: 4.8483e-04\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.2594e-04 - val_loss: 5.2135e-04\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.0605e-04 - val_loss: 4.8629e-04\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.0661e-04 - val_loss: 4.7324e-04\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.1627e-04 - val_loss: 4.8888e-04\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.8883e-04 - val_loss: 4.8504e-04\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.9807e-04 - val_loss: 4.7180e-04\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.0744e-04 - val_loss: 5.1420e-04\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.0002e-04 - val_loss: 4.7932e-04\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.9404e-04 - val_loss: 4.5444e-04\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.7121e-04 - val_loss: 4.5470e-04\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.7202e-04 - val_loss: 4.5017e-04\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 6.6351e-04 - val_loss: 4.6027e-04\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.6112e-04 - val_loss: 4.5375e-04\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.6362e-04 - val_loss: 4.9194e-04\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.9490e-04 - val_loss: 4.3409e-04\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.5481e-04 - val_loss: 4.6224e-04\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.8216e-04 - val_loss: 4.3459e-04\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.7130e-04 - val_loss: 4.6325e-04\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.5326e-04 - val_loss: 4.9532e-04\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 6.6354e-04 - val_loss: 4.2330e-04\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 6.5706e-04 - val_loss: 4.3310e-04\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.3434e-04 - val_loss: 4.5406e-04\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.2919e-04 - val_loss: 4.1557e-04\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.3069e-04 - val_loss: 4.1500e-04\n",
      "Thời gian huấn luyện:  43.61006832122803\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_13 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_55 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "22/22 [==============================] - 0s 965us/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 1s 3ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 1s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 1s 6ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Thời gian huấn luyện:  9.544904470443726\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_70 (Dense)            (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_56 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 1s 10ms/step - loss: 0.0181 - val_loss: 0.0012\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 8.9182e-04\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 8.0334e-04\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 8.3112e-04\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 8.1323e-04\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 6.1200e-04\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 5.8454e-04\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 5.6298e-04\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 5.4018e-04\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 5.1221e-04\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.9631e-04 - val_loss: 5.1081e-04\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.5962e-04 - val_loss: 4.6656e-04\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.4455e-04 - val_loss: 4.8664e-04\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.3077e-04 - val_loss: 4.8491e-04\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.0199e-04 - val_loss: 4.4946e-04\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.9173e-04 - val_loss: 4.2617e-04\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.9040e-04 - val_loss: 4.4503e-04\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.8271e-04 - val_loss: 4.5989e-04\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.5782e-04 - val_loss: 4.6058e-04\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.3355e-04 - val_loss: 4.3172e-04\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.1784e-04 - val_loss: 4.5122e-04\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.1363e-04 - val_loss: 4.0001e-04\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.4041e-04 - val_loss: 4.1017e-04\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 8.0367e-04 - val_loss: 4.4307e-04\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 8.1840e-04 - val_loss: 4.0027e-04\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.2624e-04 - val_loss: 3.9561e-04\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.7533e-04 - val_loss: 4.4381e-04\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.8807e-04 - val_loss: 4.1211e-04\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.9123e-04 - val_loss: 4.6974e-04\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.8819e-04 - val_loss: 4.0644e-04\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.6999e-04 - val_loss: 3.6727e-04\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.9583e-04 - val_loss: 4.5534e-04\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.5212e-04 - val_loss: 4.0359e-04\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.3403e-04 - val_loss: 4.0927e-04\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.2611e-04 - val_loss: 3.6991e-04\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.4909e-04 - val_loss: 3.9507e-04\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.7506e-04 - val_loss: 3.6316e-04\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.1322e-04 - val_loss: 4.3159e-04\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.4682e-04 - val_loss: 3.5637e-04\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.0868e-04 - val_loss: 3.5168e-04\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.2626e-04 - val_loss: 3.5293e-04\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.1207e-04 - val_loss: 3.3468e-04\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.2392e-04 - val_loss: 3.3895e-04\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.9051e-04 - val_loss: 3.4681e-04\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.7969e-04 - val_loss: 3.8997e-04\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.8172e-04 - val_loss: 3.9592e-04\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.8002e-04 - val_loss: 3.9001e-04\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.9735e-04 - val_loss: 5.3869e-04\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.9397e-04 - val_loss: 4.1157e-04\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.7147e-04 - val_loss: 3.1602e-04\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.3073e-04 - val_loss: 3.1811e-04\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.9665e-04 - val_loss: 3.1981e-04\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3901e-04 - val_loss: 3.1580e-04\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.5147e-04 - val_loss: 3.3097e-04\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.4588e-04 - val_loss: 3.9078e-04\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.5403e-04 - val_loss: 3.3261e-04\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3171e-04 - val_loss: 3.1570e-04\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.2353e-04 - val_loss: 3.3314e-04\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.4970e-04 - val_loss: 3.4634e-04\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3548e-04 - val_loss: 2.9673e-04\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.4450e-04 - val_loss: 3.3605e-04\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.2955e-04 - val_loss: 2.9666e-04\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3939e-04 - val_loss: 3.2783e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 6.0156e-04 - val_loss: 3.0780e-04\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.9694e-04 - val_loss: 2.9334e-04\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.9478e-04 - val_loss: 2.8667e-04\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.0318e-04 - val_loss: 2.8513e-04\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.9897e-04 - val_loss: 3.2470e-04\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.0260e-04 - val_loss: 3.0179e-04\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.0332e-04 - val_loss: 3.0371e-04\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.8903e-04 - val_loss: 3.2681e-04\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.9116e-04 - val_loss: 2.9654e-04\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.8906e-04 - val_loss: 3.6429e-04\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.1748e-04 - val_loss: 2.7456e-04\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3908e-04 - val_loss: 3.4386e-04\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.7699e-04 - val_loss: 2.9365e-04\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.7734e-04 - val_loss: 2.7071e-04\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.8817e-04 - val_loss: 3.0610e-04\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.9964e-04 - val_loss: 2.8761e-04\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.7400e-04 - val_loss: 2.6656e-04\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6445e-04 - val_loss: 2.7385e-04\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.7689e-04 - val_loss: 3.0229e-04\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.0468e-04 - val_loss: 2.6211e-04\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5076e-04 - val_loss: 2.6470e-04\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5146e-04 - val_loss: 2.6163e-04\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5565e-04 - val_loss: 2.6959e-04\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5057e-04 - val_loss: 2.6397e-04\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.4971e-04 - val_loss: 2.6531e-04\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.4326e-04 - val_loss: 2.5824e-04\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6868e-04 - val_loss: 2.5552e-04\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6866e-04 - val_loss: 2.5292e-04\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.4134e-04 - val_loss: 2.9386e-04\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.8659e-04 - val_loss: 2.5733e-04\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.3211e-04 - val_loss: 2.8412e-04\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.3570e-04 - val_loss: 2.5010e-04\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2657e-04 - val_loss: 2.4677e-04\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6815e-04 - val_loss: 4.6109e-04\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.8362e-04 - val_loss: 3.0850e-04\n",
      "Thời gian huấn luyện:  17.591930389404297\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_14 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_57 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 3s 22ms/step - loss: 0.0350 - val_loss: 0.0019\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 9.8023e-04\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 9.7896e-04\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 9.1449e-04\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 9.6318e-04\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 8.3317e-04\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 9.4721e-04\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 9.1185e-04\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 9.1489e-04\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 8.8602e-04\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 9.1868e-04\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 8.3530e-04\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 8.9627e-04\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 8.1461e-04\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 8.0417e-04\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 7.7865e-04\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 8.9280e-04\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 7.7146e-04\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 8.1452e-04\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 8.4262e-04\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 7.9195e-04\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 7.3905e-04\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 7.4092e-04\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 8.3812e-04\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.4642e-04\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 9.1991e-04\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.8500e-04\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 7.9384e-04\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.4469e-04\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.7180e-04\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.9800e-04\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.5486e-04\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.2682e-04\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.9823e-04\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.2382e-04\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.6853e-04\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 6.9000e-04\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.7075e-04\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.9936e-04\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.4941e-04\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.8543e-04\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.6495e-04\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.4058e-04\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.5960e-04\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.0324e-04\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 5.9485e-04\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.9849e-04\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.9096e-04\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.6996e-04\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.2060e-04\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.9196e-04\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.3023e-04\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.9997e-04 - val_loss: 5.7012e-04\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 5.3467e-04\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 5.2640e-04\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.0961e-04\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.6957e-04\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.2900e-04\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.6192e-04 - val_loss: 5.5187e-04\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.6656e-04 - val_loss: 5.6541e-04\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.6782e-04 - val_loss: 6.2841e-04\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.7792e-04 - val_loss: 5.2927e-04\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 6.8372e-04\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 9.7435e-04 - val_loss: 5.3099e-04\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.0431e-04\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.5231e-04 - val_loss: 5.0772e-04\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.9050e-04 - val_loss: 4.9827e-04\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.6764e-04\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.3933e-04 - val_loss: 5.0399e-04\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.5655e-04 - val_loss: 5.7399e-04\n",
      "Thời gian huấn luyện:  40.21137857437134\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_58 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 3s 21ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2385 - val_loss: 0.0661\n",
      "Thời gian huấn luyện:  36.155030965805054\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_14 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_59 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 857us/step\n",
      "22/22 [==============================] - 0s 981us/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 1s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 1s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "47/47 [==============================] - 1s 5ms/step - loss: 0.0853 - val_loss: 0.0302\n",
      "Epoch 2/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0202\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0167\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0110\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0083\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0067\n",
      "Epoch 8/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 21/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 29/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.6904e-04\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 9.9352e-04\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 9.9697e-04\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.8892e-04\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.5933e-04\n",
      "Epoch 48/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.5242e-04\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.6007e-04\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.2718e-04\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.6130e-04\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.9350e-04\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 8.6637e-04\n",
      "Epoch 56/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 8.4097e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 8.7486e-04\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 8.7334e-04\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 9.0027e-04\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 9.2312e-04\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 9.2212e-04\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 9.1686e-04\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 8.1193e-04\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 8.8479e-04\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 8.2568e-04\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 8.4063e-04\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 8.0889e-04\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.9725e-04\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.7585e-04\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.9796e-04 - val_loss: 7.3080e-04\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.8340e-04 - val_loss: 7.9805e-04\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.7529e-04 - val_loss: 6.9935e-04\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.7916e-04 - val_loss: 7.6220e-04\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.6018e-04 - val_loss: 7.7668e-04\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.4267e-04 - val_loss: 7.3516e-04\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.3750e-04 - val_loss: 7.3548e-04\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.2973e-04 - val_loss: 7.2122e-04\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.1444e-04 - val_loss: 6.5812e-04\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 9.4177e-04 - val_loss: 6.8925e-04\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.0480e-04 - val_loss: 7.0416e-04\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.8816e-04 - val_loss: 7.5179e-04\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.8851e-04 - val_loss: 7.2722e-04\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.7796e-04 - val_loss: 6.7917e-04\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.7201e-04 - val_loss: 6.7579e-04\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.5712e-04 - val_loss: 7.1323e-04\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.4737e-04 - val_loss: 7.2862e-04\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.5323e-04 - val_loss: 6.3129e-04\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.3458e-04 - val_loss: 6.4285e-04\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.2433e-04 - val_loss: 6.8363e-04\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.3241e-04 - val_loss: 6.5048e-04\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.0618e-04 - val_loss: 6.8883e-04\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.0179e-04 - val_loss: 6.1765e-04\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.0042e-04 - val_loss: 6.1454e-04\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.8207e-04 - val_loss: 6.3368e-04\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.7438e-04 - val_loss: 5.9051e-04\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.7023e-04 - val_loss: 6.3552e-04\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.6146e-04 - val_loss: 6.1235e-04\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.5389e-04 - val_loss: 6.2581e-04\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.4748e-04 - val_loss: 5.7637e-04\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.5124e-04 - val_loss: 6.3814e-04\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.3007e-04 - val_loss: 5.8644e-04\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.2298e-04 - val_loss: 6.3763e-04\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.2428e-04 - val_loss: 5.7808e-04\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.1822e-04 - val_loss: 5.8090e-04\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.0567e-04 - val_loss: 5.4998e-04\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.9898e-04 - val_loss: 5.2157e-04\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.9235e-04 - val_loss: 5.8091e-04\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.9190e-04 - val_loss: 5.8100e-04\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.8085e-04 - val_loss: 6.1144e-04\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.7612e-04 - val_loss: 5.4765e-04\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.7158e-04 - val_loss: 5.2926e-04\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.6771e-04 - val_loss: 5.9221e-04\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.6901e-04 - val_loss: 5.1210e-04\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.5472e-04 - val_loss: 4.8862e-04\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.4643e-04 - val_loss: 4.9066e-04\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.5370e-04 - val_loss: 5.1758e-04\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.4036e-04 - val_loss: 5.0814e-04\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.4088e-04 - val_loss: 5.4213e-04\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.5667e-04 - val_loss: 4.7934e-04\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.2910e-04 - val_loss: 4.9775e-04\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.2265e-04 - val_loss: 5.0511e-04\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.2126e-04 - val_loss: 5.2975e-04\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.2196e-04 - val_loss: 5.4871e-04\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.2898e-04 - val_loss: 4.5044e-04\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.1913e-04 - val_loss: 4.8841e-04\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.0682e-04 - val_loss: 4.6957e-04\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.0313e-04 - val_loss: 4.9900e-04\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.0067e-04 - val_loss: 4.9080e-04\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.9398e-04 - val_loss: 4.8471e-04\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.9155e-04 - val_loss: 5.1650e-04\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.9105e-04 - val_loss: 4.7216e-04\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.8615e-04 - val_loss: 5.1035e-04\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 3ms/step - loss: 5.8567e-04 - val_loss: 4.6415e-04\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.8427e-04 - val_loss: 4.4490e-04\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.7641e-04 - val_loss: 4.9303e-04\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.7676e-04 - val_loss: 4.3787e-04\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.7254e-04 - val_loss: 4.4881e-04\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.7123e-04 - val_loss: 4.7110e-04\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.6654e-04 - val_loss: 4.5446e-04\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.6630e-04 - val_loss: 4.5894e-04\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.7099e-04 - val_loss: 4.7781e-04\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.5992e-04 - val_loss: 4.3113e-04\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.5943e-04 - val_loss: 4.4442e-04\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.5529e-04 - val_loss: 4.3746e-04\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.5457e-04 - val_loss: 4.3814e-04\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.6072e-04 - val_loss: 4.3921e-04\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 5.5216e-04 - val_loss: 4.5624e-04\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.5231e-04 - val_loss: 4.3269e-04\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.4989e-04 - val_loss: 4.6412e-04\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.4739e-04 - val_loss: 4.4814e-04\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.5099e-04 - val_loss: 4.1575e-04\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.4518e-04 - val_loss: 4.3285e-04\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.3975e-04 - val_loss: 4.0104e-04\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.4194e-04 - val_loss: 4.2401e-04\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.3875e-04 - val_loss: 4.5129e-04\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 5.3514e-04 - val_loss: 4.1936e-04\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.3296e-04 - val_loss: 4.3771e-04\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.3156e-04 - val_loss: 4.7455e-04\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.3084e-04 - val_loss: 3.9002e-04\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.3616e-04 - val_loss: 4.1383e-04\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.2622e-04 - val_loss: 4.4466e-04\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.2951e-04 - val_loss: 4.0021e-04\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.2820e-04 - val_loss: 4.4425e-04\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.2187e-04 - val_loss: 4.0040e-04\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.2874e-04 - val_loss: 4.1272e-04\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 5.2161e-04 - val_loss: 4.1643e-04\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.2162e-04 - val_loss: 3.8785e-04\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.2032e-04 - val_loss: 4.1530e-04\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.1753e-04 - val_loss: 3.9547e-04\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.2262e-04 - val_loss: 4.0050e-04\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.1535e-04 - val_loss: 3.9357e-04\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.1129e-04 - val_loss: 3.8862e-04\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.1942e-04 - val_loss: 4.1054e-04\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.2077e-04 - val_loss: 3.9101e-04\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.1220e-04 - val_loss: 3.9862e-04\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.0642e-04 - val_loss: 4.4297e-04\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.1139e-04 - val_loss: 3.8904e-04\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.1042e-04 - val_loss: 4.0181e-04\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.0412e-04 - val_loss: 4.1377e-04\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 5.0354e-04 - val_loss: 4.2544e-04\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.0935e-04 - val_loss: 3.7994e-04\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.0279e-04 - val_loss: 4.1347e-04\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.0172e-04 - val_loss: 4.0857e-04\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.2009e-04 - val_loss: 3.7595e-04\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.9902e-04 - val_loss: 3.9245e-04\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.9885e-04 - val_loss: 3.7019e-04\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.0043e-04 - val_loss: 3.9268e-04\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.0439e-04 - val_loss: 3.6848e-04\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.1149e-04 - val_loss: 3.6962e-04\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.0121e-04 - val_loss: 4.0287e-04\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.0049e-04 - val_loss: 3.7387e-04\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.9261e-04 - val_loss: 3.9057e-04\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.9356e-04 - val_loss: 4.0933e-04\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.0530e-04 - val_loss: 4.1584e-04\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.9221e-04 - val_loss: 3.9635e-04\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.9500e-04 - val_loss: 4.0000e-04\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.9220e-04 - val_loss: 3.7368e-04\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.9638e-04 - val_loss: 3.7395e-04\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.9168e-04 - val_loss: 3.8285e-04\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.8466e-04 - val_loss: 3.5827e-04\n",
      "Thời gian huấn luyện:  20.198535442352295\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_75 (Dense)            (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_60 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "47/47 [==============================] - 1s 8ms/step - loss: 0.0156 - val_loss: 0.0020\n",
      "Epoch 2/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 8.9329e-04\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 7.8119e-04\n",
      "Epoch 8/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 9.9021e-04\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 7.3016e-04\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 7.1511e-04\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 7.3951e-04\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.7547e-04 - val_loss: 6.5496e-04\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.7674e-04 - val_loss: 6.8427e-04\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.3348e-04 - val_loss: 7.8285e-04\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 9.7552e-04 - val_loss: 5.9639e-04\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 9.2560e-04 - val_loss: 6.7585e-04\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 8.7290e-04 - val_loss: 7.3619e-04\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.6566e-04 - val_loss: 6.2850e-04\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.5839e-04 - val_loss: 6.3725e-04\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.4029e-04 - val_loss: 6.8827e-04\n",
      "Epoch 21/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.3172e-04 - val_loss: 6.0504e-04\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 8.1305e-04 - val_loss: 6.2868e-04\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 8.1828e-04 - val_loss: 6.3129e-04\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 8.4337e-04 - val_loss: 5.9301e-04\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.8379e-04 - val_loss: 6.5318e-04\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.7759e-04 - val_loss: 6.7278e-04\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.8083e-04 - val_loss: 5.3457e-04\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 7.6750e-04 - val_loss: 5.3944e-04\n",
      "Epoch 29/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 7.6280e-04 - val_loss: 5.2865e-04\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 7.8714e-04 - val_loss: 5.7867e-04\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.3157e-04 - val_loss: 5.1687e-04\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.3592e-04 - val_loss: 5.3499e-04\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 7.4507e-04 - val_loss: 4.9784e-04\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.6334e-04 - val_loss: 5.5389e-04\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.1600e-04 - val_loss: 5.1726e-04\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.9495e-04 - val_loss: 4.9384e-04\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.8583e-04 - val_loss: 4.9589e-04\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.1061e-04 - val_loss: 4.8030e-04\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.8598e-04 - val_loss: 4.9576e-04\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.9158e-04 - val_loss: 4.7708e-04\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.1321e-04 - val_loss: 5.0748e-04\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 6.7064e-04 - val_loss: 5.5562e-04\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 6.9054e-04 - val_loss: 5.1231e-04\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.7472e-04 - val_loss: 4.4677e-04\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.9083e-04 - val_loss: 4.9446e-04\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 6.4837e-04 - val_loss: 4.6104e-04\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.6395e-04 - val_loss: 4.7039e-04\n",
      "Epoch 48/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.5851e-04 - val_loss: 4.6622e-04\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.2984e-04 - val_loss: 4.2970e-04\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.6813e-04 - val_loss: 4.5872e-04\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.2162e-04 - val_loss: 4.4958e-04\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.2740e-04 - val_loss: 5.6165e-04\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 6.3503e-04 - val_loss: 4.2665e-04\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 6.3521e-04 - val_loss: 5.2207e-04\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.3778e-04 - val_loss: 4.1294e-04\n",
      "Epoch 56/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 6.1560e-04 - val_loss: 4.1041e-04\n",
      "Epoch 57/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.4749e-04 - val_loss: 4.0781e-04\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.8146e-04 - val_loss: 4.6115e-04\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.9478e-04 - val_loss: 4.1827e-04\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 5.8544e-04 - val_loss: 4.1838e-04\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.9718e-04 - val_loss: 3.9861e-04\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 5.8834e-04 - val_loss: 4.0562e-04\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.2046e-04 - val_loss: 3.8958e-04\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.7623e-04 - val_loss: 4.3586e-04\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.9413e-04 - val_loss: 4.0552e-04\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.8461e-04 - val_loss: 4.2543e-04\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.8599e-04 - val_loss: 5.1852e-04\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.3456e-04 - val_loss: 3.9525e-04\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.8908e-04 - val_loss: 5.1920e-04\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.6820e-04 - val_loss: 3.8895e-04\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.6351e-04 - val_loss: 4.0471e-04\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.5590e-04 - val_loss: 3.9495e-04\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.7179e-04 - val_loss: 3.7659e-04\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.8899e-04 - val_loss: 3.6862e-04\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.5943e-04 - val_loss: 3.6850e-04\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.6211e-04 - val_loss: 3.7044e-04\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.5212e-04 - val_loss: 3.5249e-04\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.7336e-04 - val_loss: 3.5896e-04\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.2345e-04 - val_loss: 3.4691e-04\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 5.6722e-04 - val_loss: 3.6790e-04\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.4104e-04 - val_loss: 3.8191e-04\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.4491e-04 - val_loss: 3.9267e-04\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.4705e-04 - val_loss: 3.9880e-04\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.3212e-04 - val_loss: 3.7408e-04\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.4308e-04 - val_loss: 3.4935e-04\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.4108e-04 - val_loss: 3.7725e-04\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.1687e-04 - val_loss: 3.4737e-04\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.2104e-04 - val_loss: 3.9500e-04\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.2550e-04 - val_loss: 3.5579e-04\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.2711e-04 - val_loss: 4.6804e-04\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 5.3732e-04 - val_loss: 3.8702e-04\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.2755e-04 - val_loss: 3.2953e-04\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.2578e-04 - val_loss: 3.3358e-04\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.1131e-04 - val_loss: 3.2462e-04\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.1367e-04 - val_loss: 3.5516e-04\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.3367e-04 - val_loss: 3.3316e-04\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.9899e-04 - val_loss: 3.7358e-04\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 5.0673e-04 - val_loss: 3.2893e-04\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.2528e-04 - val_loss: 4.0163e-04\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.0261e-04 - val_loss: 3.4279e-04\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.1676e-04 - val_loss: 3.2855e-04\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8882e-04 - val_loss: 3.2239e-04\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.1244e-04 - val_loss: 3.1294e-04\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8806e-04 - val_loss: 3.0373e-04\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 5.2996e-04 - val_loss: 3.4756e-04\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.9772e-04 - val_loss: 3.0041e-04\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.9135e-04 - val_loss: 3.1003e-04\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.7309e-04 - val_loss: 3.0273e-04\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.0670e-04 - val_loss: 3.9566e-04\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.9782e-04 - val_loss: 2.9765e-04\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.7507e-04 - val_loss: 3.7979e-04\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.9560e-04 - val_loss: 3.0994e-04\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6665e-04 - val_loss: 3.2434e-04\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8247e-04 - val_loss: 3.1294e-04\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6767e-04 - val_loss: 3.1449e-04\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8464e-04 - val_loss: 3.1975e-04\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8530e-04 - val_loss: 3.1255e-04\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.7104e-04 - val_loss: 2.9499e-04\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6678e-04 - val_loss: 2.8362e-04\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6156e-04 - val_loss: 3.1992e-04\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5888e-04 - val_loss: 2.9832e-04\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5862e-04 - val_loss: 3.0774e-04\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.9893e-04 - val_loss: 3.1658e-04\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8705e-04 - val_loss: 3.0322e-04\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.9183e-04 - val_loss: 2.8183e-04\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6500e-04 - val_loss: 2.9066e-04\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.4785e-04 - val_loss: 2.7771e-04\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.4623e-04 - val_loss: 3.2115e-04\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5738e-04 - val_loss: 2.8089e-04\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.4046e-04 - val_loss: 3.5440e-04\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8552e-04 - val_loss: 3.0237e-04\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5856e-04 - val_loss: 2.8740e-04\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5065e-04 - val_loss: 2.6781e-04\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3791e-04 - val_loss: 2.6910e-04\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.4094e-04 - val_loss: 2.6517e-04\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6601e-04 - val_loss: 2.6453e-04\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5448e-04 - val_loss: 2.7481e-04\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5429e-04 - val_loss: 2.6356e-04\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3137e-04 - val_loss: 2.9238e-04\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.4380e-04 - val_loss: 2.6285e-04\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.3780e-04 - val_loss: 2.8714e-04\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3767e-04 - val_loss: 2.8128e-04\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3041e-04 - val_loss: 2.6521e-04\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.4749e-04 - val_loss: 2.8048e-04\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2543e-04 - val_loss: 2.6349e-04\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.4634e-04 - val_loss: 2.6428e-04\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 5.2842e-04 - val_loss: 2.5592e-04\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.6627e-04 - val_loss: 2.7690e-04\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.1992e-04 - val_loss: 2.5829e-04\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.4283e-04 - val_loss: 2.5957e-04\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.2388e-04 - val_loss: 2.5319e-04\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3421e-04 - val_loss: 2.5128e-04\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2268e-04 - val_loss: 2.7248e-04\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2815e-04 - val_loss: 3.1406e-04\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.5362e-04 - val_loss: 2.7721e-04\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.3127e-04 - val_loss: 2.5997e-04\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.1297e-04 - val_loss: 2.8019e-04\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.2737e-04 - val_loss: 2.5179e-04\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0897e-04 - val_loss: 2.5761e-04\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8007e-04 - val_loss: 2.6510e-04\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2908e-04 - val_loss: 2.4600e-04\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.0991e-04 - val_loss: 2.6121e-04\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.0683e-04 - val_loss: 2.5636e-04\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 4.1134e-04 - val_loss: 2.8627e-04\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3610e-04 - val_loss: 2.7318e-04\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2731e-04 - val_loss: 2.7225e-04\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1629e-04 - val_loss: 2.5566e-04\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0691e-04 - val_loss: 2.8377e-04\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0908e-04 - val_loss: 2.4225e-04\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3367e-04 - val_loss: 2.4063e-04\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.1882e-04 - val_loss: 2.4890e-04\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1207e-04 - val_loss: 2.3823e-04\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1577e-04 - val_loss: 2.4669e-04\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2891e-04 - val_loss: 2.3804e-04\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1343e-04 - val_loss: 2.3883e-04\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3979e-04 - val_loss: 2.3627e-04\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5876e-04 - val_loss: 2.9195e-04\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.4899e-04 - val_loss: 2.4537e-04\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9527e-04 - val_loss: 2.5463e-04\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0926e-04 - val_loss: 2.4937e-04\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1536e-04 - val_loss: 2.5594e-04\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9756e-04 - val_loss: 2.5919e-04\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2633e-04 - val_loss: 2.3863e-04\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2567e-04 - val_loss: 2.5993e-04\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0742e-04 - val_loss: 2.4494e-04\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0498e-04 - val_loss: 2.9124e-04\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2051e-04 - val_loss: 2.5612e-04\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9275e-04 - val_loss: 2.4202e-04\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.9783e-04 - val_loss: 2.7652e-04\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.4529e-04 - val_loss: 2.2646e-04\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0846e-04 - val_loss: 2.4916e-04\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9755e-04 - val_loss: 2.2823e-04\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5094e-04 - val_loss: 2.6425e-04\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0188e-04 - val_loss: 2.2581e-04\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2220e-04 - val_loss: 2.3960e-04\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1337e-04 - val_loss: 2.6512e-04\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1227e-04 - val_loss: 2.2918e-04\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9505e-04 - val_loss: 2.3932e-04\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9966e-04 - val_loss: 2.3083e-04\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1567e-04 - val_loss: 2.2436e-04\n",
      "Thời gian huấn luyện:  36.24804425239563\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_15 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_61 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "47/47 [==============================] - 4s 26ms/step - loss: 0.0341 - val_loss: 0.0039\n",
      "Epoch 2/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 8/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 29/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 9.3421e-04\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 9.2512e-04\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 9.5105e-04\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0013 - val_loss: 9.1214e-04\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 9.0540e-04\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 9.1024e-04\n",
      "Epoch 48/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 8.7239e-04\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 8.3334e-04\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.8793e-04\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 8.7687e-04\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 8.6785e-04\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 8.9415e-04\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.5960e-04\n",
      "Epoch 56/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.9801e-04\n",
      "Epoch 57/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 8.6246e-04\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 7.2129e-04\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 8.8343e-04\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 7.9506e-04\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 7.2032e-04\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 8.6530e-04\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 7.5443e-04\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 8.7612e-04\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 7.3575e-04\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.7394e-04 - val_loss: 7.4546e-04\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.5151e-04 - val_loss: 7.4001e-04\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.6911e-04 - val_loss: 8.0805e-04\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.5863e-04 - val_loss: 6.9247e-04\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.5409e-04 - val_loss: 7.7029e-04\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.6335e-04 - val_loss: 7.6238e-04\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.5859e-04 - val_loss: 9.1334e-04\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.3508e-04 - val_loss: 6.6760e-04\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.4937e-04 - val_loss: 7.3326e-04\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.2893e-04 - val_loss: 6.9709e-04\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.4978e-04 - val_loss: 6.8875e-04\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.0123e-04 - val_loss: 7.0666e-04\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.0158e-04 - val_loss: 7.2469e-04\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.9510e-04 - val_loss: 7.2953e-04\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.9113e-04 - val_loss: 7.5323e-04\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.1078e-04 - val_loss: 7.3006e-04\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.9810e-04 - val_loss: 7.6487e-04\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.9828e-04 - val_loss: 6.8188e-04\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.9819e-04 - val_loss: 7.2928e-04\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.7783e-04 - val_loss: 6.5873e-04\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.8396e-04 - val_loss: 6.5231e-04\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.8876e-04 - val_loss: 7.8396e-04\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.7031e-04 - val_loss: 6.9970e-04\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.7735e-04 - val_loss: 6.8468e-04\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.5583e-04 - val_loss: 6.9196e-04\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.6966e-04 - val_loss: 7.0245e-04\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.2107e-04 - val_loss: 6.9178e-04\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.4608e-04 - val_loss: 6.5363e-04\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.4072e-04 - val_loss: 7.3132e-04\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.7903e-04 - val_loss: 6.4329e-04\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.4702e-04 - val_loss: 6.3640e-04\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.4900e-04 - val_loss: 6.9916e-04\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.2836e-04 - val_loss: 6.5082e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.3952e-04 - val_loss: 6.5976e-04\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.2076e-04 - val_loss: 6.5780e-04\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.3794e-04 - val_loss: 6.1040e-04\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.3836e-04 - val_loss: 7.2507e-04\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.2911e-04 - val_loss: 6.9343e-04\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.0864e-04 - val_loss: 6.1270e-04\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.0436e-04 - val_loss: 6.9908e-04\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.2428e-04 - val_loss: 6.5541e-04\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.2944e-04 - val_loss: 7.8760e-04\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.3298e-04 - val_loss: 7.0523e-04\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.0480e-04 - val_loss: 6.4645e-04\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.0638e-04 - val_loss: 6.1006e-04\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.2840e-04 - val_loss: 6.7641e-04\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.9705e-04 - val_loss: 6.6025e-04\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.8029e-04 - val_loss: 7.0367e-04\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.2211e-04 - val_loss: 5.6529e-04\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.1201e-04 - val_loss: 6.2242e-04\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 7.8512e-04 - val_loss: 6.6834e-04\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.8166e-04 - val_loss: 6.0693e-04\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.7609e-04 - val_loss: 5.7732e-04\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.6639e-04 - val_loss: 6.1063e-04\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.5671e-04 - val_loss: 6.2193e-04\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.6724e-04 - val_loss: 6.3877e-04\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.4335e-04 - val_loss: 5.9250e-04\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.6445e-04 - val_loss: 6.4646e-04\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.4704e-04 - val_loss: 5.8016e-04\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.4288e-04 - val_loss: 6.1717e-04\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.3711e-04 - val_loss: 6.2328e-04\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.2779e-04 - val_loss: 5.8818e-04\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.3076e-04 - val_loss: 6.4059e-04\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.4099e-04 - val_loss: 5.6546e-04\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.4136e-04 - val_loss: 5.7842e-04\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.3330e-04 - val_loss: 6.2418e-04\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.8154e-04 - val_loss: 5.6542e-04\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.1505e-04 - val_loss: 5.3970e-04\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.3305e-04 - val_loss: 7.0989e-04\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.2140e-04 - val_loss: 5.5864e-04\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.1955e-04 - val_loss: 6.1231e-04\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.0162e-04 - val_loss: 6.1271e-04\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.0243e-04 - val_loss: 5.9985e-04\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.0491e-04 - val_loss: 5.4311e-04\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.8478e-04 - val_loss: 6.0379e-04\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.2688e-04 - val_loss: 6.9138e-04\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.1661e-04 - val_loss: 5.8938e-04\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.1545e-04 - val_loss: 5.6780e-04\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.8102e-04 - val_loss: 5.7189e-04\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.8315e-04 - val_loss: 5.4519e-04\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.7669e-04 - val_loss: 5.4302e-04\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.0107e-04 - val_loss: 5.6345e-04\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.7620e-04 - val_loss: 6.1174e-04\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.8290e-04 - val_loss: 5.7105e-04\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.9161e-04 - val_loss: 5.5128e-04\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.6495e-04 - val_loss: 5.4168e-04\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.8787e-04 - val_loss: 5.7788e-04\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.6698e-04 - val_loss: 5.7201e-04\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.6125e-04 - val_loss: 5.6754e-04\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.7532e-04 - val_loss: 5.3947e-04\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.5501e-04 - val_loss: 5.3617e-04\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.8870e-04 - val_loss: 5.0268e-04\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.7625e-04 - val_loss: 5.3362e-04\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.7864e-04 - val_loss: 4.9480e-04\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.8583e-04 - val_loss: 5.3794e-04\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.6025e-04 - val_loss: 5.5797e-04\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.3735e-04 - val_loss: 5.5048e-04\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.4081e-04 - val_loss: 5.5854e-04\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.5927e-04 - val_loss: 5.6615e-04\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.3637e-04 - val_loss: 5.7157e-04\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.6419e-04 - val_loss: 4.9538e-04\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.5345e-04 - val_loss: 5.6585e-04\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.3170e-04 - val_loss: 5.2620e-04\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.2319e-04 - val_loss: 5.6084e-04\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.2717e-04 - val_loss: 4.9157e-04\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.5682e-04 - val_loss: 4.8558e-04\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.3461e-04 - val_loss: 4.7017e-04\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.0737e-04 - val_loss: 4.8150e-04\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 9ms/step - loss: 6.3073e-04 - val_loss: 5.0425e-04\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.1320e-04 - val_loss: 5.7394e-04\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.2613e-04 - val_loss: 5.3793e-04\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.2027e-04 - val_loss: 5.7634e-04\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.0121e-04 - val_loss: 5.0159e-04\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.0578e-04 - val_loss: 4.7182e-04\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.1832e-04 - val_loss: 5.3941e-04\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.2528e-04 - val_loss: 5.7732e-04\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.0687e-04 - val_loss: 5.3110e-04\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.5660e-04 - val_loss: 5.0247e-04\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.5812e-04 - val_loss: 5.8404e-04\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.9741e-04 - val_loss: 5.4199e-04\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.8699e-04 - val_loss: 4.9931e-04\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.2257e-04 - val_loss: 5.1367e-04\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.8317e-04 - val_loss: 4.9290e-04\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.9173e-04 - val_loss: 5.1366e-04\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.8156e-04 - val_loss: 4.9222e-04\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.1588e-04 - val_loss: 4.9569e-04\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.9941e-04 - val_loss: 4.9543e-04\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.7654e-04 - val_loss: 5.5292e-04\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.8594e-04 - val_loss: 5.0026e-04\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.7326e-04 - val_loss: 4.8771e-04\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.7642e-04 - val_loss: 4.4500e-04\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.7149e-04 - val_loss: 4.8129e-04\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.7537e-04 - val_loss: 4.6456e-04\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.6097e-04 - val_loss: 5.2894e-04\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.7134e-04 - val_loss: 4.6214e-04\n",
      "Thời gian huấn luyện:  92.96853232383728\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_62 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "47/47 [==============================] - 3s 19ms/step - loss: 0.0268 - val_loss: 0.0034\n",
      "Epoch 2/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 8/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 9.6832e-04\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 9.3820e-04\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 9.4355e-04\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 9.3596e-04\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.9601e-04\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 9.2885e-04\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.8580e-04\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 7.9329e-04\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 8.5910e-04\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 8.3481e-04\n",
      "Epoch 21/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 9.4939e-04\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.9015e-04\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 8.2080e-04\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 7.3041e-04\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.5961e-04\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 8.0490e-04\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.9810e-04\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 7.5676e-04\n",
      "Epoch 29/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.9643e-04\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 7.0069e-04\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 9.8233e-04 - val_loss: 7.3678e-04\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.6757e-04 - val_loss: 7.3182e-04\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.6411e-04 - val_loss: 7.5845e-04\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 9.2813e-04 - val_loss: 6.7858e-04\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.1160e-04 - val_loss: 6.3027e-04\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.3047e-04 - val_loss: 6.4183e-04\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.8335e-04 - val_loss: 6.2618e-04\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.6825e-04 - val_loss: 6.3968e-04\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.5498e-04 - val_loss: 6.6099e-04\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.3751e-04 - val_loss: 6.6076e-04\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.2738e-04 - val_loss: 6.1163e-04\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.3024e-04 - val_loss: 6.6080e-04\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.1982e-04 - val_loss: 6.0448e-04\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 8.1288e-04 - val_loss: 6.6968e-04\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 1s 15ms/step - loss: 8.1389e-04 - val_loss: 5.6295e-04\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.1706e-04 - val_loss: 5.8561e-04\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.7251e-04 - val_loss: 6.6330e-04\n",
      "Epoch 48/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.3585e-04 - val_loss: 6.0524e-04\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.8917e-04 - val_loss: 5.8057e-04\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.5840e-04 - val_loss: 5.5421e-04\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.6194e-04 - val_loss: 5.5572e-04\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.5216e-04 - val_loss: 5.4806e-04\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.5411e-04 - val_loss: 5.5256e-04\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.4488e-04 - val_loss: 6.0519e-04\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.5558e-04 - val_loss: 6.1322e-04\n",
      "Epoch 56/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.3978e-04 - val_loss: 5.6363e-04\n",
      "Epoch 57/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 7.2531e-04 - val_loss: 5.4810e-04\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.1310e-04 - val_loss: 5.6053e-04\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.2455e-04 - val_loss: 5.8616e-04\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.1082e-04 - val_loss: 6.0296e-04\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.0814e-04 - val_loss: 5.3838e-04\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.9630e-04 - val_loss: 5.4963e-04\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.9661e-04 - val_loss: 5.3105e-04\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.0072e-04 - val_loss: 5.3188e-04\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.8098e-04 - val_loss: 5.3196e-04\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.8527e-04 - val_loss: 5.7210e-04\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.8101e-04 - val_loss: 5.2616e-04\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 6.6987e-04 - val_loss: 5.0752e-04\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.0593e-04 - val_loss: 5.4107e-04\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.7753e-04 - val_loss: 5.7227e-04\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.8075e-04 - val_loss: 5.2570e-04\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.6639e-04 - val_loss: 5.3786e-04\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.4865e-04 - val_loss: 5.1487e-04\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.5289e-04 - val_loss: 5.0661e-04\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.4331e-04 - val_loss: 5.3148e-04\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.4734e-04 - val_loss: 5.1146e-04\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.5108e-04 - val_loss: 4.8964e-04\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.3344e-04 - val_loss: 5.0805e-04\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.4657e-04 - val_loss: 4.9402e-04\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.4917e-04 - val_loss: 5.2321e-04\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.5198e-04 - val_loss: 4.8421e-04\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.2602e-04 - val_loss: 5.0411e-04\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.2164e-04 - val_loss: 5.0897e-04\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.3368e-04 - val_loss: 5.5162e-04\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.2547e-04 - val_loss: 4.8040e-04\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.0971e-04 - val_loss: 4.6722e-04\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.1091e-04 - val_loss: 4.5884e-04\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.0262e-04 - val_loss: 4.5380e-04\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.0989e-04 - val_loss: 4.6277e-04\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.3145e-04 - val_loss: 4.7721e-04\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.1372e-04 - val_loss: 5.0656e-04\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.1218e-04 - val_loss: 4.6166e-04\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.8584e-04 - val_loss: 4.5883e-04\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.8573e-04 - val_loss: 4.8066e-04\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.8342e-04 - val_loss: 4.9483e-04\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.0618e-04 - val_loss: 4.4915e-04\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.8199e-04 - val_loss: 4.4250e-04\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.9516e-04 - val_loss: 4.2892e-04\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 6.0023e-04 - val_loss: 4.6567e-04\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.6774e-04 - val_loss: 4.5005e-04\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.7514e-04 - val_loss: 4.5064e-04\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.6072e-04 - val_loss: 4.2001e-04\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.6990e-04 - val_loss: 5.1227e-04\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.7205e-04 - val_loss: 4.3709e-04\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.7407e-04 - val_loss: 4.4098e-04\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.4996e-04 - val_loss: 4.1821e-04\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.7009e-04 - val_loss: 4.3278e-04\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.5266e-04 - val_loss: 4.3903e-04\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.6208e-04 - val_loss: 4.0816e-04\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.4871e-04 - val_loss: 4.1294e-04\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.4702e-04 - val_loss: 4.2797e-04\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.4119e-04 - val_loss: 4.3804e-04\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.3889e-04 - val_loss: 4.0513e-04\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.4127e-04 - val_loss: 4.0631e-04\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.3765e-04 - val_loss: 3.9423e-04\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.3979e-04 - val_loss: 4.0688e-04\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.3648e-04 - val_loss: 3.9701e-04\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 8ms/step - loss: 5.4163e-04 - val_loss: 3.9760e-04\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.3270e-04 - val_loss: 4.0887e-04\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.2143e-04 - val_loss: 3.9420e-04\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.2030e-04 - val_loss: 4.2830e-04\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.2873e-04 - val_loss: 3.7668e-04\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.2150e-04 - val_loss: 4.1926e-04\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.1624e-04 - val_loss: 4.0887e-04\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.1219e-04 - val_loss: 4.0766e-04\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.1958e-04 - val_loss: 4.1799e-04\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.2689e-04 - val_loss: 3.8167e-04\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.1958e-04 - val_loss: 3.8017e-04\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.0774e-04 - val_loss: 4.1483e-04\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.0584e-04 - val_loss: 3.8266e-04\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.0448e-04 - val_loss: 3.6433e-04\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.0177e-04 - val_loss: 3.8642e-04\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 5.0724e-04 - val_loss: 3.7960e-04\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.8681e-04 - val_loss: 3.7253e-04\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 5.0491e-04 - val_loss: 3.8789e-04\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.0246e-04 - val_loss: 3.7813e-04\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.8681e-04 - val_loss: 3.7150e-04\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.0651e-04 - val_loss: 3.9930e-04\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.9818e-04 - val_loss: 3.7359e-04\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.9146e-04 - val_loss: 3.5317e-04\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.8391e-04 - val_loss: 3.5416e-04\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.7747e-04 - val_loss: 3.7554e-04\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.9536e-04 - val_loss: 3.4509e-04\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.9346e-04 - val_loss: 3.6997e-04\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.8233e-04 - val_loss: 3.6398e-04\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.7188e-04 - val_loss: 3.4359e-04\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.7235e-04 - val_loss: 3.8019e-04\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.7198e-04 - val_loss: 3.5882e-04\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.9238e-04 - val_loss: 3.3405e-04\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.1028e-04 - val_loss: 3.3065e-04\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.7486e-04 - val_loss: 3.5253e-04\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.6632e-04 - val_loss: 4.0330e-04\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.1456e-04 - val_loss: 4.4203e-04\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.9962e-04 - val_loss: 3.3823e-04\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.6898e-04 - val_loss: 3.4899e-04\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.5868e-04 - val_loss: 3.2349e-04\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.6475e-04 - val_loss: 3.3364e-04\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.6532e-04 - val_loss: 3.2261e-04\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.6419e-04 - val_loss: 3.2584e-04\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.7114e-04 - val_loss: 3.2126e-04\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.6005e-04 - val_loss: 3.3125e-04\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.5347e-04 - val_loss: 3.3545e-04\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.6083e-04 - val_loss: 3.6000e-04\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.5245e-04 - val_loss: 3.8531e-04\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.6788e-04 - val_loss: 3.3104e-04\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.6247e-04 - val_loss: 3.2476e-04\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.7503e-04 - val_loss: 3.2253e-04\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.4474e-04 - val_loss: 3.1869e-04\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.5285e-04 - val_loss: 3.0569e-04\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.6422e-04 - val_loss: 3.1083e-04\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.3870e-04 - val_loss: 3.2904e-04\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.6003e-04 - val_loss: 3.3803e-04\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.4828e-04 - val_loss: 3.2159e-04\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.4753e-04 - val_loss: 3.0534e-04\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.4357e-04 - val_loss: 3.4086e-04\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.5585e-04 - val_loss: 2.9773e-04\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.5063e-04 - val_loss: 2.9838e-04\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.4837e-04 - val_loss: 3.6586e-04\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.4421e-04 - val_loss: 3.6188e-04\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.5032e-04 - val_loss: 3.1892e-04\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.2962e-04 - val_loss: 3.0113e-04\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.2734e-04 - val_loss: 3.0501e-04\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.3223e-04 - val_loss: 3.8092e-04\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.4511e-04 - val_loss: 2.9712e-04\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.2462e-04 - val_loss: 2.9538e-04\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.2122e-04 - val_loss: 3.2239e-04\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.4072e-04 - val_loss: 2.8719e-04\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.2258e-04 - val_loss: 3.3051e-04\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.2428e-04 - val_loss: 2.8750e-04\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.4775e-04 - val_loss: 2.8604e-04\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.2801e-04 - val_loss: 2.9303e-04\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.1762e-04 - val_loss: 2.9757e-04\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.3217e-04 - val_loss: 3.0200e-04\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.2169e-04 - val_loss: 2.7726e-04\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.6878e-04 - val_loss: 2.9026e-04\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.2816e-04 - val_loss: 3.0941e-04\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.1404e-04 - val_loss: 2.7795e-04\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.3643e-04 - val_loss: 2.9043e-04\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.1629e-04 - val_loss: 3.0165e-04\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 4.2289e-04 - val_loss: 2.7240e-04\n",
      "Thời gian huấn luyện:  85.42476773262024\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_15 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_63 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 975us/step\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 1s 3ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 1s 3ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Thời gian huấn luyện:  18.222508192062378\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_64 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 1s 8ms/step - loss: 0.0260 - val_loss: 0.0011\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 9.7316e-04\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 8.9599e-04\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 9.3558e-04\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 8.6656e-04\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 8.2082e-04\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 8.2172e-04\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 7.4717e-04\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 7.5237e-04\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 7.2216e-04\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 7.6698e-04\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 7.4397e-04\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 7.0682e-04\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 7.8908e-04\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.7060e-04\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.8888e-04\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 7.0825e-04\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 6.7824e-04\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 6.9774e-04\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 6.6202e-04\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.7729e-04 - val_loss: 6.6015e-04\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.7505e-04 - val_loss: 6.5312e-04\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.6154e-04 - val_loss: 5.9773e-04\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.4789e-04 - val_loss: 6.1127e-04\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.4779e-04 - val_loss: 6.4636e-04\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.2889e-04 - val_loss: 5.6908e-04\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.3957e-04 - val_loss: 5.9202e-04\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.0038e-04 - val_loss: 5.8487e-04\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.8466e-04 - val_loss: 5.7498e-04\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.6430e-04 - val_loss: 5.7167e-04\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.7321e-04 - val_loss: 5.2807e-04\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.5241e-04 - val_loss: 5.4488e-04\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.7009e-04 - val_loss: 5.3306e-04\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.3064e-04 - val_loss: 5.2049e-04\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.5475e-04 - val_loss: 5.1666e-04\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.6736e-04 - val_loss: 4.9645e-04\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 8.3119e-04 - val_loss: 5.0825e-04\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.1728e-04 - val_loss: 5.3037e-04\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.1104e-04 - val_loss: 4.9259e-04\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.8603e-04 - val_loss: 4.9557e-04\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.9076e-04 - val_loss: 4.8941e-04\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.7308e-04 - val_loss: 4.8660e-04\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.5662e-04 - val_loss: 4.8383e-04\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.3792e-04 - val_loss: 4.5814e-04\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.5326e-04 - val_loss: 4.5518e-04\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.8992e-04 - val_loss: 4.6527e-04\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4618e-04 - val_loss: 4.4212e-04\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.5880e-04 - val_loss: 4.8800e-04\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.3913e-04 - val_loss: 4.5909e-04\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.2659e-04 - val_loss: 4.4703e-04\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.2672e-04 - val_loss: 4.4543e-04\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.0037e-04 - val_loss: 4.2979e-04\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.2104e-04 - val_loss: 4.1732e-04\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.5566e-04 - val_loss: 4.4771e-04\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.0273e-04 - val_loss: 4.1930e-04\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.0094e-04 - val_loss: 4.1930e-04\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 6.8914e-04 - val_loss: 4.0855e-04\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.6992e-04 - val_loss: 4.1431e-04\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.0556e-04 - val_loss: 3.9783e-04\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.7091e-04 - val_loss: 4.1238e-04\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.6382e-04 - val_loss: 3.8826e-04\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.7744e-04 - val_loss: 4.3047e-04\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.3654e-04 - val_loss: 4.0599e-04\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.4584e-04 - val_loss: 3.7799e-04\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.8917e-04 - val_loss: 4.5094e-04\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.5045e-04 - val_loss: 4.0631e-04\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.5049e-04 - val_loss: 3.6877e-04\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.4523e-04 - val_loss: 4.1121e-04\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.4532e-04 - val_loss: 4.2523e-04\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.2218e-04 - val_loss: 3.6375e-04\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.6501e-04 - val_loss: 3.5749e-04\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.1585e-04 - val_loss: 3.7407e-04\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.9870e-04 - val_loss: 3.9946e-04\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.0429e-04 - val_loss: 3.7469e-04\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.2924e-04 - val_loss: 3.4706e-04\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 6.0867e-04 - val_loss: 3.7163e-04\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.0005e-04 - val_loss: 3.4089e-04\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.1861e-04 - val_loss: 3.5898e-04\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.8178e-04 - val_loss: 3.6908e-04\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.8754e-04 - val_loss: 3.5025e-04\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.8827e-04 - val_loss: 3.7796e-04\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.7411e-04 - val_loss: 3.2988e-04\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.9403e-04 - val_loss: 3.8714e-04\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.1807e-04 - val_loss: 3.3708e-04\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.7314e-04 - val_loss: 3.3022e-04\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.6571e-04 - val_loss: 3.9115e-04\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.9106e-04 - val_loss: 3.2343e-04\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4714e-04 - val_loss: 3.1755e-04\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.7200e-04 - val_loss: 3.2470e-04\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4536e-04 - val_loss: 3.4564e-04\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4824e-04 - val_loss: 3.0843e-04\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 5.7162e-04 - val_loss: 3.2960e-04\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.1391e-04 - val_loss: 3.4210e-04\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.6592e-04 - val_loss: 3.0404e-04\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 5.3432e-04 - val_loss: 3.1722e-04\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 5.4841e-04 - val_loss: 3.0830e-04\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.6557e-04 - val_loss: 3.0833e-04\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.3409e-04 - val_loss: 3.2095e-04\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4470e-04 - val_loss: 3.0730e-04\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4210e-04 - val_loss: 3.0442e-04\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2464e-04 - val_loss: 3.0362e-04\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2937e-04 - val_loss: 2.8826e-04\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4008e-04 - val_loss: 3.7681e-04\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.5954e-04 - val_loss: 2.9145e-04\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1797e-04 - val_loss: 2.8311e-04\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1718e-04 - val_loss: 2.8990e-04\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.0974e-04 - val_loss: 3.1580e-04\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.3323e-04 - val_loss: 2.7796e-04\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1557e-04 - val_loss: 2.7911e-04\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9632e-04 - val_loss: 3.0074e-04\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9682e-04 - val_loss: 3.0739e-04\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9770e-04 - val_loss: 3.1723e-04\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2631e-04 - val_loss: 2.7348e-04\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.9207e-04 - val_loss: 2.9071e-04\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1141e-04 - val_loss: 2.9518e-04\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9291e-04 - val_loss: 2.7926e-04\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9869e-04 - val_loss: 2.6761e-04\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8485e-04 - val_loss: 2.8407e-04\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8372e-04 - val_loss: 2.9822e-04\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8874e-04 - val_loss: 2.8905e-04\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7878e-04 - val_loss: 2.7487e-04\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9146e-04 - val_loss: 2.6722e-04\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7604e-04 - val_loss: 2.6197e-04\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8608e-04 - val_loss: 3.1772e-04\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2873e-04 - val_loss: 2.5554e-04\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8474e-04 - val_loss: 2.6199e-04\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.8119e-04 - val_loss: 2.5521e-04\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7859e-04 - val_loss: 2.7973e-04\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7714e-04 - val_loss: 2.5262e-04\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7000e-04 - val_loss: 2.4992e-04\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6748e-04 - val_loss: 2.6058e-04\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.6427e-04 - val_loss: 2.4739e-04\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.8158e-04 - val_loss: 2.9490e-04\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7820e-04 - val_loss: 2.4949e-04\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.0993e-04 - val_loss: 2.5854e-04\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6078e-04 - val_loss: 2.4333e-04\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6849e-04 - val_loss: 2.4937e-04\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6344e-04 - val_loss: 2.4350e-04\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7037e-04 - val_loss: 2.4449e-04\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.5983e-04 - val_loss: 2.6656e-04\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6636e-04 - val_loss: 2.3935e-04\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7633e-04 - val_loss: 2.5568e-04\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6679e-04 - val_loss: 2.4339e-04\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6231e-04 - val_loss: 2.3661e-04\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4848e-04 - val_loss: 2.5326e-04\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.5185e-04 - val_loss: 2.5489e-04\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4489e-04 - val_loss: 2.6295e-04\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4109e-04 - val_loss: 2.5838e-04\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4475e-04 - val_loss: 2.3547e-04\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 4.3911e-04 - val_loss: 2.4011e-04\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.6453e-04 - val_loss: 2.3413e-04\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2868e-04 - val_loss: 2.3240e-04\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4559e-04 - val_loss: 2.4561e-04\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4804e-04 - val_loss: 2.2863e-04\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6341e-04 - val_loss: 2.6489e-04\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.5698e-04 - val_loss: 2.3841e-04\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3068e-04 - val_loss: 2.2728e-04\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2564e-04 - val_loss: 2.5168e-04\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.5565e-04 - val_loss: 2.4513e-04\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4603e-04 - val_loss: 2.2541e-04\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3691e-04 - val_loss: 2.3321e-04\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2767e-04 - val_loss: 2.2330e-04\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2763e-04 - val_loss: 2.5123e-04\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2963e-04 - val_loss: 2.3732e-04\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2316e-04 - val_loss: 2.2219e-04\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3445e-04 - val_loss: 2.4432e-04\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4959e-04 - val_loss: 2.4274e-04\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3360e-04 - val_loss: 2.2050e-04\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.2342e-04 - val_loss: 2.1853e-04\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3499e-04 - val_loss: 2.1718e-04\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1705e-04 - val_loss: 2.1787e-04\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3960e-04 - val_loss: 2.2460e-04\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9607e-04 - val_loss: 2.5292e-04\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3884e-04 - val_loss: 2.1574e-04\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1950e-04 - val_loss: 2.2698e-04\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3518e-04 - val_loss: 2.2987e-04\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1809e-04 - val_loss: 2.1445e-04\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2310e-04 - val_loss: 2.1420e-04\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2096e-04 - val_loss: 2.3381e-04\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2455e-04 - val_loss: 2.1232e-04\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3891e-04 - val_loss: 2.2990e-04\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1329e-04 - val_loss: 2.2905e-04\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1866e-04 - val_loss: 2.1727e-04\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1684e-04 - val_loss: 2.1413e-04\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3906e-04 - val_loss: 2.5111e-04\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2065e-04 - val_loss: 2.1012e-04\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.1776e-04 - val_loss: 2.0900e-04\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3641e-04 - val_loss: 2.2016e-04\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1938e-04 - val_loss: 2.2297e-04\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2271e-04 - val_loss: 2.1850e-04\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4280e-04 - val_loss: 2.0762e-04\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1303e-04 - val_loss: 2.0832e-04\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2440e-04 - val_loss: 2.0995e-04\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1702e-04 - val_loss: 2.1811e-04\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1824e-04 - val_loss: 2.1784e-04\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2480e-04 - val_loss: 2.2080e-04\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1788e-04 - val_loss: 2.1028e-04\n",
      "Thời gian huấn luyện:  36.24774765968323\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_16 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_65 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 3s 21ms/step - loss: 0.0346 - val_loss: 0.0032\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 9.9475e-04\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 9.5797e-04\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 9.1934e-04\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 9.7186e-04\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 9.1739e-04\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 8.4799e-04\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 9.6255e-04\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 9.2560e-04\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 9.2740e-04\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 9.1661e-04\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 9.0970e-04\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 9.1012e-04\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 7.7187e-04\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 8.0945e-04\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 8.6705e-04\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 7.5722e-04\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.3408e-04\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.4440e-04\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.0402e-04\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.3013e-04\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.5930e-04\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.0876e-04\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.6493e-04\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.9546e-04\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 7.0192e-04\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 8.0923e-04\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 7.4671e-04\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 6.9022e-04\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.9738e-04\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.5531e-04\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 7.3010e-04\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 6.5778e-04\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 9.9621e-04 - val_loss: 6.3626e-04\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.8253e-04 - val_loss: 6.8745e-04\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 9.8230e-04 - val_loss: 7.3748e-04\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.7898e-04 - val_loss: 6.9765e-04\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 9.6509e-04 - val_loss: 6.5832e-04\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.8082e-04 - val_loss: 6.4339e-04\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.7982e-04 - val_loss: 6.6356e-04\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 9.7467e-04 - val_loss: 6.3178e-04\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.6632e-04 - val_loss: 6.7998e-04\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 9.5191e-04 - val_loss: 6.3502e-04\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.3977e-04 - val_loss: 6.3677e-04\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 9.4927e-04 - val_loss: 6.4665e-04\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.2918e-04 - val_loss: 6.6444e-04\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.3195e-04 - val_loss: 6.0722e-04\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.6718e-04 - val_loss: 6.0101e-04\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 9.3742e-04 - val_loss: 6.3831e-04\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.2412e-04 - val_loss: 6.1101e-04\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.1583e-04 - val_loss: 6.3200e-04\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.1772e-04 - val_loss: 6.8407e-04\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.3938e-04 - val_loss: 6.5292e-04\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.2721e-04 - val_loss: 6.7386e-04\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.3124e-04 - val_loss: 6.4676e-04\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.9803e-04 - val_loss: 6.4328e-04\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 9.2233e-04 - val_loss: 6.2060e-04\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.1738e-04 - val_loss: 6.4808e-04\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.0726e-04 - val_loss: 5.8350e-04\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.2203e-04 - val_loss: 6.5632e-04\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.0134e-04 - val_loss: 6.7120e-04\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.3165e-04 - val_loss: 5.9494e-04\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.1050e-04 - val_loss: 6.4040e-04\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 9.1512e-04 - val_loss: 6.0603e-04\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 8.7482e-04 - val_loss: 5.9721e-04\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.6721e-04 - val_loss: 6.2289e-04\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.6313e-04 - val_loss: 6.3528e-04\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.6126e-04 - val_loss: 5.7744e-04\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.6476e-04 - val_loss: 6.2883e-04\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.6112e-04 - val_loss: 5.7985e-04\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.4982e-04 - val_loss: 6.4568e-04\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.7694e-04 - val_loss: 5.7496e-04\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.4647e-04 - val_loss: 6.1339e-04\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.7381e-04 - val_loss: 5.8918e-04\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.3858e-04 - val_loss: 5.7570e-04\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.6194e-04 - val_loss: 5.6896e-04\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 9ms/step - loss: 9.2264e-04 - val_loss: 6.1377e-04\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.9277e-04 - val_loss: 6.3856e-04\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.4183e-04 - val_loss: 5.7330e-04\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.2681e-04 - val_loss: 5.6795e-04\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 8.5342e-04 - val_loss: 6.2813e-04\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.5702e-04 - val_loss: 6.0607e-04\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.1118e-04 - val_loss: 5.9750e-04\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.2772e-04 - val_loss: 6.0204e-04\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.1383e-04 - val_loss: 5.4163e-04\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.0840e-04 - val_loss: 5.4250e-04\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.2794e-04 - val_loss: 5.6098e-04\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.0870e-04 - val_loss: 5.3327e-04\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.0232e-04 - val_loss: 5.8304e-04\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.8574e-04 - val_loss: 6.0676e-04\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.0680e-04 - val_loss: 6.4456e-04\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.2182e-04 - val_loss: 5.2914e-04\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.8515e-04 - val_loss: 5.9596e-04\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 8.0684e-04 - val_loss: 5.9897e-04\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 8.0329e-04 - val_loss: 5.6092e-04\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.7380e-04 - val_loss: 5.7382e-04\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 8.0993e-04 - val_loss: 5.2858e-04\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.7450e-04 - val_loss: 5.6764e-04\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.9359e-04 - val_loss: 5.5213e-04\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.7597e-04 - val_loss: 5.9685e-04\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.5983e-04 - val_loss: 5.2369e-04\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.6829e-04 - val_loss: 5.0736e-04\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.8409e-04 - val_loss: 6.4791e-04\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.6830e-04 - val_loss: 5.8925e-04\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 7.6336e-04 - val_loss: 6.4489e-04\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.5082e-04 - val_loss: 5.3300e-04\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.6713e-04 - val_loss: 5.3002e-04\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.7222e-04 - val_loss: 5.1093e-04\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.5186e-04 - val_loss: 5.1648e-04\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.4090e-04 - val_loss: 5.3731e-04\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.6057e-04 - val_loss: 5.0851e-04\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.2418e-04 - val_loss: 5.1233e-04\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 7.3736e-04 - val_loss: 5.2205e-04\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.5410e-04 - val_loss: 5.0868e-04\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.2582e-04 - val_loss: 5.3794e-04\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.3394e-04 - val_loss: 5.2196e-04\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 7.2316e-04 - val_loss: 5.1318e-04\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.1202e-04 - val_loss: 5.1058e-04\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.1736e-04 - val_loss: 6.0747e-04\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.3577e-04 - val_loss: 5.9099e-04\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.1629e-04 - val_loss: 5.1361e-04\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.1057e-04 - val_loss: 5.5164e-04\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.0726e-04 - val_loss: 5.0401e-04\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.2163e-04 - val_loss: 4.9476e-04\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.8415e-04 - val_loss: 4.7109e-04\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.1618e-04 - val_loss: 5.0172e-04\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 7.0079e-04 - val_loss: 5.3218e-04\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.8303e-04 - val_loss: 4.9652e-04\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.8657e-04 - val_loss: 5.0419e-04\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 6.8437e-04 - val_loss: 5.1297e-04\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.8368e-04 - val_loss: 4.7192e-04\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.0949e-04 - val_loss: 4.6888e-04\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 7.0637e-04 - val_loss: 4.6812e-04\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.7241e-04 - val_loss: 4.7243e-04\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.7344e-04 - val_loss: 4.9346e-04\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.7174e-04 - val_loss: 4.7056e-04\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.6334e-04 - val_loss: 4.6721e-04\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 6.6842e-04 - val_loss: 4.6109e-04\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.6972e-04 - val_loss: 4.9135e-04\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.5384e-04 - val_loss: 4.5424e-04\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.5658e-04 - val_loss: 4.7007e-04\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.5798e-04 - val_loss: 4.7297e-04\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.7395e-04 - val_loss: 4.9431e-04\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.4521e-04 - val_loss: 4.5744e-04\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.5369e-04 - val_loss: 5.3584e-04\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.6007e-04 - val_loss: 5.0052e-04\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.7597e-04 - val_loss: 4.5717e-04\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.3597e-04 - val_loss: 4.7859e-04\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.5011e-04 - val_loss: 4.3366e-04\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.6561e-04 - val_loss: 4.3883e-04\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.6135e-04 - val_loss: 4.7665e-04\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.3416e-04 - val_loss: 4.5499e-04\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.4802e-04 - val_loss: 4.5609e-04\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.2550e-04 - val_loss: 5.8569e-04\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 6.6672e-04 - val_loss: 4.3535e-04\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.2195e-04 - val_loss: 4.8640e-04\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.2297e-04 - val_loss: 4.7851e-04\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.2178e-04 - val_loss: 4.3323e-04\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.2115e-04 - val_loss: 4.5845e-04\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.1056e-04 - val_loss: 4.7075e-04\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.1856e-04 - val_loss: 5.1135e-04\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.2829e-04 - val_loss: 4.8475e-04\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.4981e-04 - val_loss: 5.4242e-04\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 6.3195e-04 - val_loss: 4.3748e-04\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 6.1912e-04 - val_loss: 4.5157e-04\n",
      "Thời gian huấn luyện:  84.90271401405334\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_66 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 3s 19ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2316 - val_loss: 0.0475\n",
      "Thời gian huấn luyện:  81.78985524177551\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_16 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_67 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 1s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 1s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 1s 6ms/step - loss: 0.0796 - val_loss: 0.0256\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0114\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0095\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0078\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 9.9869e-04\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 9.8049e-04\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.8621e-04\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 9.2579e-04\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.8968e-04\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.6195e-04\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.8200e-04\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.1649e-04\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.2527e-04\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.8629e-04\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.8931e-04\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 8.7151e-04\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 8.2197e-04\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 8.1111e-04\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.5976e-04\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.9147e-04\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 8.6187e-04\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.8299e-04\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.8408e-04\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.5785e-04\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.2279e-04\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.3405e-04\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.1309e-04\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.4172e-04\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.3213e-04\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.2574e-04\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 7.6063e-04\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.8397e-04\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.5479e-04\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 7.0463e-04\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.7714e-04\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 6.5950e-04\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.6395e-04\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.1577e-04\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.9526e-04\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.0160e-04\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.8071e-04\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.9984e-04\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.2572e-04\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.3524e-04\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.4986e-04\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.8657e-04\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.9842e-04\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 6.1180e-04\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.2630e-04\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 5.7492e-04\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 6.1852e-04\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 9.9696e-04 - val_loss: 5.4433e-04\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 9.8696e-04 - val_loss: 5.6863e-04\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 9.7586e-04 - val_loss: 5.9262e-04\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 9.6592e-04 - val_loss: 5.4124e-04\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 9.6181e-04 - val_loss: 6.0134e-04\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 9.7721e-04 - val_loss: 5.6556e-04\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 9.3882e-04 - val_loss: 6.0025e-04\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 9.3009e-04 - val_loss: 5.5694e-04\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 9.2348e-04 - val_loss: 5.8944e-04\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 9.2441e-04 - val_loss: 5.4494e-04\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 9.0546e-04 - val_loss: 5.2377e-04\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.9306e-04 - val_loss: 5.3663e-04\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.8823e-04 - val_loss: 4.7589e-04\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.7532e-04 - val_loss: 4.8691e-04\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.6927e-04 - val_loss: 5.4090e-04\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.6476e-04 - val_loss: 4.7490e-04\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 8.6411e-04 - val_loss: 4.8684e-04\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.4314e-04 - val_loss: 4.7685e-04\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 8.3831e-04 - val_loss: 4.9352e-04\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.2965e-04 - val_loss: 4.9600e-04\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 8.1331e-04 - val_loss: 5.4632e-04\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.1558e-04 - val_loss: 5.3348e-04\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 8.0473e-04 - val_loss: 4.6001e-04\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.9220e-04 - val_loss: 4.6985e-04\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.9171e-04 - val_loss: 4.7972e-04\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.8190e-04 - val_loss: 4.3554e-04\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 7.7342e-04 - val_loss: 4.5704e-04\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.6475e-04 - val_loss: 4.5312e-04\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.6592e-04 - val_loss: 4.3424e-04\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.5567e-04 - val_loss: 4.2445e-04\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.4053e-04 - val_loss: 4.7676e-04\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 7.3834e-04 - val_loss: 4.0428e-04\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.3036e-04 - val_loss: 4.0391e-04\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.3504e-04 - val_loss: 4.3047e-04\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.1918e-04 - val_loss: 4.0469e-04\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 7.1982e-04 - val_loss: 4.3567e-04\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.1508e-04 - val_loss: 4.0893e-04\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.0320e-04 - val_loss: 3.9093e-04\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 7.0416e-04 - val_loss: 3.9736e-04\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.9081e-04 - val_loss: 4.1138e-04\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.8503e-04 - val_loss: 3.9316e-04\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.8224e-04 - val_loss: 3.8092e-04\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.8179e-04 - val_loss: 3.8094e-04\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.7525e-04 - val_loss: 3.7112e-04\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.6797e-04 - val_loss: 3.6582e-04\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.7035e-04 - val_loss: 3.5192e-04\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.6194e-04 - val_loss: 4.0159e-04\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.5543e-04 - val_loss: 3.7392e-04\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.5116e-04 - val_loss: 3.7835e-04\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.4460e-04 - val_loss: 3.5667e-04\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.4075e-04 - val_loss: 3.5633e-04\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.3809e-04 - val_loss: 3.4133e-04\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3613e-04 - val_loss: 3.7760e-04\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.3451e-04 - val_loss: 3.6943e-04\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.2861e-04 - val_loss: 3.3713e-04\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.2546e-04 - val_loss: 3.5981e-04\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.2529e-04 - val_loss: 3.8414e-04\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.3040e-04 - val_loss: 3.2741e-04\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.2310e-04 - val_loss: 4.1540e-04\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.1485e-04 - val_loss: 3.4216e-04\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6.1236e-04 - val_loss: 3.2614e-04\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.1197e-04 - val_loss: 3.9473e-04\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.0757e-04 - val_loss: 3.3980e-04\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.0062e-04 - val_loss: 3.2357e-04\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 6.0096e-04 - val_loss: 3.6727e-04\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.9844e-04 - val_loss: 3.3323e-04\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9276e-04 - val_loss: 3.2257e-04\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9365e-04 - val_loss: 3.2620e-04\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9177e-04 - val_loss: 3.0641e-04\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9596e-04 - val_loss: 3.1358e-04\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8344e-04 - val_loss: 3.1657e-04\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8248e-04 - val_loss: 3.1590e-04\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.9018e-04 - val_loss: 3.5069e-04\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.8434e-04 - val_loss: 3.0369e-04\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7876e-04 - val_loss: 3.2899e-04\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7588e-04 - val_loss: 3.3513e-04\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.7405e-04 - val_loss: 3.3932e-04\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7920e-04 - val_loss: 3.0583e-04\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6814e-04 - val_loss: 3.1778e-04\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6788e-04 - val_loss: 3.2301e-04\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7059e-04 - val_loss: 3.3418e-04\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7536e-04 - val_loss: 3.2170e-04\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6401e-04 - val_loss: 2.9028e-04\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6065e-04 - val_loss: 3.2184e-04\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6387e-04 - val_loss: 2.8673e-04\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.6512e-04 - val_loss: 3.3873e-04\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.6123e-04 - val_loss: 2.9738e-04\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.5794e-04 - val_loss: 2.9253e-04\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5344e-04 - val_loss: 2.8429e-04\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.7397e-04 - val_loss: 3.1446e-04\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.5680e-04 - val_loss: 3.0359e-04\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5512e-04 - val_loss: 3.1513e-04\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4900e-04 - val_loss: 3.0256e-04\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5821e-04 - val_loss: 3.4963e-04\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.6208e-04 - val_loss: 3.0273e-04\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4433e-04 - val_loss: 2.9870e-04\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4562e-04 - val_loss: 2.9102e-04\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.5195e-04 - val_loss: 2.9775e-04\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4072e-04 - val_loss: 2.8129e-04\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4592e-04 - val_loss: 3.3759e-04\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4170e-04 - val_loss: 3.4220e-04\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.4308e-04 - val_loss: 3.0336e-04\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.4146e-04 - val_loss: 3.0185e-04\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3626e-04 - val_loss: 2.9406e-04\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3611e-04 - val_loss: 2.9443e-04\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3576e-04 - val_loss: 3.3068e-04\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3336e-04 - val_loss: 2.7364e-04\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2993e-04 - val_loss: 2.8730e-04\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.3391e-04 - val_loss: 3.1154e-04\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3240e-04 - val_loss: 2.7013e-04\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2829e-04 - val_loss: 2.9132e-04\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.3628e-04 - val_loss: 3.0737e-04\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2572e-04 - val_loss: 3.1799e-04\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2370e-04 - val_loss: 2.9983e-04\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2228e-04 - val_loss: 2.7140e-04\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2184e-04 - val_loss: 3.0153e-04\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2239e-04 - val_loss: 2.8415e-04\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2597e-04 - val_loss: 2.7224e-04\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.1879e-04 - val_loss: 2.8299e-04\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2214e-04 - val_loss: 2.7884e-04\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.1875e-04 - val_loss: 2.7863e-04\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.1758e-04 - val_loss: 2.8903e-04\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.1912e-04 - val_loss: 2.6224e-04\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2231e-04 - val_loss: 2.7920e-04\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1365e-04 - val_loss: 2.6520e-04\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1672e-04 - val_loss: 2.8381e-04\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2394e-04 - val_loss: 3.1033e-04\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0970e-04 - val_loss: 2.6432e-04\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.0985e-04 - val_loss: 2.6600e-04\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.1473e-04 - val_loss: 2.7531e-04\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1492e-04 - val_loss: 2.6103e-04\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1530e-04 - val_loss: 2.6759e-04\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1300e-04 - val_loss: 2.5774e-04\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.2054e-04 - val_loss: 2.8386e-04\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.0196e-04 - val_loss: 2.5594e-04\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.0315e-04 - val_loss: 2.7081e-04\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.1249e-04 - val_loss: 2.8581e-04\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5.0427e-04 - val_loss: 2.5625e-04\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.0215e-04 - val_loss: 2.7033e-04\n",
      "Thời gian huấn luyện:  19.84563970565796\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_85 (Dense)            (None, 10, 116)           232       \n",
      "                                                                 \n",
      " flatten_68 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 2s 14ms/step - loss: 0.0032 - val_loss: 9.0586e-04\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 6.3698e-04\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 7.0205e-04\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 6.0682e-04\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 5.8761e-04\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 4.9590e-04\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.5801e-04 - val_loss: 4.7370e-04\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.4288e-04 - val_loss: 4.5881e-04\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.6496e-04\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.3834e-04 - val_loss: 5.6933e-04\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.2889e-04 - val_loss: 5.3654e-04\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.9033e-04 - val_loss: 4.3403e-04\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 9.0260e-04 - val_loss: 4.0797e-04\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 8.7034e-04 - val_loss: 4.0214e-04\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.8001e-04 - val_loss: 3.9354e-04\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.0121e-04 - val_loss: 3.9281e-04\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.8276e-04 - val_loss: 4.5292e-04\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.7122e-04 - val_loss: 3.8729e-04\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 7.7314e-04 - val_loss: 5.0515e-04\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 7.7574e-04 - val_loss: 3.7606e-04\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.8883e-04 - val_loss: 3.9931e-04\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 8.2750e-04 - val_loss: 3.7118e-04\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.2502e-04 - val_loss: 4.1192e-04\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.4080e-04 - val_loss: 3.9353e-04\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.5512e-04 - val_loss: 4.1358e-04\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.8426e-04 - val_loss: 3.4526e-04\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.4111e-04 - val_loss: 4.0596e-04\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.0026e-04 - val_loss: 3.4656e-04\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 4ms/step - loss: 7.0285e-04 - val_loss: 3.7286e-04\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.7735e-04 - val_loss: 3.3852e-04\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.0813e-04 - val_loss: 3.2884e-04\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.0472e-04 - val_loss: 3.3011e-04\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.7400e-04 - val_loss: 3.4414e-04\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.5328e-04 - val_loss: 3.2719e-04\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.0160e-04 - val_loss: 3.2007e-04\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.5501e-04 - val_loss: 3.2599e-04\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.4828e-04 - val_loss: 3.4557e-04\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 6.5667e-04 - val_loss: 3.6017e-04\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 6.8285e-04 - val_loss: 3.7792e-04\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.7244e-04 - val_loss: 3.8283e-04\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.4527e-04 - val_loss: 4.7943e-04\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7.1077e-04 - val_loss: 3.8341e-04\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.1915e-04 - val_loss: 3.4413e-04\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3244e-04 - val_loss: 3.9669e-04\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.8096e-04 - val_loss: 3.1493e-04\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3833e-04 - val_loss: 2.9246e-04\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.4979e-04 - val_loss: 3.1919e-04\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.0332e-04 - val_loss: 2.9307e-04\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.0999e-04 - val_loss: 2.9424e-04\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.9998e-04 - val_loss: 3.0653e-04\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3948e-04 - val_loss: 3.2810e-04\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.0365e-04 - val_loss: 3.4044e-04\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.3981e-04 - val_loss: 3.3922e-04\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.9551e-04 - val_loss: 3.0159e-04\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.1470e-04 - val_loss: 2.8536e-04\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.0588e-04 - val_loss: 2.9845e-04\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.7121e-04 - val_loss: 2.7809e-04\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 6.2938e-04 - val_loss: 2.7668e-04\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.8743e-04 - val_loss: 3.9852e-04\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6.0209e-04 - val_loss: 3.0027e-04\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.8012e-04 - val_loss: 3.1457e-04\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.7154e-04 - val_loss: 2.9669e-04\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.8811e-04 - val_loss: 2.8265e-04\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5869e-04 - val_loss: 3.3223e-04\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6615e-04 - val_loss: 2.6664e-04\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 6.0608e-04 - val_loss: 3.0462e-04\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.8640e-04 - val_loss: 2.6532e-04\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.7445e-04 - val_loss: 2.6025e-04\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5031e-04 - val_loss: 2.8900e-04\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.8864e-04 - val_loss: 2.8792e-04\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5573e-04 - val_loss: 2.5455e-04\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.7501e-04 - val_loss: 2.5368e-04\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5112e-04 - val_loss: 2.5793e-04\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.4359e-04 - val_loss: 2.5683e-04\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2278e-04 - val_loss: 2.6749e-04\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6705e-04 - val_loss: 2.6417e-04\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.7415e-04 - val_loss: 2.4847e-04\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.3183e-04 - val_loss: 2.5873e-04\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2065e-04 - val_loss: 2.5220e-04\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.4533e-04 - val_loss: 2.8360e-04\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2866e-04 - val_loss: 2.5448e-04\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1618e-04 - val_loss: 2.6364e-04\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.4819e-04 - val_loss: 2.4425e-04\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.3609e-04 - val_loss: 2.4524e-04\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.4032e-04 - val_loss: 2.6098e-04\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.9878e-04 - val_loss: 2.7364e-04\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6868e-04 - val_loss: 3.0476e-04\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.6277e-04 - val_loss: 2.3760e-04\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5.1249e-04 - val_loss: 2.6112e-04\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1185e-04 - val_loss: 2.4039e-04\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2172e-04 - val_loss: 2.5205e-04\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1669e-04 - val_loss: 2.6333e-04\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0881e-04 - val_loss: 3.2663e-04\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2436e-04 - val_loss: 2.9103e-04\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.3602e-04 - val_loss: 2.3233e-04\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1318e-04 - val_loss: 3.0023e-04\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.4657e-04 - val_loss: 3.3312e-04\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 5.1203e-04 - val_loss: 2.5690e-04\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 5.4269e-04 - val_loss: 2.3458e-04\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5260e-04 - val_loss: 2.3697e-04\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2792e-04 - val_loss: 2.6411e-04\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.9417e-04 - val_loss: 2.2766e-04\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1633e-04 - val_loss: 2.4095e-04\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.9548e-04 - val_loss: 2.2653e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0196e-04 - val_loss: 2.2596e-04\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0726e-04 - val_loss: 2.3642e-04\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.0410e-04 - val_loss: 2.2458e-04\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.9779e-04 - val_loss: 2.3448e-04\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8130e-04 - val_loss: 2.3149e-04\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.9980e-04 - val_loss: 2.2274e-04\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7932e-04 - val_loss: 2.3380e-04\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8667e-04 - val_loss: 2.2559e-04\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.5380e-04 - val_loss: 2.2306e-04\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8575e-04 - val_loss: 2.2318e-04\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.3089e-04 - val_loss: 2.2430e-04\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2698e-04 - val_loss: 2.2293e-04\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8117e-04 - val_loss: 2.4893e-04\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 4.8171e-04 - val_loss: 2.1846e-04\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8644e-04 - val_loss: 3.0251e-04\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8313e-04 - val_loss: 2.1667e-04\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8092e-04 - val_loss: 2.2879e-04\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7831e-04 - val_loss: 2.7180e-04\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.1166e-04 - val_loss: 2.2031e-04\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7465e-04 - val_loss: 2.5658e-04\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5.2530e-04 - val_loss: 2.1250e-04\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.9360e-04 - val_loss: 2.1270e-04\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5605e-04 - val_loss: 2.3606e-04\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.9010e-04 - val_loss: 2.1278e-04\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7446e-04 - val_loss: 2.2516e-04\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8291e-04 - val_loss: 2.1758e-04\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7015e-04 - val_loss: 2.1090e-04\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7212e-04 - val_loss: 2.1164e-04\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5881e-04 - val_loss: 2.2511e-04\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6425e-04 - val_loss: 2.1296e-04\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5262e-04 - val_loss: 2.1003e-04\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7884e-04 - val_loss: 2.2264e-04\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7059e-04 - val_loss: 2.0704e-04\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 4.6565e-04 - val_loss: 2.0924e-04\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6970e-04 - val_loss: 2.0594e-04\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6665e-04 - val_loss: 2.1219e-04\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7813e-04 - val_loss: 2.2459e-04\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6225e-04 - val_loss: 2.1076e-04\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6754e-04 - val_loss: 2.0607e-04\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5024e-04 - val_loss: 2.0667e-04\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5222e-04 - val_loss: 2.1184e-04\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5773e-04 - val_loss: 2.0292e-04\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5750e-04 - val_loss: 2.0891e-04\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5826e-04 - val_loss: 2.0780e-04\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6320e-04 - val_loss: 2.0512e-04\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4587e-04 - val_loss: 2.1141e-04\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8548e-04 - val_loss: 2.4616e-04\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4448e-04 - val_loss: 2.1042e-04\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6352e-04 - val_loss: 2.0268e-04\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5274e-04 - val_loss: 2.0112e-04\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6828e-04 - val_loss: 2.4084e-04\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5152e-04 - val_loss: 2.1815e-04\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 4.6197e-04 - val_loss: 2.7348e-04\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 4.9109e-04 - val_loss: 2.0113e-04\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 4.4970e-04 - val_loss: 1.9947e-04\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.6794e-04 - val_loss: 1.9904e-04\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4603e-04 - val_loss: 1.9815e-04\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4912e-04 - val_loss: 1.9645e-04\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3209e-04 - val_loss: 2.2129e-04\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5953e-04 - val_loss: 2.0876e-04\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8605e-04 - val_loss: 2.1830e-04\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5800e-04 - val_loss: 2.1628e-04\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3409e-04 - val_loss: 2.0275e-04\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5759e-04 - val_loss: 1.9803e-04\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4381e-04 - val_loss: 2.0095e-04\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4035e-04 - val_loss: 1.9519e-04\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3195e-04 - val_loss: 2.1909e-04\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4564e-04 - val_loss: 1.9757e-04\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4314e-04 - val_loss: 2.0434e-04\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7924e-04 - val_loss: 2.5323e-04\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4904e-04 - val_loss: 1.9229e-04\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4626e-04 - val_loss: 1.9476e-04\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 4.3287e-04 - val_loss: 2.0324e-04\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4197e-04 - val_loss: 1.9183e-04\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3130e-04 - val_loss: 1.9388e-04\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3648e-04 - val_loss: 1.9945e-04\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2582e-04 - val_loss: 1.9093e-04\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2550e-04 - val_loss: 1.9022e-04\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2808e-04 - val_loss: 1.9066e-04\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2813e-04 - val_loss: 1.9041e-04\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3451e-04 - val_loss: 1.9254e-04\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3566e-04 - val_loss: 2.1054e-04\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2533e-04 - val_loss: 1.9817e-04\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3491e-04 - val_loss: 1.9244e-04\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3599e-04 - val_loss: 2.0532e-04\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3451e-04 - val_loss: 1.9409e-04\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.3218e-04 - val_loss: 1.8932e-04\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.8022e-04 - val_loss: 1.8910e-04\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.7755e-04 - val_loss: 1.9105e-04\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.9938e-04 - val_loss: 2.0673e-04\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4356e-04 - val_loss: 2.2306e-04\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 4.4039e-04 - val_loss: 1.8779e-04\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 4.3053e-04 - val_loss: 1.8732e-04\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.2756e-04 - val_loss: 1.8780e-04\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4300e-04 - val_loss: 1.8764e-04\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.4682e-04 - val_loss: 1.9045e-04\n",
      "Thời gian huấn luyện:  35.194249629974365\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_17 (SimpleRNN)   (None, 10, 116)           13688     \n",
      "                                                                 \n",
      " flatten_69 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 3s 27ms/step - loss: 0.0299 - val_loss: 0.0023\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 9.9673e-04\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 9.3573e-04\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 9.3645e-04\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 9.1265e-04\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 9.2918e-04\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 8.7817e-04\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 9.0791e-04\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 8.2211e-04\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 9.3157e-04\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 8.3682e-04\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 8.6534e-04\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 9.5132e-04\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 8.1050e-04\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 8.6421e-04\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 8.2917e-04\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 8.4244e-04\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 7.8288e-04\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 7.6963e-04\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 8.1672e-04\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 7.1914e-04\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 8.4751e-04\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 7.9187e-04\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 6.7592e-04\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 6.4230e-04\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 6.3771e-04\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.7571e-04\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 7.9640e-04\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.5809e-04\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 7.4601e-04\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 6.2161e-04\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.3145e-04\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.7046e-04\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.4028e-04\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.8165e-04\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.4392e-04\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.3065e-04\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.7076e-04\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.2947e-04\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 6.1304e-04\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.8491e-04\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.2523e-04\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.1567e-04\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.5291e-04\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.1385e-04\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.9436e-04\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 7.0734e-04\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.6375e-04\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 6.4486e-04\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.3862e-04\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.5360e-04\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.4010e-04\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.0529e-04\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.1326e-04\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.1526e-04\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.4905e-04\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.9261e-04 - val_loss: 5.2578e-04\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 7.2661e-04\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.9937e-04 - val_loss: 5.3502e-04\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.8311e-04 - val_loss: 5.3907e-04\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.5443e-04\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.8852e-04 - val_loss: 5.3462e-04\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.6783e-04 - val_loss: 5.7842e-04\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.5689e-04 - val_loss: 5.6471e-04\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.6077e-04 - val_loss: 6.0810e-04\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 9.6840e-04 - val_loss: 5.0633e-04\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.7664e-04 - val_loss: 6.0239e-04\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 6.3174e-04\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.3349e-04\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.4786e-04 - val_loss: 6.1866e-04\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.8972e-04 - val_loss: 5.0681e-04\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.3630e-04 - val_loss: 5.1807e-04\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.5498e-04 - val_loss: 6.1997e-04\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 9.4607e-04 - val_loss: 5.4151e-04\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 9.2419e-04 - val_loss: 5.3617e-04\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 9.2411e-04 - val_loss: 5.2530e-04\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.0322e-04 - val_loss: 5.7221e-04\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.2064e-04 - val_loss: 5.8409e-04\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.2020e-04 - val_loss: 5.0046e-04\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.2293e-04 - val_loss: 5.0790e-04\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.9742e-04 - val_loss: 4.8982e-04\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.2816e-04 - val_loss: 5.3947e-04\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.1178e-04 - val_loss: 4.9787e-04\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 9.3710e-04 - val_loss: 5.4743e-04\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.8900e-04 - val_loss: 5.0396e-04\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.7922e-04 - val_loss: 4.9938e-04\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 8.8903e-04 - val_loss: 6.0678e-04\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.2673e-04 - val_loss: 4.7441e-04\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.8043e-04 - val_loss: 4.9481e-04\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.9190e-04 - val_loss: 5.1466e-04\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.9630e-04 - val_loss: 4.9254e-04\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.9131e-04 - val_loss: 4.9648e-04\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 8.7039e-04 - val_loss: 4.7385e-04\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.5682e-04 - val_loss: 4.7195e-04\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 8.7678e-04 - val_loss: 5.3344e-04\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.7588e-04 - val_loss: 4.7441e-04\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.5240e-04 - val_loss: 4.7420e-04\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.4786e-04 - val_loss: 4.9519e-04\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.4881e-04 - val_loss: 4.5481e-04\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.4206e-04 - val_loss: 5.3693e-04\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 8.3280e-04 - val_loss: 4.7378e-04\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 8.5705e-04 - val_loss: 4.5941e-04\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.6147e-04 - val_loss: 5.3047e-04\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.3705e-04 - val_loss: 4.8353e-04\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.1038e-04 - val_loss: 4.5656e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.1590e-04 - val_loss: 4.7181e-04\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.1453e-04 - val_loss: 4.7263e-04\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.1118e-04 - val_loss: 5.3450e-04\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.0912e-04 - val_loss: 4.6522e-04\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 8.0474e-04 - val_loss: 4.5917e-04\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.0439e-04 - val_loss: 4.6096e-04\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.1136e-04 - val_loss: 4.6284e-04\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 8.1152e-04 - val_loss: 4.5262e-04\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.0599e-04 - val_loss: 4.6879e-04\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.1035e-04 - val_loss: 4.4511e-04\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.8096e-04 - val_loss: 4.5023e-04\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.7573e-04 - val_loss: 4.4451e-04\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.7892e-04 - val_loss: 4.4312e-04\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.6935e-04 - val_loss: 4.7127e-04\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.7084e-04 - val_loss: 4.4472e-04\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.7344e-04 - val_loss: 4.5898e-04\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.5336e-04 - val_loss: 4.6524e-04\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.1109e-04 - val_loss: 4.2803e-04\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.5220e-04 - val_loss: 4.4179e-04\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.5092e-04 - val_loss: 4.6130e-04\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.4351e-04 - val_loss: 4.3556e-04\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.6137e-04 - val_loss: 4.1325e-04\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.7716e-04 - val_loss: 4.1248e-04\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.4924e-04 - val_loss: 4.2499e-04\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2985e-04 - val_loss: 4.1785e-04\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.5829e-04 - val_loss: 4.8924e-04\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.7484e-04 - val_loss: 4.1116e-04\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.6116e-04 - val_loss: 4.1380e-04\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.3198e-04 - val_loss: 4.1187e-04\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.1673e-04 - val_loss: 4.9503e-04\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.3205e-04 - val_loss: 4.2585e-04\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.3368e-04 - val_loss: 4.0466e-04\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.2382e-04 - val_loss: 4.1901e-04\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.3095e-04 - val_loss: 4.1339e-04\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.0469e-04 - val_loss: 4.1405e-04\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2004e-04 - val_loss: 3.9189e-04\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9924e-04 - val_loss: 4.7191e-04\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.2024e-04 - val_loss: 4.4601e-04\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.0413e-04 - val_loss: 4.1546e-04\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.0525e-04 - val_loss: 4.3871e-04\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.8458e-04 - val_loss: 3.8395e-04\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.0448e-04 - val_loss: 3.9456e-04\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8734e-04 - val_loss: 4.0928e-04\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.9346e-04 - val_loss: 4.8473e-04\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.2638e-04 - val_loss: 3.8497e-04\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8789e-04 - val_loss: 4.1175e-04\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.9891e-04 - val_loss: 4.7517e-04\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.9059e-04 - val_loss: 4.2697e-04\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.8593e-04 - val_loss: 4.0615e-04\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.6911e-04 - val_loss: 3.8146e-04\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.6695e-04 - val_loss: 3.8204e-04\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.7666e-04 - val_loss: 4.5768e-04\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.0693e-04 - val_loss: 3.9005e-04\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.7821e-04 - val_loss: 4.2151e-04\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.6285e-04 - val_loss: 4.2545e-04\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.7848e-04 - val_loss: 3.9866e-04\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.9007e-04 - val_loss: 4.3600e-04\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.7560e-04 - val_loss: 4.1781e-04\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.4541e-04 - val_loss: 3.9988e-04\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.4977e-04 - val_loss: 3.6351e-04\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8932e-04 - val_loss: 3.6303e-04\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6323e-04 - val_loss: 3.8934e-04\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3702e-04 - val_loss: 3.9754e-04\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4953e-04 - val_loss: 3.6545e-04\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.3146e-04 - val_loss: 3.7245e-04\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4584e-04 - val_loss: 3.9896e-04\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3475e-04 - val_loss: 4.1021e-04\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4807e-04 - val_loss: 4.6865e-04\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.4394e-04 - val_loss: 3.7996e-04\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.3598e-04 - val_loss: 3.6045e-04\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2634e-04 - val_loss: 3.5998e-04\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3099e-04 - val_loss: 4.1621e-04\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4422e-04 - val_loss: 3.7502e-04\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2357e-04 - val_loss: 4.1987e-04\n",
      "Thời gian huấn luyện:  76.90853142738342\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_17 (LSTM)              (None, 10, 116)           54752     \n",
      "                                                                 \n",
      " flatten_70 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,913\n",
      "Trainable params: 55,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 2s 18ms/step - loss: 0.0294 - val_loss: 0.0015\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 8.8833e-04\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 8.3780e-04\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 7.9946e-04\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 8.0358e-04\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 8.0957e-04\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 8.2413e-04\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 8.4356e-04\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 7.3470e-04\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 7.2789e-04\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 7.4372e-04\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.2003e-04\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 7.5164e-04\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 6.7323e-04\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 6.9906e-04\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 6.9939e-04\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.3200e-04\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.4306e-04\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 6.0854e-04\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 6.3246e-04\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 6.9561e-04\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.1619e-04\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 6.8881e-04\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 5.8070e-04\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 5.7787e-04\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 5.7713e-04\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.7931e-04\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 5.3252e-04\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 5.5666e-04\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 5.7438e-04\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 9.9324e-04 - val_loss: 5.2449e-04\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 9.7949e-04 - val_loss: 5.4525e-04\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 9.7818e-04 - val_loss: 5.2656e-04\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 9.5622e-04 - val_loss: 5.7875e-04\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 9.5109e-04 - val_loss: 5.0600e-04\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 9.3060e-04 - val_loss: 5.3216e-04\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 9.1787e-04 - val_loss: 5.7130e-04\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 9.0814e-04 - val_loss: 5.5729e-04\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.9374e-04 - val_loss: 4.9581e-04\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.8765e-04 - val_loss: 5.4590e-04\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.7397e-04 - val_loss: 5.3389e-04\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.6439e-04 - val_loss: 5.2468e-04\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.6885e-04 - val_loss: 4.6631e-04\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.6423e-04 - val_loss: 4.6148e-04\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.6334e-04 - val_loss: 4.4849e-04\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.5857e-04 - val_loss: 4.5916e-04\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.4758e-04 - val_loss: 4.6751e-04\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 8.3401e-04 - val_loss: 4.9446e-04\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.2146e-04 - val_loss: 4.8944e-04\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.1984e-04 - val_loss: 4.4365e-04\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.0880e-04 - val_loss: 4.7191e-04\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.2398e-04 - val_loss: 4.3771e-04\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 8.0487e-04 - val_loss: 4.3532e-04\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.3036e-04 - val_loss: 4.4275e-04\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.0690e-04 - val_loss: 4.3636e-04\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 7.9522e-04 - val_loss: 4.5319e-04\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.2511e-04 - val_loss: 5.4466e-04\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 7.9045e-04 - val_loss: 5.0601e-04\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.7390e-04 - val_loss: 4.2811e-04\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.9376e-04 - val_loss: 4.6091e-04\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.7084e-04 - val_loss: 4.6544e-04\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.6984e-04 - val_loss: 4.5812e-04\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 7.8549e-04 - val_loss: 4.8665e-04\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.4573e-04 - val_loss: 5.1110e-04\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 8.0707e-04 - val_loss: 4.1645e-04\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.4625e-04 - val_loss: 4.1625e-04\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.3748e-04 - val_loss: 4.1112e-04\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.3876e-04 - val_loss: 4.1674e-04\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.3599e-04 - val_loss: 4.1437e-04\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.3075e-04 - val_loss: 3.9956e-04\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 7.6062e-04 - val_loss: 4.1420e-04\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.1686e-04 - val_loss: 4.2508e-04\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.3017e-04 - val_loss: 3.9671e-04\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 7.1139e-04 - val_loss: 4.0818e-04\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 7.2090e-04 - val_loss: 4.1345e-04\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 7.3269e-04 - val_loss: 4.2752e-04\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.9108e-04 - val_loss: 4.2003e-04\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.9026e-04 - val_loss: 3.9615e-04\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.9456e-04 - val_loss: 3.9580e-04\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.9897e-04 - val_loss: 3.8755e-04\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.9339e-04 - val_loss: 4.0478e-04\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.8246e-04 - val_loss: 3.8042e-04\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.7608e-04 - val_loss: 4.0240e-04\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.8522e-04 - val_loss: 3.6752e-04\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.7667e-04 - val_loss: 3.8636e-04\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.7276e-04 - val_loss: 3.6452e-04\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.7001e-04 - val_loss: 3.8259e-04\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.6324e-04 - val_loss: 4.0136e-04\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.7269e-04 - val_loss: 4.9581e-04\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.8523e-04 - val_loss: 3.5585e-04\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.5082e-04 - val_loss: 3.5575e-04\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.6153e-04 - val_loss: 3.5515e-04\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.4006e-04 - val_loss: 3.8056e-04\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.3718e-04 - val_loss: 3.7779e-04\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3798e-04 - val_loss: 3.5347e-04\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3428e-04 - val_loss: 3.5750e-04\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3108e-04 - val_loss: 3.5256e-04\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.3388e-04 - val_loss: 3.4568e-04\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.2851e-04 - val_loss: 3.5781e-04\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2183e-04 - val_loss: 4.1086e-04\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.3338e-04 - val_loss: 3.7852e-04\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.4405e-04 - val_loss: 3.3517e-04\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.0850e-04 - val_loss: 3.5635e-04\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.2432e-04 - val_loss: 3.2957e-04\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.1285e-04 - val_loss: 3.4535e-04\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.0757e-04 - val_loss: 3.2939e-04\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.0252e-04 - val_loss: 3.4899e-04\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.0693e-04 - val_loss: 3.4901e-04\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.1864e-04 - val_loss: 3.5364e-04\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.0199e-04 - val_loss: 3.3300e-04\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.1041e-04 - val_loss: 3.2245e-04\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2605e-04 - val_loss: 3.1702e-04\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.8464e-04 - val_loss: 3.4269e-04\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.8518e-04 - val_loss: 3.1897e-04\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.8685e-04 - val_loss: 3.1614e-04\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.7796e-04 - val_loss: 3.5127e-04\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.7525e-04 - val_loss: 3.3170e-04\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.8274e-04 - val_loss: 3.0992e-04\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.9411e-04 - val_loss: 3.5906e-04\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.6949e-04 - val_loss: 3.3284e-04\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.7011e-04 - val_loss: 3.0812e-04\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.7130e-04 - val_loss: 3.1642e-04\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.8641e-04 - val_loss: 3.0430e-04\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.6218e-04 - val_loss: 2.9996e-04\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.7358e-04 - val_loss: 3.0895e-04\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.5187e-04 - val_loss: 2.9962e-04\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.5447e-04 - val_loss: 3.0795e-04\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.5823e-04 - val_loss: 3.1970e-04\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.4798e-04 - val_loss: 3.2249e-04\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.5194e-04 - val_loss: 3.0810e-04\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.7434e-04 - val_loss: 3.0030e-04\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.6550e-04 - val_loss: 2.9989e-04\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.7059e-04 - val_loss: 2.8837e-04\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.4142e-04 - val_loss: 2.8925e-04\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3771e-04 - val_loss: 3.0376e-04\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.2970e-04 - val_loss: 2.9014e-04\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.3044e-04 - val_loss: 2.8724e-04\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.3554e-04 - val_loss: 2.8487e-04\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.4306e-04 - val_loss: 2.8076e-04\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.3004e-04 - val_loss: 2.7946e-04\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3547e-04 - val_loss: 3.3658e-04\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.5104e-04 - val_loss: 2.7903e-04\n",
      "Epoch 146/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3141e-04 - val_loss: 2.8968e-04\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.3580e-04 - val_loss: 2.9022e-04\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.2280e-04 - val_loss: 2.7857e-04\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.1895e-04 - val_loss: 2.9327e-04\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.3068e-04 - val_loss: 2.9639e-04\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.1968e-04 - val_loss: 2.7287e-04\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.2520e-04 - val_loss: 2.7036e-04\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.0621e-04 - val_loss: 2.6810e-04\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1604e-04 - val_loss: 2.9925e-04\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.1218e-04 - val_loss: 2.6740e-04\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.3338e-04 - val_loss: 3.3682e-04\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.1876e-04 - val_loss: 3.4977e-04\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.2685e-04 - val_loss: 2.7750e-04\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.0831e-04 - val_loss: 2.8236e-04\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.1087e-04 - val_loss: 3.2661e-04\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.0539e-04 - val_loss: 2.6290e-04\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.9658e-04 - val_loss: 2.6541e-04\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.0135e-04 - val_loss: 3.0700e-04\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.0707e-04 - val_loss: 2.6903e-04\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.0585e-04 - val_loss: 2.6607e-04\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.0040e-04 - val_loss: 2.5707e-04\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8687e-04 - val_loss: 2.5771e-04\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.8820e-04 - val_loss: 2.5611e-04\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.8879e-04 - val_loss: 2.6660e-04\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8707e-04 - val_loss: 2.5166e-04\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8824e-04 - val_loss: 2.5155e-04\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.0310e-04 - val_loss: 2.6117e-04\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8745e-04 - val_loss: 2.5088e-04\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.8131e-04 - val_loss: 2.4734e-04\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.8846e-04 - val_loss: 2.7859e-04\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8591e-04 - val_loss: 2.6279e-04\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.8664e-04 - val_loss: 2.4574e-04\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.8232e-04 - val_loss: 3.3695e-04\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8245e-04 - val_loss: 2.4766e-04\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.7447e-04 - val_loss: 2.4813e-04\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.7587e-04 - val_loss: 2.5308e-04\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.8893e-04 - val_loss: 2.5113e-04\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.7664e-04 - val_loss: 2.6442e-04\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.7764e-04 - val_loss: 2.5142e-04\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.6748e-04 - val_loss: 2.8404e-04\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8158e-04 - val_loss: 2.4275e-04\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.6831e-04 - val_loss: 2.3668e-04\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.7213e-04 - val_loss: 2.4017e-04\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.6635e-04 - val_loss: 2.4501e-04\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.7888e-04 - val_loss: 2.3471e-04\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.7655e-04 - val_loss: 2.3443e-04\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.6827e-04 - val_loss: 2.4195e-04\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.7962e-04 - val_loss: 2.3175e-04\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.7008e-04 - val_loss: 2.3079e-04\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.6729e-04 - val_loss: 2.3086e-04\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7219e-04 - val_loss: 2.2952e-04\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.5603e-04 - val_loss: 2.2862e-04\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.8818e-04 - val_loss: 2.2803e-04\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.6772e-04 - val_loss: 2.2769e-04\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 4.5920e-04 - val_loss: 2.5526e-04\n",
      "Thời gian huấn luyện:  69.93803119659424\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_17 (GRU)                (None, 10, 116)           41412     \n",
      "                                                                 \n",
      " flatten_71 (Flatten)        (None, 1160)              0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,573\n",
      "Trainable params: 42,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 1s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 1s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "53/53 [==============================] - 1s 5ms/step - loss: 0.0948 - val_loss: 0.0434\n",
      "Epoch 2/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0212\n",
      "Epoch 3/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0136\n",
      "Epoch 4/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0082\n",
      "Epoch 5/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 6/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 9.4283e-04\n",
      "Epoch 9/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.4199e-04\n",
      "Epoch 10/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.2177e-04\n",
      "Epoch 11/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.4430e-04\n",
      "Epoch 12/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.0039e-04\n",
      "Epoch 13/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.9412e-04\n",
      "Epoch 14/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.6040e-04\n",
      "Epoch 15/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.4370e-04\n",
      "Epoch 16/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.2584e-04\n",
      "Epoch 17/50\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 3.3005e-04\n",
      "Epoch 18/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.9821e-04\n",
      "Epoch 19/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.2445e-04\n",
      "Epoch 20/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.0236e-04\n",
      "Epoch 21/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.7416e-04\n",
      "Epoch 22/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.8377e-04\n",
      "Epoch 23/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.7045e-04\n",
      "Epoch 24/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.8660e-04\n",
      "Epoch 25/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.5204e-04\n",
      "Epoch 26/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.5113e-04\n",
      "Epoch 27/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.6051e-04\n",
      "Epoch 28/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.4027e-04\n",
      "Epoch 29/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.5333e-04\n",
      "Epoch 30/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.3648e-04\n",
      "Epoch 31/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.5860e-04\n",
      "Epoch 32/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.3565e-04\n",
      "Epoch 33/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.3312e-04\n",
      "Epoch 34/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.2795e-04\n",
      "Epoch 35/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.4405e-04\n",
      "Epoch 36/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.1312e-04\n",
      "Epoch 37/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.2012e-04\n",
      "Epoch 38/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.1554e-04\n",
      "Epoch 39/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.2974e-04\n",
      "Epoch 40/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.1255e-04\n",
      "Epoch 41/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.8438e-04 - val_loss: 2.0849e-04\n",
      "Epoch 42/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.6589e-04 - val_loss: 1.9646e-04\n",
      "Epoch 43/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.6089e-04 - val_loss: 2.0416e-04\n",
      "Epoch 44/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.4558e-04 - val_loss: 1.9810e-04\n",
      "Epoch 45/50\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 9.3749e-04 - val_loss: 2.1182e-04\n",
      "Epoch 46/50\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 9.2609e-04 - val_loss: 2.1714e-04\n",
      "Epoch 47/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.2206e-04 - val_loss: 2.1300e-04\n",
      "Epoch 48/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.0483e-04 - val_loss: 2.0124e-04\n",
      "Epoch 49/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.9365e-04 - val_loss: 1.8391e-04\n",
      "Epoch 50/50\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.8048e-04 - val_loss: 2.1206e-04\n",
      "Thời gian huấn luyện:  6.242626667022705\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 10, 125)           250       \n",
      "                                                                 \n",
      " flatten_72 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,501\n",
      "Trainable params: 1,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.0439 - val_loss: 3.8581e-04\n",
      "Epoch 2/50\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 3.5809e-04\n",
      "Epoch 3/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 3.5883e-04\n",
      "Epoch 4/50\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 3.6559e-04\n",
      "Epoch 5/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 3.8307e-04\n",
      "Epoch 6/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 3.9297e-04\n",
      "Epoch 7/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 3.6523e-04\n",
      "Epoch 8/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 3.3921e-04\n",
      "Epoch 9/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 3.1700e-04\n",
      "Epoch 10/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 2.8444e-04\n",
      "Epoch 11/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.6650e-04\n",
      "Epoch 12/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.4816e-04\n",
      "Epoch 13/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.3693e-04\n",
      "Epoch 14/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.1810e-04\n",
      "Epoch 15/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.0102e-04\n",
      "Epoch 16/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 1.9731e-04\n",
      "Epoch 17/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.6057e-04 - val_loss: 1.9254e-04\n",
      "Epoch 18/50\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 9.2804e-04 - val_loss: 1.8524e-04\n",
      "Epoch 19/50\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.9999e-04 - val_loss: 1.8148e-04\n",
      "Epoch 20/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.8240e-04 - val_loss: 1.7614e-04\n",
      "Epoch 21/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.8173e-04 - val_loss: 1.7385e-04\n",
      "Epoch 22/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.8371e-04 - val_loss: 1.7030e-04\n",
      "Epoch 23/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.4492e-04 - val_loss: 1.6776e-04\n",
      "Epoch 24/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.1991e-04 - val_loss: 1.6557e-04\n",
      "Epoch 25/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.1489e-04 - val_loss: 1.6934e-04\n",
      "Epoch 26/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.9367e-04 - val_loss: 1.6605e-04\n",
      "Epoch 27/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.3068e-04 - val_loss: 1.7141e-04\n",
      "Epoch 28/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.4641e-04 - val_loss: 1.5884e-04\n",
      "Epoch 29/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.8810e-04 - val_loss: 1.7108e-04\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 7.8609e-04 - val_loss: 1.5941e-04\n",
      "Epoch 31/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4908e-04 - val_loss: 1.5550e-04\n",
      "Epoch 32/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4689e-04 - val_loss: 1.5425e-04\n",
      "Epoch 33/50\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3704e-04 - val_loss: 1.5458e-04\n",
      "Epoch 34/50\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.4015e-04 - val_loss: 1.6358e-04\n",
      "Epoch 35/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4052e-04 - val_loss: 1.5042e-04\n",
      "Epoch 36/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3565e-04 - val_loss: 1.4899e-04\n",
      "Epoch 37/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2033e-04 - val_loss: 1.5963e-04\n",
      "Epoch 38/50\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.0445e-04 - val_loss: 1.5439e-04\n",
      "Epoch 39/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3273e-04 - val_loss: 1.5013e-04\n",
      "Epoch 40/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2522e-04 - val_loss: 1.4436e-04\n",
      "Epoch 41/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8941e-04 - val_loss: 1.4766e-04\n",
      "Epoch 42/50\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.7267e-04 - val_loss: 1.4257e-04\n",
      "Epoch 43/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7378e-04 - val_loss: 1.4532e-04\n",
      "Epoch 44/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7033e-04 - val_loss: 1.4170e-04\n",
      "Epoch 45/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6086e-04 - val_loss: 1.5440e-04\n",
      "Epoch 46/50\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.7972e-04 - val_loss: 1.4931e-04\n",
      "Epoch 47/50\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6675e-04 - val_loss: 1.4648e-04\n",
      "Epoch 48/50\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.5288e-04 - val_loss: 1.3895e-04\n",
      "Epoch 49/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3435e-04 - val_loss: 1.3918e-04\n",
      "Epoch 50/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4126e-04 - val_loss: 1.3894e-04\n",
      "Thời gian huấn luyện:  13.40714406967163\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_18 (SimpleRNN)   (None, 10, 125)           15875     \n",
      "                                                                 \n",
      " flatten_73 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,126\n",
      "Trainable params: 17,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "53/53 [==============================] - 4s 21ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 2/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 3/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 5/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 6/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 7/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 8/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 9/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 10/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 11/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 12/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 13/50\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 14/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 15/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 16/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 17/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 18/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 19/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 20/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 21/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 22/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 23/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 24/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 25/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 26/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 27/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 28/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 29/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 30/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 31/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 32/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 33/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 34/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 35/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 36/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 37/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 38/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 39/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 40/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 41/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 43/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 44/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 45/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 47/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 48/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 49/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 50/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Thời gian huấn luyện:  29.554134607315063\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 10, 125)           63500     \n",
      "                                                                 \n",
      " flatten_74 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,751\n",
      "Trainable params: 64,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "53/53 [==============================] - 3s 18ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 2/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 3/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 5/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 6/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 7/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 8/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 9/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 10/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 11/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 12/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 13/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 14/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 15/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 16/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 17/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 18/50\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 19/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 20/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 21/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 22/50\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 23/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 24/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 25/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 26/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 27/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 28/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 29/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 30/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 31/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 32/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 33/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 34/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 35/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 36/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 37/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 38/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 39/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 40/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 41/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 43/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 44/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 45/50\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 47/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 48/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 49/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 50/50\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Thời gian huấn luyện:  26.901021480560303\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_18 (GRU)                (None, 10, 125)           48000     \n",
      "                                                                 \n",
      " flatten_75 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,251\n",
      "Trainable params: 49,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 907us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 1s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "59/59 [==============================] - 1s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 1s 5ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Thời gian huấn luyện:  6.073537588119507\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_95 (Dense)            (None, 10, 125)           250       \n",
      "                                                                 \n",
      " flatten_76 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,501\n",
      "Trainable params: 1,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 2s 10ms/step - loss: 0.0220 - val_loss: 6.3339e-04\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 5.3148e-04\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 4.8226e-04\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 4.4059e-04\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 4.0748e-04\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 3.7967e-04\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 3.4897e-04\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 3.2741e-04\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 3.1637e-04\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 3.0423e-04\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 3.1371e-04\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 3.2572e-04\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.8494e-04\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 3.1298e-04\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.9477e-04\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.6296e-04\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.0197e-04\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.5794e-04\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.3065e-04\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.7954e-04\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 9.9147e-04 - val_loss: 2.6159e-04\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 9.4998e-04 - val_loss: 2.8347e-04\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 9.6305e-04 - val_loss: 2.5268e-04\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.5747e-04\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 9.4826e-04 - val_loss: 2.3972e-04\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.8352e-04 - val_loss: 2.6996e-04\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.7919e-04 - val_loss: 2.9436e-04\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.5347e-04 - val_loss: 2.5175e-04\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 9.3009e-04 - val_loss: 2.2304e-04\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.7054e-04 - val_loss: 2.1024e-04\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.1818e-04 - val_loss: 2.2243e-04\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.4021e-04 - val_loss: 2.0773e-04\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.0882e-04 - val_loss: 2.2895e-04\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.0643e-04 - val_loss: 2.0826e-04\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 4ms/step - loss: 7.5744e-04 - val_loss: 2.1501e-04\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.4811e-04 - val_loss: 2.2021e-04\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.4061e-04 - val_loss: 2.2727e-04\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.4398e-04 - val_loss: 2.3215e-04\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.8476e-04 - val_loss: 2.4731e-04\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.5842e-04 - val_loss: 2.0061e-04\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.2301e-04 - val_loss: 1.8303e-04\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 7.1212e-04 - val_loss: 2.1932e-04\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.0265e-04 - val_loss: 1.8643e-04\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.1674e-04 - val_loss: 1.6921e-04\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.0213e-04 - val_loss: 1.9455e-04\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.4881e-04 - val_loss: 1.9554e-04\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.1283e-04 - val_loss: 2.2281e-04\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.1204e-04 - val_loss: 1.8547e-04\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.4304e-04 - val_loss: 1.8382e-04\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.4060e-04 - val_loss: 1.6294e-04\n",
      "Thời gian huấn luyện:  11.890747547149658\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_19 (SimpleRNN)   (None, 10, 125)           15875     \n",
      "                                                                 \n",
      " flatten_77 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,126\n",
      "Trainable params: 17,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 3s 17ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Thời gian huấn luyện:  27.53791379928589\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_19 (LSTM)              (None, 10, 125)           63500     \n",
      "                                                                 \n",
      " flatten_78 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 1)                 1251      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 64,751\n",
      "Trainable params: 64,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 3s 16ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Thời gian huấn luyện:  23.688782215118408\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_19 (GRU)                (None, 10, 125)           48000     \n",
      "                                                                 \n",
      " flatten_79 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,251\n",
      "Trainable params: 49,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 1s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 1s 6ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Thời gian huấn luyện:  6.079923391342163\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 10, 125)           250       \n",
      "                                                                 \n",
      " flatten_80 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,501\n",
      "Trainable params: 1,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 2s 9ms/step - loss: 0.0108 - val_loss: 6.8614e-04\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 6.9766e-04\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 6.7286e-04\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 5.8581e-04\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 5.4675e-04\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 4.9190e-04\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.5634e-04\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.3093e-04\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 4.1653e-04\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 3.9359e-04\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 9.6815e-04 - val_loss: 3.8379e-04\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.3468e-04 - val_loss: 3.8431e-04\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 9.5530e-04 - val_loss: 3.6163e-04\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.0740e-04 - val_loss: 3.7190e-04\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.9662e-04 - val_loss: 3.4183e-04\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 8.8682e-04 - val_loss: 3.3511e-04\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.4964e-04 - val_loss: 3.5808e-04\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.3031e-04 - val_loss: 3.4729e-04\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.2711e-04 - val_loss: 3.2931e-04\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.8542e-04 - val_loss: 3.2455e-04\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.9516e-04 - val_loss: 3.0992e-04\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 8.0799e-04 - val_loss: 3.1821e-04\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.0497e-04 - val_loss: 3.1334e-04\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.9556e-04 - val_loss: 2.9714e-04\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.3289e-04 - val_loss: 3.3308e-04\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.4869e-04 - val_loss: 2.9316e-04\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.3433e-04 - val_loss: 2.9587e-04\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.1456e-04 - val_loss: 3.1120e-04\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.2657e-04 - val_loss: 2.8243e-04\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.1615e-04 - val_loss: 2.7807e-04\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.2283e-04 - val_loss: 2.8387e-04\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.9063e-04 - val_loss: 2.7872e-04\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.9153e-04 - val_loss: 3.2854e-04\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.1107e-04 - val_loss: 3.3402e-04\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.8132e-04 - val_loss: 2.8762e-04\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.0611e-04 - val_loss: 2.7950e-04\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.6108e-04 - val_loss: 2.8167e-04\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.7742e-04 - val_loss: 3.0087e-04\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.5486e-04 - val_loss: 3.0104e-04\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.4632e-04 - val_loss: 2.5482e-04\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 6.3603e-04 - val_loss: 2.7379e-04\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.5733e-04 - val_loss: 2.5093e-04\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.4269e-04 - val_loss: 2.7331e-04\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.6815e-04 - val_loss: 2.6859e-04\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.2401e-04 - val_loss: 2.6419e-04\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.4657e-04 - val_loss: 2.5504e-04\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.3469e-04 - val_loss: 2.3967e-04\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.1299e-04 - val_loss: 2.5048e-04\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.1558e-04 - val_loss: 2.7993e-04\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.2639e-04 - val_loss: 2.3646e-04\n",
      "Thời gian huấn luyện:  12.203882694244385\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_20 (SimpleRNN)   (None, 10, 125)           15875     \n",
      "                                                                 \n",
      " flatten_81 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,126\n",
      "Trainable params: 17,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 4s 23ms/step - loss: 0.0309 - val_loss: 0.0039\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 8.0815e-04\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 9.6473e-04\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 8.9598e-04\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 7.1313e-04\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 8.6358e-04\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 8.5036e-04\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 7.0683e-04\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 8.2678e-04\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 7.9664e-04\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 7.9104e-04\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 8.7320e-04\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 7.2384e-04\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 7.8592e-04\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 8.0527e-04\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 8.0889e-04\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 7.9963e-04\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 8.5813e-04\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 7.6019e-04\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0015 - val_loss: 8.2323e-04\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 8.4785e-04\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 6.8306e-04\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 7.7619e-04\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0014 - val_loss: 7.2603e-04\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 7.4580e-04\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0014 - val_loss: 7.7640e-04\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 7.4845e-04\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 7.2717e-04\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 7.4136e-04\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 8.2240e-04\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 7.2913e-04\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 6.1718e-04\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0013 - val_loss: 6.6012e-04\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 6.5406e-04\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 6.1714e-04\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.8969e-04\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 6.4407e-04\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.7822e-04\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.8281e-04\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0012 - val_loss: 5.5597e-04\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 6.4654e-04\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 5.0320e-04\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 5.4563e-04\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 5.2352e-04\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 5.4861e-04\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 5.4394e-04\n",
      "Thời gian huấn luyện:  27.66787075996399\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 10, 125)           63500     \n",
      "                                                                 \n",
      " flatten_82 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,751\n",
      "Trainable params: 64,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 4s 21ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Thời gian huấn luyện:  26.11092782020569\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_20 (GRU)                (None, 10, 125)           48000     \n",
      "                                                                 \n",
      " flatten_83 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,251\n",
      "Trainable params: 49,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 1s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 1s 6ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.0094\n",
      "Thời gian huấn luyện:  11.86989426612854\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_105 (Dense)           (None, 10, 125)           250       \n",
      "                                                                 \n",
      " flatten_84 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,501\n",
      "Trainable params: 1,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 10ms/step - loss: 0.0306 - val_loss: 4.2047e-04\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 3.4783e-04\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 3.6957e-04\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 3.6130e-04\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 3.4551e-04\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 3.0932e-04\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 2.9685e-04\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 2.8626e-04\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.8932e-04\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.5156e-04\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.2500e-04\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.1450e-04\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.1744e-04\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.9978e-04 - val_loss: 2.0687e-04\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 9.7614e-04 - val_loss: 2.0454e-04\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 9.7651e-04 - val_loss: 1.9405e-04\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.3793e-04 - val_loss: 1.9195e-04\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.1583e-04 - val_loss: 1.8645e-04\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.9698e-04 - val_loss: 1.9195e-04\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.2419e-04 - val_loss: 1.7976e-04\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.7674e-04 - val_loss: 1.7900e-04\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.5219e-04 - val_loss: 1.7469e-04\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.3486e-04 - val_loss: 1.7187e-04\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.3445e-04 - val_loss: 1.7021e-04\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.1218e-04 - val_loss: 1.6880e-04\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.5364e-04 - val_loss: 1.6815e-04\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.0334e-04 - val_loss: 1.7113e-04\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.7506e-04 - val_loss: 1.6923e-04\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.7993e-04 - val_loss: 1.7280e-04\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.5814e-04 - val_loss: 1.6961e-04\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.5120e-04 - val_loss: 1.6587e-04\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.7255e-04 - val_loss: 1.5496e-04\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4218e-04 - val_loss: 1.6067e-04\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3773e-04 - val_loss: 1.5755e-04\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1387e-04 - val_loss: 1.5141e-04\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2423e-04 - val_loss: 1.5203e-04\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9100e-04 - val_loss: 1.5115e-04\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1733e-04 - val_loss: 1.8436e-04\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0566e-04 - val_loss: 1.4571e-04\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0963e-04 - val_loss: 1.5769e-04\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8914e-04 - val_loss: 1.4344e-04\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9061e-04 - val_loss: 1.5754e-04\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6502e-04 - val_loss: 1.4296e-04\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6220e-04 - val_loss: 1.4198e-04\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.5069e-04 - val_loss: 1.3983e-04\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8432e-04 - val_loss: 1.4328e-04\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4476e-04 - val_loss: 1.4075e-04\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4408e-04 - val_loss: 1.4705e-04\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5573e-04 - val_loss: 1.3820e-04\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4467e-04 - val_loss: 1.3642e-04\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3789e-04 - val_loss: 1.3886e-04\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2224e-04 - val_loss: 1.3481e-04\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1193e-04 - val_loss: 1.3175e-04\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2305e-04 - val_loss: 1.3727e-04\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2962e-04 - val_loss: 1.3421e-04\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2438e-04 - val_loss: 1.3951e-04\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0429e-04 - val_loss: 1.2824e-04\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9146e-04 - val_loss: 1.3159e-04\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8898e-04 - val_loss: 1.3370e-04\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.8042e-04 - val_loss: 1.2999e-04\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.6955e-04 - val_loss: 1.2533e-04\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.8543e-04 - val_loss: 1.2520e-04\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.6465e-04 - val_loss: 1.2287e-04\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0150e-04 - val_loss: 1.3184e-04\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0063e-04 - val_loss: 1.2306e-04\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9203e-04 - val_loss: 1.2062e-04\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8874e-04 - val_loss: 1.2123e-04\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.5811e-04 - val_loss: 1.2090e-04\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.5694e-04 - val_loss: 1.2576e-04\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7183e-04 - val_loss: 1.1993e-04\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.6631e-04 - val_loss: 1.1865e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.5493e-04 - val_loss: 1.2115e-04\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.4011e-04 - val_loss: 1.1549e-04\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.5536e-04 - val_loss: 1.2536e-04\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.6761e-04 - val_loss: 1.1440e-04\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.2531e-04 - val_loss: 1.1458e-04\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4055e-04 - val_loss: 1.1649e-04\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2494e-04 - val_loss: 1.1719e-04\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2852e-04 - val_loss: 1.1180e-04\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1693e-04 - val_loss: 1.1134e-04\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1178e-04 - val_loss: 1.1287e-04\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0849e-04 - val_loss: 1.2033e-04\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2190e-04 - val_loss: 1.0885e-04\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1770e-04 - val_loss: 1.0860e-04\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.3003e-04 - val_loss: 1.0985e-04\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9783e-04 - val_loss: 1.0868e-04\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9525e-04 - val_loss: 1.0719e-04\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8582e-04 - val_loss: 1.0824e-04\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.4055e-04 - val_loss: 1.0653e-04\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.2620e-04 - val_loss: 1.0549e-04\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8465e-04 - val_loss: 1.0422e-04\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8691e-04 - val_loss: 1.0930e-04\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2739e-04 - val_loss: 1.0348e-04\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9385e-04 - val_loss: 1.0892e-04\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7211e-04 - val_loss: 1.0828e-04\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7839e-04 - val_loss: 1.0271e-04\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8285e-04 - val_loss: 1.0151e-04\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1636e-04 - val_loss: 1.2681e-04\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7049e-04 - val_loss: 1.0071e-04\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8422e-04 - val_loss: 1.0156e-04\n",
      "Thời gian huấn luyện:  23.94572925567627\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_21 (SimpleRNN)   (None, 10, 125)           15875     \n",
      "                                                                 \n",
      " flatten_85 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,126\n",
      "Trainable params: 17,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 4s 20ms/step - loss: 0.0237 - val_loss: 0.0028\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0022 - val_loss: 7.8972e-04\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0020 - val_loss: 5.0459e-04\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 3.9174e-04\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 4.1238e-04\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 4.0365e-04\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 4.1500e-04\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 4.0909e-04\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0018 - val_loss: 3.2476e-04\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 3.3883e-04\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 3.5159e-04\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 3.7130e-04\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 3.9297e-04\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 3.1475e-04\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 3.3369e-04\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 3.0061e-04\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 3.3803e-04\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 3.0841e-04\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 2.9849e-04\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 3.5889e-04\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 3.2571e-04\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 3.0521e-04\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 2.7861e-04\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 2.7506e-04\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 3.1354e-04\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 2.9830e-04\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 3.0161e-04\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 2.7119e-04\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 3.0064e-04\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 2.5484e-04\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 2.8961e-04\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.5592e-04\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.7352e-04\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.5741e-04\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 3.3551e-04\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.5262e-04\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.4392e-04\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.8027e-04\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.2123e-04\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.3753e-04\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.4322e-04\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 2.7223e-04\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.1844e-04\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.1745e-04\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 2.1090e-04\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 2.1354e-04\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 2.2045e-04\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 2.1758e-04\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.8342e-04 - val_loss: 2.2493e-04\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.8628e-04 - val_loss: 2.1071e-04\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.8227e-04 - val_loss: 2.0561e-04\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 2.2680e-04\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.9044e-04 - val_loss: 2.0256e-04\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 2.0615e-04\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 9.6784e-04 - val_loss: 2.1564e-04\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.5531e-04 - val_loss: 2.1424e-04\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.2524e-04 - val_loss: 2.0472e-04\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.2512e-04 - val_loss: 1.9955e-04\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.0624e-04 - val_loss: 1.9881e-04\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.0082e-04 - val_loss: 1.9801e-04\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.4113e-04 - val_loss: 2.0525e-04\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.9639e-04 - val_loss: 1.9468e-04\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.0444e-04 - val_loss: 1.9325e-04\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.2157e-04 - val_loss: 2.0537e-04\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.9319e-04 - val_loss: 1.9233e-04\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.8806e-04 - val_loss: 1.9173e-04\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.7804e-04 - val_loss: 2.1145e-04\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.8148e-04 - val_loss: 1.9187e-04\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.9245e-04 - val_loss: 1.9312e-04\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.8144e-04 - val_loss: 2.0147e-04\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.6513e-04 - val_loss: 1.8889e-04\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.9873e-04 - val_loss: 1.8541e-04\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.5701e-04 - val_loss: 2.0595e-04\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.8729e-04 - val_loss: 1.8523e-04\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.4880e-04 - val_loss: 1.9313e-04\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.3424e-04 - val_loss: 1.8160e-04\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.6946e-04 - val_loss: 1.8963e-04\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.2774e-04 - val_loss: 1.8762e-04\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.3000e-04 - val_loss: 2.1466e-04\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.4041e-04 - val_loss: 1.8906e-04\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.1608e-04 - val_loss: 1.7906e-04\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 8.1382e-04 - val_loss: 1.7866e-04\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.9992e-04 - val_loss: 1.7914e-04\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.0718e-04 - val_loss: 1.8006e-04\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.9117e-04 - val_loss: 1.8425e-04\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.0677e-04 - val_loss: 1.9724e-04\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.1394e-04 - val_loss: 1.8675e-04\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.8438e-04 - val_loss: 1.8437e-04\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.7756e-04 - val_loss: 1.8025e-04\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.7662e-04 - val_loss: 1.7653e-04\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.7816e-04 - val_loss: 1.7211e-04\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.7636e-04 - val_loss: 1.7683e-04\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.6169e-04 - val_loss: 1.8997e-04\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.7702e-04 - val_loss: 1.6913e-04\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.6859e-04 - val_loss: 1.7912e-04\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.5283e-04 - val_loss: 1.7223e-04\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.9138e-04 - val_loss: 1.6703e-04\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.5805e-04 - val_loss: 1.7103e-04\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.0413e-04 - val_loss: 1.7149e-04\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.4362e-04 - val_loss: 1.7637e-04\n",
      "Thời gian huấn luyện:  52.2682466506958\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_21 (LSTM)              (None, 10, 125)           63500     \n",
      "                                                                 \n",
      " flatten_86 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,751\n",
      "Trainable params: 64,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 3s 15ms/step - loss: 0.0141 - val_loss: 8.3264e-04\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 2.9810e-04\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 2.4406e-04\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 2.3655e-04\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.3218e-04\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.2439e-04\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.2344e-04\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.3091e-04\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.1304e-04\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.1749e-04\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.1529e-04\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.1450e-04\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.0581e-04\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.2773e-04\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.0234e-04\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.0667e-04\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.1128e-04\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 9.9446e-04 - val_loss: 1.9613e-04\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 9.6329e-04 - val_loss: 1.9256e-04\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.4453e-04 - val_loss: 1.8620e-04\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.2820e-04 - val_loss: 1.8995e-04\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 9.0091e-04 - val_loss: 1.8305e-04\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.8379e-04 - val_loss: 1.8674e-04\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.7541e-04 - val_loss: 1.8115e-04\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.5727e-04 - val_loss: 1.8433e-04\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.5289e-04 - val_loss: 1.8506e-04\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.2480e-04 - val_loss: 1.7715e-04\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.2469e-04 - val_loss: 1.7628e-04\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.2173e-04 - val_loss: 1.7391e-04\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.9424e-04 - val_loss: 1.7402e-04\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.9133e-04 - val_loss: 1.7305e-04\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.8057e-04 - val_loss: 1.7253e-04\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.7460e-04 - val_loss: 1.7293e-04\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.7155e-04 - val_loss: 1.7511e-04\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.1691e-04 - val_loss: 1.6999e-04\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.5396e-04 - val_loss: 1.7607e-04\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.5267e-04 - val_loss: 1.6971e-04\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.3845e-04 - val_loss: 1.7602e-04\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.4088e-04 - val_loss: 1.6761e-04\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.3861e-04 - val_loss: 1.7153e-04\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.1716e-04 - val_loss: 1.6739e-04\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.3241e-04 - val_loss: 1.6235e-04\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.1990e-04 - val_loss: 1.7357e-04\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.1559e-04 - val_loss: 1.7072e-04\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.0190e-04 - val_loss: 1.6318e-04\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.9926e-04 - val_loss: 1.6173e-04\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.8940e-04 - val_loss: 1.6032e-04\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.8354e-04 - val_loss: 1.6058e-04\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.7651e-04 - val_loss: 1.6775e-04\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.7682e-04 - val_loss: 1.6172e-04\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.6461e-04 - val_loss: 1.6323e-04\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.6436e-04 - val_loss: 1.5859e-04\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.6417e-04 - val_loss: 1.5625e-04\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.5850e-04 - val_loss: 1.5400e-04\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.5467e-04 - val_loss: 1.5388e-04\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.4244e-04 - val_loss: 1.5379e-04\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.4181e-04 - val_loss: 1.5166e-04\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.3515e-04 - val_loss: 1.5103e-04\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.4566e-04 - val_loss: 1.5807e-04\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.3817e-04 - val_loss: 1.5084e-04\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.2605e-04 - val_loss: 1.5663e-04\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.2297e-04 - val_loss: 1.4708e-04\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.2116e-04 - val_loss: 1.4745e-04\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.1176e-04 - val_loss: 1.5593e-04\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.3144e-04 - val_loss: 1.4405e-04\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.2303e-04 - val_loss: 1.4966e-04\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.9974e-04 - val_loss: 1.4013e-04\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.1225e-04 - val_loss: 1.4608e-04\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.8300e-04 - val_loss: 1.4060e-04\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.8339e-04 - val_loss: 1.3801e-04\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.8175e-04 - val_loss: 1.3726e-04\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.8139e-04 - val_loss: 1.3630e-04\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.7882e-04 - val_loss: 1.3656e-04\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.7368e-04 - val_loss: 1.3514e-04\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.6872e-04 - val_loss: 1.3685e-04\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.6268e-04 - val_loss: 1.3322e-04\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.5910e-04 - val_loss: 1.3239e-04\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.6228e-04 - val_loss: 1.3287e-04\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.8408e-04 - val_loss: 1.3167e-04\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.6548e-04 - val_loss: 1.3796e-04\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.5236e-04 - val_loss: 1.3034e-04\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.4967e-04 - val_loss: 1.2943e-04\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.5803e-04 - val_loss: 1.2784e-04\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.3390e-04 - val_loss: 1.3245e-04\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.3054e-04 - val_loss: 1.3510e-04\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.3674e-04 - val_loss: 1.4432e-04\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.3566e-04 - val_loss: 1.2434e-04\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.4708e-04 - val_loss: 1.2744e-04\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1584e-04 - val_loss: 1.2395e-04\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.2729e-04 - val_loss: 1.3163e-04\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.2109e-04 - val_loss: 1.2359e-04\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.2331e-04 - val_loss: 1.2179e-04\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.1395e-04 - val_loss: 1.2083e-04\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.1076e-04 - val_loss: 1.2836e-04\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.2112e-04 - val_loss: 1.1992e-04\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.1033e-04 - val_loss: 1.1953e-04\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.9593e-04 - val_loss: 1.2114e-04\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.9753e-04 - val_loss: 1.2630e-04\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.9356e-04 - val_loss: 1.2321e-04\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.9665e-04 - val_loss: 1.2426e-04\n",
      "Thời gian huấn luyện:  45.639556646347046\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_21 (GRU)                (None, 10, 125)           48000     \n",
      "                                                                 \n",
      " flatten_87 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,251\n",
      "Trainable params: 49,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 914us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 1s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 1s 4ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Thời gian huấn luyện:  10.41352128982544\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_110 (Dense)           (None, 10, 125)           250       \n",
      "                                                                 \n",
      " flatten_88 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,501\n",
      "Trainable params: 1,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 1s 8ms/step - loss: 0.0146 - val_loss: 3.8398e-04\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 3.8862e-04\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 3.6569e-04\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 3.6324e-04\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 3.3062e-04\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.8379e-04\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.6429e-04\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.5160e-04\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.4205e-04\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 9.6255e-04 - val_loss: 2.3084e-04\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 9.2511e-04 - val_loss: 2.2339e-04\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.9542e-04 - val_loss: 2.1694e-04\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.7846e-04 - val_loss: 2.1160e-04\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.4457e-04 - val_loss: 2.0994e-04\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.3111e-04 - val_loss: 2.0003e-04\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.3579e-04 - val_loss: 2.0049e-04\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.2978e-04 - val_loss: 1.9771e-04\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.1460e-04 - val_loss: 1.9056e-04\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.0940e-04 - val_loss: 1.8461e-04\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 7.5532e-04 - val_loss: 1.8096e-04\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 7.7701e-04 - val_loss: 1.8590e-04\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.2231e-04 - val_loss: 1.7400e-04\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.4431e-04 - val_loss: 1.7851e-04\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.0951e-04 - val_loss: 1.7112e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.2962e-04 - val_loss: 1.6725e-04\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.9568e-04 - val_loss: 1.6776e-04\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.4414e-04 - val_loss: 1.6311e-04\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.1869e-04 - val_loss: 1.8648e-04\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.3747e-04 - val_loss: 1.7814e-04\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.0708e-04 - val_loss: 1.7710e-04\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.5947e-04 - val_loss: 1.6112e-04\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.5355e-04 - val_loss: 1.6858e-04\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.4636e-04 - val_loss: 1.5866e-04\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.5451e-04 - val_loss: 1.5531e-04\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.2521e-04 - val_loss: 1.4843e-04\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 6.3213e-04 - val_loss: 1.6185e-04\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.1393e-04 - val_loss: 1.5260e-04\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.2981e-04 - val_loss: 1.5583e-04\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.1719e-04 - val_loss: 1.4129e-04\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.9690e-04 - val_loss: 1.5960e-04\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.0949e-04 - val_loss: 1.5190e-04\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.8313e-04 - val_loss: 1.4410e-04\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.8843e-04 - val_loss: 1.5670e-04\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.9418e-04 - val_loss: 1.5305e-04\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.7178e-04 - val_loss: 1.4049e-04\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.6019e-04 - val_loss: 1.4222e-04\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.9018e-04 - val_loss: 1.3337e-04\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.9145e-04 - val_loss: 1.3426e-04\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.5899e-04 - val_loss: 1.3571e-04\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.5774e-04 - val_loss: 1.3425e-04\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.5733e-04 - val_loss: 1.3150e-04\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.4627e-04 - val_loss: 1.3169e-04\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.6321e-04 - val_loss: 1.3238e-04\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.4416e-04 - val_loss: 1.3758e-04\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.4259e-04 - val_loss: 1.3385e-04\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.5888e-04 - val_loss: 1.2582e-04\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.2039e-04 - val_loss: 1.2648e-04\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.2538e-04 - val_loss: 1.2482e-04\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.1912e-04 - val_loss: 1.2584e-04\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.2889e-04 - val_loss: 1.2592e-04\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.2873e-04 - val_loss: 1.3767e-04\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.4366e-04 - val_loss: 1.3285e-04\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.2041e-04 - val_loss: 1.2272e-04\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.0434e-04 - val_loss: 1.2962e-04\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.0886e-04 - val_loss: 1.1992e-04\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.4213e-04 - val_loss: 1.1861e-04\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.4348e-04 - val_loss: 1.1866e-04\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.1091e-04 - val_loss: 1.2107e-04\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.2079e-04 - val_loss: 1.2119e-04\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.9552e-04 - val_loss: 1.1577e-04\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.8690e-04 - val_loss: 1.1841e-04\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.8502e-04 - val_loss: 1.2222e-04\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.8751e-04 - val_loss: 1.1843e-04\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.8770e-04 - val_loss: 1.1557e-04\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.4939e-04 - val_loss: 1.1508e-04\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.9263e-04 - val_loss: 1.1423e-04\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.5247e-04 - val_loss: 1.2789e-04\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.8339e-04 - val_loss: 1.1204e-04\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.7750e-04 - val_loss: 1.1524e-04\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.7370e-04 - val_loss: 1.1171e-04\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.7456e-04 - val_loss: 1.1391e-04\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.6339e-04 - val_loss: 1.1120e-04\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.6897e-04 - val_loss: 1.1111e-04\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.5375e-04 - val_loss: 1.1073e-04\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.5263e-04 - val_loss: 1.0965e-04\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.6552e-04 - val_loss: 1.1035e-04\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.8712e-04 - val_loss: 1.1994e-04\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.0496e-04 - val_loss: 1.0698e-04\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.0425e-04 - val_loss: 1.1069e-04\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.8832e-04 - val_loss: 1.1187e-04\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.4185e-04 - val_loss: 1.0675e-04\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.4489e-04 - val_loss: 1.0809e-04\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.4314e-04 - val_loss: 1.0689e-04\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.5036e-04 - val_loss: 1.0819e-04\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.4063e-04 - val_loss: 1.0524e-04\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.4173e-04 - val_loss: 1.2105e-04\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.4875e-04 - val_loss: 1.0891e-04\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.4409e-04 - val_loss: 1.0335e-04\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.4466e-04 - val_loss: 1.0325e-04\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.2925e-04 - val_loss: 1.1019e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian huấn luyện:  22.109623432159424\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_22 (SimpleRNN)   (None, 10, 125)           15875     \n",
      "                                                                 \n",
      " flatten_89 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,126\n",
      "Trainable params: 17,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 4s 21ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Thời gian huấn luyện:  54.984480142593384\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 10, 125)           63500     \n",
      "                                                                 \n",
      " flatten_90 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,751\n",
      "Trainable params: 64,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 4s 19ms/step - loss: 0.0229 - val_loss: 0.0040\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 8.8849e-04\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 5.2074e-04\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 3.7690e-04\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 3.3259e-04\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 3.5251e-04\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 3.4700e-04\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 3.1678e-04\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 3.2380e-04\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 3.1684e-04\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 3.3821e-04\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 3.0473e-04\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.8480e-04\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.8531e-04\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.9260e-04\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.8568e-04\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 2.7596e-04\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.8272e-04\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.7430e-04\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.8033e-04\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.5574e-04\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.7251e-04\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.5721e-04\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 2.4413e-04\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 2.5124e-04\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.9502e-04 - val_loss: 2.3513e-04\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.6898e-04 - val_loss: 2.4849e-04\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.4563e-04 - val_loss: 2.3188e-04\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.2079e-04 - val_loss: 2.4649e-04\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.0438e-04 - val_loss: 2.4525e-04\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 9.0440e-04 - val_loss: 2.5168e-04\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 8.8183e-04 - val_loss: 2.2546e-04\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6029e-04 - val_loss: 2.2841e-04\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.4405e-04 - val_loss: 2.3357e-04\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.3006e-04 - val_loss: 2.2172e-04\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.1984e-04 - val_loss: 2.2014e-04\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.1384e-04 - val_loss: 2.1896e-04\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 7.9641e-04 - val_loss: 2.1768e-04\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 7.9974e-04 - val_loss: 2.2137e-04\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.0420e-04 - val_loss: 2.2568e-04\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.9914e-04 - val_loss: 2.1529e-04\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.7974e-04 - val_loss: 2.1513e-04\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.6817e-04 - val_loss: 2.1572e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.9098e-04 - val_loss: 2.2064e-04\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.5681e-04 - val_loss: 2.1524e-04\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 7.5168e-04 - val_loss: 2.0961e-04\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.4740e-04 - val_loss: 2.0934e-04\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.6410e-04 - val_loss: 2.0734e-04\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.5878e-04 - val_loss: 2.5747e-04\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.2719e-04 - val_loss: 2.0685e-04\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.2166e-04 - val_loss: 2.0590e-04\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.2129e-04 - val_loss: 2.0699e-04\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 7.1532e-04 - val_loss: 2.0327e-04\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.1602e-04 - val_loss: 2.0208e-04\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.1239e-04 - val_loss: 2.0738e-04\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.1260e-04 - val_loss: 2.0135e-04\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.9544e-04 - val_loss: 2.0332e-04\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.8957e-04 - val_loss: 1.9694e-04\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.7935e-04 - val_loss: 1.9867e-04\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.8051e-04 - val_loss: 1.9450e-04\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 6.8907e-04 - val_loss: 1.9664e-04\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.8163e-04 - val_loss: 2.0139e-04\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.7037e-04 - val_loss: 2.1776e-04\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.6365e-04 - val_loss: 1.9164e-04\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.8290e-04 - val_loss: 1.8912e-04\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.6507e-04 - val_loss: 1.8597e-04\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 7.1895e-04 - val_loss: 1.8594e-04\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 6.4535e-04 - val_loss: 2.0310e-04\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.5126e-04 - val_loss: 1.8345e-04\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.3256e-04 - val_loss: 1.8712e-04\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.3395e-04 - val_loss: 1.8091e-04\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.2819e-04 - val_loss: 1.8370e-04\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.2891e-04 - val_loss: 1.8304e-04\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.1493e-04 - val_loss: 1.9048e-04\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 6.2139e-04 - val_loss: 1.7915e-04\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.1129e-04 - val_loss: 1.8318e-04\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.1130e-04 - val_loss: 1.7443e-04\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.1321e-04 - val_loss: 1.7563e-04\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.0153e-04 - val_loss: 1.7741e-04\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.0490e-04 - val_loss: 1.8281e-04\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.0359e-04 - val_loss: 1.8719e-04\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.9422e-04 - val_loss: 1.7391e-04\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 5.8792e-04 - val_loss: 1.7125e-04\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.8771e-04 - val_loss: 1.6775e-04\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.8083e-04 - val_loss: 1.6450e-04\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.8962e-04 - val_loss: 1.7309e-04\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.1128e-04 - val_loss: 1.6207e-04\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.8648e-04 - val_loss: 1.6440e-04\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 5.7850e-04 - val_loss: 1.6822e-04\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.7893e-04 - val_loss: 1.6210e-04\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.7846e-04 - val_loss: 1.6900e-04\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.5540e-04 - val_loss: 1.5779e-04\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.5586e-04 - val_loss: 1.6110e-04\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.5591e-04 - val_loss: 1.5874e-04\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.6306e-04 - val_loss: 1.5204e-04\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 5.4822e-04 - val_loss: 1.5129e-04\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 5.5437e-04 - val_loss: 1.5415e-04\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.6284e-04 - val_loss: 1.5340e-04\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.4439e-04 - val_loss: 1.4963e-04\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.3555e-04 - val_loss: 1.4987e-04\n",
      "Thời gian huấn luyện:  48.90759468078613\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_22 (GRU)                (None, 10, 125)           48000     \n",
      "                                                                 \n",
      " flatten_91 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,251\n",
      "Trainable params: 49,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 969us/step\n",
      "15/15 [==============================] - 0s 968us/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 1s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 1s 6ms/step - loss: 0.0672 - val_loss: 0.0407\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0228\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0167\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0123\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0095\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0065\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.8470e-04\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.3724e-04\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.0445e-04\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.7486e-04\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 8.9754e-04\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.4219e-04\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 9.7605e-04\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 8.3803e-04\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 9.6028e-04\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 9.1121e-04\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.9592e-04\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 8.9160e-04\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.9524e-04\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 7.9755e-04\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 9.2475e-04\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 7.2840e-04\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.8909e-04\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 8.5347e-04\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 7.1240e-04\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.9825e-04 - val_loss: 6.9439e-04\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.8907e-04 - val_loss: 6.8826e-04\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.7980e-04 - val_loss: 7.4448e-04\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.6843e-04 - val_loss: 6.6997e-04\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.5701e-04 - val_loss: 6.7344e-04\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.4810e-04 - val_loss: 5.9386e-04\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.4454e-04 - val_loss: 6.4753e-04\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.3122e-04 - val_loss: 6.3485e-04\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.1826e-04 - val_loss: 5.6444e-04\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.1390e-04 - val_loss: 6.4213e-04\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.0277e-04 - val_loss: 6.2825e-04\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.9501e-04 - val_loss: 6.6796e-04\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.7774e-04 - val_loss: 5.9662e-04\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.7092e-04 - val_loss: 6.3496e-04\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.6457e-04 - val_loss: 6.2492e-04\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.6119e-04 - val_loss: 5.6626e-04\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.4435e-04 - val_loss: 6.3019e-04\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.4618e-04 - val_loss: 5.1900e-04\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 8.3574e-04 - val_loss: 5.6743e-04\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.1252e-04 - val_loss: 4.9222e-04\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.1035e-04 - val_loss: 6.2435e-04\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.0152e-04 - val_loss: 5.2472e-04\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.9512e-04 - val_loss: 5.8953e-04\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.8628e-04 - val_loss: 5.5295e-04\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 7.7532e-04 - val_loss: 4.9504e-04\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 7.6527e-04 - val_loss: 5.8513e-04\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.5864e-04 - val_loss: 5.2194e-04\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.4932e-04 - val_loss: 4.7791e-04\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.4244e-04 - val_loss: 5.6482e-04\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 7.3761e-04 - val_loss: 4.4271e-04\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 7.2833e-04 - val_loss: 5.0309e-04\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.1186e-04 - val_loss: 4.3302e-04\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.1966e-04 - val_loss: 4.4966e-04\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.0591e-04 - val_loss: 4.7434e-04\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.9584e-04 - val_loss: 4.4388e-04\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.8962e-04 - val_loss: 5.2595e-04\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 2ms/step - loss: 6.9176e-04 - val_loss: 4.2827e-04\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.7651e-04 - val_loss: 4.6162e-04\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.7169e-04 - val_loss: 4.7693e-04\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.6891e-04 - val_loss: 4.2572e-04\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.5650e-04 - val_loss: 4.3679e-04\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.5137e-04 - val_loss: 3.7421e-04\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.4562e-04 - val_loss: 4.8775e-04\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.4275e-04 - val_loss: 4.4898e-04\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.3467e-04 - val_loss: 4.3987e-04\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.2928e-04 - val_loss: 4.4151e-04\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.2595e-04 - val_loss: 3.8660e-04\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.2425e-04 - val_loss: 4.2121e-04\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.1810e-04 - val_loss: 4.0831e-04\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.1310e-04 - val_loss: 4.1913e-04\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.0755e-04 - val_loss: 3.7400e-04\n",
      "Thời gian huấn luyện:  11.385509014129639\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_115 (Dense)           (None, 10, 125)           250       \n",
      "                                                                 \n",
      " flatten_92 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,501\n",
      "Trainable params: 1,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 2s 10ms/step - loss: 0.0347 - val_loss: 7.7009e-04\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 7.7157e-04\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 7.1999e-04\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 6.7369e-04\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 6.6356e-04\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 6.1581e-04\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 5.8505e-04\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 5.5570e-04\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 5.3378e-04\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 4.9015e-04\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 4.9179e-04\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 4.8465e-04\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 5.0052e-04\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 4.8435e-04\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.9472e-04\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 4.4962e-04\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.8931e-04\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.5329e-04\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 4.3625e-04\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.9659e-04\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 4.4685e-04\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 9.9224e-04 - val_loss: 4.5708e-04\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 9.7969e-04 - val_loss: 4.6907e-04\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 9.5024e-04 - val_loss: 4.1687e-04\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 9.7939e-04 - val_loss: 4.3081e-04\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 9.3728e-04 - val_loss: 4.0056e-04\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 9.3640e-04 - val_loss: 4.0965e-04\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.9576e-04 - val_loss: 4.7518e-04\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.0392e-04 - val_loss: 4.6549e-04\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.8224e-04 - val_loss: 4.2769e-04\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.0627e-04 - val_loss: 4.1868e-04\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.4659e-04 - val_loss: 3.6705e-04\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 8.7014e-04 - val_loss: 4.1033e-04\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.8511e-04 - val_loss: 3.5823e-04\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.5764e-04 - val_loss: 4.3181e-04\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.6412e-04 - val_loss: 4.1464e-04\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 8.0478e-04 - val_loss: 3.4918e-04\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.0636e-04 - val_loss: 3.6838e-04\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.9389e-04 - val_loss: 4.0077e-04\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.9684e-04 - val_loss: 3.4376e-04\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.7868e-04 - val_loss: 4.0343e-04\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.6269e-04 - val_loss: 3.4496e-04\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.5534e-04 - val_loss: 3.5720e-04\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.6999e-04 - val_loss: 3.8576e-04\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.3720e-04 - val_loss: 3.1387e-04\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.3714e-04 - val_loss: 3.4622e-04\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.6358e-04 - val_loss: 3.4837e-04\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.2850e-04 - val_loss: 3.5587e-04\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.7172e-04 - val_loss: 3.1385e-04\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.9677e-04 - val_loss: 3.4324e-04\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.9620e-04 - val_loss: 3.3136e-04\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.9530e-04 - val_loss: 3.2025e-04\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.9711e-04 - val_loss: 3.0036e-04\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.0668e-04 - val_loss: 3.0173e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.6836e-04 - val_loss: 3.0756e-04\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.7944e-04 - val_loss: 2.9805e-04\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.9253e-04 - val_loss: 3.1977e-04\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.9242e-04 - val_loss: 3.3086e-04\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.6903e-04 - val_loss: 2.8513e-04\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.8433e-04 - val_loss: 3.1100e-04\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.7173e-04 - val_loss: 2.7628e-04\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.5588e-04 - val_loss: 2.8232e-04\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.2777e-04 - val_loss: 2.9567e-04\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.3599e-04 - val_loss: 2.7811e-04\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.2811e-04 - val_loss: 2.6988e-04\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.2919e-04 - val_loss: 2.8427e-04\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.7792e-04 - val_loss: 2.9000e-04\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.5749e-04 - val_loss: 2.8269e-04\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.5457e-04 - val_loss: 2.7526e-04\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.1704e-04 - val_loss: 2.5348e-04\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.2313e-04 - val_loss: 3.0744e-04\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.1355e-04 - val_loss: 2.9740e-04\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.2119e-04 - val_loss: 2.4701e-04\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.8862e-04 - val_loss: 2.6096e-04\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.2357e-04 - val_loss: 2.6540e-04\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.9236e-04 - val_loss: 2.8412e-04\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.2139e-04 - val_loss: 2.6466e-04\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.0093e-04 - val_loss: 2.4705e-04\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.9109e-04 - val_loss: 2.2875e-04\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.8537e-04 - val_loss: 2.2923e-04\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.7059e-04 - val_loss: 2.4358e-04\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.6479e-04 - val_loss: 2.3645e-04\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.2027e-04 - val_loss: 2.2617e-04\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.9998e-04 - val_loss: 2.6437e-04\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.8451e-04 - val_loss: 2.3261e-04\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.6717e-04 - val_loss: 2.4956e-04\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.7224e-04 - val_loss: 2.3137e-04\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.5275e-04 - val_loss: 2.3291e-04\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.6737e-04 - val_loss: 2.4101e-04\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.6216e-04 - val_loss: 2.6185e-04\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.5499e-04 - val_loss: 2.2020e-04\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.4683e-04 - val_loss: 2.2819e-04\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.4301e-04 - val_loss: 2.5100e-04\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.6774e-04 - val_loss: 2.1920e-04\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.1202e-04 - val_loss: 2.2848e-04\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.6937e-04 - val_loss: 2.1718e-04\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.3218e-04 - val_loss: 2.3539e-04\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.4082e-04 - val_loss: 2.2433e-04\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.3372e-04 - val_loss: 2.1225e-04\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.3894e-04 - val_loss: 2.1551e-04\n",
      "Thời gian huấn luyện:  23.409903287887573\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_23 (SimpleRNN)   (None, 10, 125)           15875     \n",
      "                                                                 \n",
      " flatten_93 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,126\n",
      "Trainable params: 17,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 4s 25ms/step - loss: 0.0276 - val_loss: 0.0042\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 8.9972e-04\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0019 - val_loss: 8.4506e-04\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0019 - val_loss: 7.7195e-04\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 8.1715e-04\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0019 - val_loss: 8.1063e-04\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 9.3447e-04\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0018 - val_loss: 8.6051e-04\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0018 - val_loss: 8.2362e-04\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0018 - val_loss: 7.9723e-04\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 8.3055e-04\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 7.2285e-04\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 7.6925e-04\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 8.7885e-04\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 8.3393e-04\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 8.1732e-04\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 7.5253e-04\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 7.8602e-04\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 7.7596e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 7.4716e-04\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0015 - val_loss: 7.7936e-04\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 8.8631e-04\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0015 - val_loss: 6.5006e-04\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 7.2218e-04\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0015 - val_loss: 7.2447e-04\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 6.8770e-04\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 8.0904e-04\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0014 - val_loss: 7.3145e-04\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0014 - val_loss: 6.8642e-04\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0013 - val_loss: 6.1559e-04\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 7.4988e-04\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0013 - val_loss: 6.6177e-04\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 6.7414e-04\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 6.7149e-04\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 6.5924e-04\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 6.5845e-04\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.6387e-04\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 5.5311e-04\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 4.8308e-04\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.7998e-04\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 5.1097e-04\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 5.3426e-04\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 4.9991e-04\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.9476e-04\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.9295e-04\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.0638e-04\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 5.2262e-04\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.9474e-04\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 5.2638e-04\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 5.1814e-04\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 4.7221e-04\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.1913e-04\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.4379e-04\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.7884e-04 - val_loss: 4.1701e-04\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 4.0889e-04\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 4.5902e-04\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 9.6910e-04 - val_loss: 4.1631e-04\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.7828e-04 - val_loss: 4.2594e-04\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 9.6973e-04 - val_loss: 4.5526e-04\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.5146e-04 - val_loss: 4.7325e-04\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.6389e-04 - val_loss: 4.4502e-04\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.4323e-04 - val_loss: 4.0753e-04\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.4624e-04 - val_loss: 4.3339e-04\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.5073e-04 - val_loss: 4.4402e-04\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.3580e-04 - val_loss: 4.1653e-04\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.2714e-04 - val_loss: 4.4766e-04\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 9.6324e-04 - val_loss: 4.4855e-04\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.2411e-04 - val_loss: 4.6742e-04\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 9.5992e-04 - val_loss: 4.5452e-04\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.2161e-04 - val_loss: 5.2199e-04\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.2331e-04 - val_loss: 4.7133e-04\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 8.9485e-04 - val_loss: 4.3061e-04\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.9544e-04 - val_loss: 4.3032e-04\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.9935e-04 - val_loss: 4.4999e-04\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.3633e-04 - val_loss: 4.4808e-04\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.9561e-04 - val_loss: 4.3866e-04\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 8.8818e-04 - val_loss: 4.3637e-04\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 9.0154e-04 - val_loss: 4.2500e-04\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 8.7936e-04 - val_loss: 4.6520e-04\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 8.6987e-04 - val_loss: 4.0087e-04\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.6898e-04 - val_loss: 4.4342e-04\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.5542e-04 - val_loss: 4.6201e-04\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 8.6973e-04 - val_loss: 4.0606e-04\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.7617e-04 - val_loss: 4.2897e-04\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.5866e-04 - val_loss: 3.8667e-04\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.5586e-04 - val_loss: 4.2666e-04\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.4319e-04 - val_loss: 4.7770e-04\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.6814e-04 - val_loss: 4.4799e-04\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.5154e-04 - val_loss: 4.1508e-04\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.4734e-04 - val_loss: 4.5123e-04\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.5137e-04 - val_loss: 4.2887e-04\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 8.8347e-04 - val_loss: 4.2145e-04\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.3315e-04 - val_loss: 4.1901e-04\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.4677e-04 - val_loss: 3.9950e-04\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.3901e-04 - val_loss: 3.6740e-04\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.2790e-04 - val_loss: 3.9064e-04\n",
      "Thời gian huấn luyện:  53.88390111923218\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_23 (LSTM)              (None, 10, 125)           63500     \n",
      "                                                                 \n",
      " flatten_94 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,751\n",
      "Trainable params: 64,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 3s 19ms/step - loss: 0.0211 - val_loss: 0.0042\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 9.4649e-04\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 7.2170e-04\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 5.9908e-04\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 6.3751e-04\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 6.3060e-04\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 6.1625e-04\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 6.0580e-04\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.9628e-04\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 5.7120e-04\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 5.6515e-04\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.6126e-04\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 6.1521e-04\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 4.7233e-04\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.4612e-04\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 4.8434e-04\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 5.4016e-04\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 5.1911e-04\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.1635e-04\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.3212e-04\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.7339e-04\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.2399e-04\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.3999e-04\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.3067e-04\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.1677e-04\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.3141e-04\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 4.0234e-04\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.9628e-04 - val_loss: 4.3432e-04\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.7294e-04 - val_loss: 4.2604e-04\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.5336e-04 - val_loss: 3.9476e-04\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.3064e-04 - val_loss: 3.8784e-04\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.1364e-04 - val_loss: 3.8903e-04\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.0107e-04 - val_loss: 4.0290e-04\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.9963e-04 - val_loss: 3.8195e-04\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.7723e-04 - val_loss: 4.0788e-04\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.8533e-04 - val_loss: 3.8224e-04\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.4657e-04 - val_loss: 3.7169e-04\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.5325e-04 - val_loss: 3.7706e-04\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.2972e-04 - val_loss: 3.7075e-04\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.2662e-04 - val_loss: 3.7276e-04\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.3085e-04 - val_loss: 3.7475e-04\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.1868e-04 - val_loss: 3.6469e-04\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.9750e-04 - val_loss: 3.7168e-04\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.0741e-04 - val_loss: 3.7835e-04\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.9513e-04 - val_loss: 3.6998e-04\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.7379e-04 - val_loss: 3.6072e-04\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.7457e-04 - val_loss: 3.6253e-04\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 8.3545e-04 - val_loss: 3.5915e-04\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.7269e-04 - val_loss: 3.5990e-04\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.7075e-04 - val_loss: 3.5643e-04\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.0981e-04 - val_loss: 3.5847e-04\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.4331e-04 - val_loss: 3.5077e-04\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.3853e-04 - val_loss: 3.4671e-04\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.5785e-04 - val_loss: 3.4703e-04\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.5224e-04 - val_loss: 3.4327e-04\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.3106e-04 - val_loss: 3.3855e-04\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.2767e-04 - val_loss: 3.4030e-04\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.2089e-04 - val_loss: 3.3477e-04\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.0710e-04 - val_loss: 3.3827e-04\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.3557e-04 - val_loss: 3.3520e-04\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.5696e-04 - val_loss: 3.3978e-04\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.4794e-04 - val_loss: 3.3461e-04\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.9586e-04 - val_loss: 3.2617e-04\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.9305e-04 - val_loss: 3.2685e-04\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.8840e-04 - val_loss: 3.2269e-04\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.7683e-04 - val_loss: 3.2728e-04\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.7439e-04 - val_loss: 3.2340e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.8297e-04 - val_loss: 3.1366e-04\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.6669e-04 - val_loss: 3.1062e-04\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.7057e-04 - val_loss: 3.1557e-04\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.7466e-04 - val_loss: 3.0765e-04\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.6584e-04 - val_loss: 3.0876e-04\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.4977e-04 - val_loss: 3.1027e-04\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.5201e-04 - val_loss: 3.0181e-04\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.5273e-04 - val_loss: 3.0047e-04\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.3959e-04 - val_loss: 3.0779e-04\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 6.3780e-04 - val_loss: 3.2990e-04\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.4684e-04 - val_loss: 2.9203e-04\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.2281e-04 - val_loss: 2.9572e-04\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.2355e-04 - val_loss: 2.9020e-04\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.1623e-04 - val_loss: 2.8714e-04\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.3901e-04 - val_loss: 2.8800e-04\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.2269e-04 - val_loss: 2.8348e-04\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.1366e-04 - val_loss: 2.8489e-04\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.1984e-04 - val_loss: 2.8000e-04\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.1053e-04 - val_loss: 2.8213e-04\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.3981e-04 - val_loss: 2.7753e-04\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.9443e-04 - val_loss: 2.8636e-04\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.1672e-04 - val_loss: 2.8822e-04\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.9424e-04 - val_loss: 2.6914e-04\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.9269e-04 - val_loss: 2.6964e-04\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.9299e-04 - val_loss: 2.8621e-04\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.8531e-04 - val_loss: 2.6578e-04\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.7992e-04 - val_loss: 2.6685e-04\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.7620e-04 - val_loss: 2.6044e-04\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.7638e-04 - val_loss: 2.5948e-04\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.7766e-04 - val_loss: 2.6174e-04\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.6706e-04 - val_loss: 2.5887e-04\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.5801e-04 - val_loss: 2.5524e-04\n",
      "Thời gian huấn luyện:  48.230668783187866\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_23 (GRU)                (None, 10, 125)           48000     \n",
      "                                                                 \n",
      " flatten_95 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,251\n",
      "Trainable params: 49,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 965us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 1s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 1s 5ms/step - loss: 0.0687 - val_loss: 0.0413\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0226\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0152\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0059\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 9.6074e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 8.0144e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.7070e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.5775e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.3059e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.9659e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.4253e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.0475e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.2146e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.8228e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.5417e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.5211e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.4965e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.5519e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.2796e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.2444e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.1452e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.1749e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.0362e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.9210e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.9212e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.1629e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.0693e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.9738e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.7226e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.6886e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.6181e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.5486e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.5847e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.5128e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.5115e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.4393e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.4352e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.5576e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.4612e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.3886e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.2366e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.4054e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.2063e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.9820e-04 - val_loss: 2.1819e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.9256e-04 - val_loss: 2.1287e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.8557e-04 - val_loss: 2.1362e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.7205e-04 - val_loss: 2.1247e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.5785e-04 - val_loss: 2.1247e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.5318e-04 - val_loss: 2.2203e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.4830e-04 - val_loss: 2.0953e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.3667e-04 - val_loss: 2.0501e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.2019e-04 - val_loss: 2.0159e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.0743e-04 - val_loss: 1.9620e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.0827e-04 - val_loss: 2.1841e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.8922e-04 - val_loss: 1.9421e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.7905e-04 - val_loss: 1.9178e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.7330e-04 - val_loss: 1.9428e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.6035e-04 - val_loss: 2.0290e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.5246e-04 - val_loss: 1.8528e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.4197e-04 - val_loss: 1.9173e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.4253e-04 - val_loss: 1.8850e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.2220e-04 - val_loss: 1.9449e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.1532e-04 - val_loss: 2.0190e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.1042e-04 - val_loss: 1.7946e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.9672e-04 - val_loss: 1.8247e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.8627e-04 - val_loss: 1.7163e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.8105e-04 - val_loss: 1.7733e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.7281e-04 - val_loss: 1.9017e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.6559e-04 - val_loss: 1.6834e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.5544e-04 - val_loss: 1.7111e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.4557e-04 - val_loss: 1.6694e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.3649e-04 - val_loss: 1.7577e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.2943e-04 - val_loss: 1.6207e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.2477e-04 - val_loss: 1.6470e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.1834e-04 - val_loss: 1.5744e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.1171e-04 - val_loss: 1.5878e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.0450e-04 - val_loss: 1.6702e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.9734e-04 - val_loss: 1.6357e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.9361e-04 - val_loss: 1.6440e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.7965e-04 - val_loss: 1.6236e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.7222e-04 - val_loss: 1.6437e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.6909e-04 - val_loss: 1.6139e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.6050e-04 - val_loss: 1.6117e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.5282e-04 - val_loss: 1.5688e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.5277e-04 - val_loss: 1.5549e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.4666e-04 - val_loss: 1.5467e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.3756e-04 - val_loss: 1.5122e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.3168e-04 - val_loss: 1.6553e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.2536e-04 - val_loss: 1.5141e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.4465e-04 - val_loss: 1.4669e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.1946e-04 - val_loss: 1.4326e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.1138e-04 - val_loss: 1.3976e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.1210e-04 - val_loss: 1.4910e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.0480e-04 - val_loss: 1.4127e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9810e-04 - val_loss: 1.6310e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9532e-04 - val_loss: 1.3827e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.8864e-04 - val_loss: 1.3717e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.8578e-04 - val_loss: 1.3725e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.8720e-04 - val_loss: 1.4507e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7637e-04 - val_loss: 1.4320e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7393e-04 - val_loss: 1.3413e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6854e-04 - val_loss: 1.4380e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.8171e-04 - val_loss: 1.3187e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7778e-04 - val_loss: 1.3687e-04\n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6219e-04 - val_loss: 1.4149e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6385e-04 - val_loss: 1.3770e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6265e-04 - val_loss: 1.4907e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5026e-04 - val_loss: 1.6258e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5461e-04 - val_loss: 1.3950e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4882e-04 - val_loss: 1.3500e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4414e-04 - val_loss: 1.3628e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4097e-04 - val_loss: 1.3544e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4028e-04 - val_loss: 1.2945e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3796e-04 - val_loss: 1.3240e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3385e-04 - val_loss: 1.4190e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3758e-04 - val_loss: 1.3625e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3445e-04 - val_loss: 1.2951e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3243e-04 - val_loss: 1.3036e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3094e-04 - val_loss: 1.3005e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2298e-04 - val_loss: 1.2866e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2162e-04 - val_loss: 1.3195e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1920e-04 - val_loss: 1.3521e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2405e-04 - val_loss: 1.3326e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2535e-04 - val_loss: 1.2393e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1512e-04 - val_loss: 1.3002e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1381e-04 - val_loss: 1.2575e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1079e-04 - val_loss: 1.3636e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2420e-04 - val_loss: 1.3733e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0970e-04 - val_loss: 1.2499e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1368e-04 - val_loss: 1.6496e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2491e-04 - val_loss: 1.4344e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1090e-04 - val_loss: 1.2458e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1095e-04 - val_loss: 1.2506e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0174e-04 - val_loss: 1.2162e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0306e-04 - val_loss: 1.2139e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0473e-04 - val_loss: 1.2109e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9677e-04 - val_loss: 1.2293e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9887e-04 - val_loss: 1.2931e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9421e-04 - val_loss: 1.2035e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9159e-04 - val_loss: 1.2036e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9454e-04 - val_loss: 1.2994e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9375e-04 - val_loss: 1.1959e-04\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9125e-04 - val_loss: 1.2977e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8496e-04 - val_loss: 1.3668e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8964e-04 - val_loss: 1.2567e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8779e-04 - val_loss: 1.2097e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8751e-04 - val_loss: 1.2741e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8413e-04 - val_loss: 1.2528e-04\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9166e-04 - val_loss: 1.3207e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.0038e-04 - val_loss: 1.2885e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7941e-04 - val_loss: 1.3434e-04\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8141e-04 - val_loss: 1.2280e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7970e-04 - val_loss: 1.2045e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7803e-04 - val_loss: 1.2071e-04\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8009e-04 - val_loss: 1.1765e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7509e-04 - val_loss: 1.1736e-04\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7310e-04 - val_loss: 1.1734e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7514e-04 - val_loss: 1.2124e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.7244e-04 - val_loss: 1.1583e-04\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7823e-04 - val_loss: 1.1592e-04\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8037e-04 - val_loss: 1.1597e-04\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7160e-04 - val_loss: 1.1582e-04\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6832e-04 - val_loss: 1.1489e-04\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7047e-04 - val_loss: 1.1507e-04\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7440e-04 - val_loss: 1.2303e-04\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6834e-04 - val_loss: 1.2191e-04\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6353e-04 - val_loss: 1.1788e-04\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6553e-04 - val_loss: 1.1506e-04\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6871e-04 - val_loss: 1.2713e-04\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6489e-04 - val_loss: 1.1397e-04\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6286e-04 - val_loss: 1.1376e-04\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5976e-04 - val_loss: 1.2043e-04\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6240e-04 - val_loss: 1.2891e-04\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6340e-04 - val_loss: 1.2530e-04\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5758e-04 - val_loss: 1.1699e-04\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5588e-04 - val_loss: 1.1495e-04\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5435e-04 - val_loss: 1.2270e-04\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6018e-04 - val_loss: 1.2150e-04\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6298e-04 - val_loss: 1.1396e-04\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5608e-04 - val_loss: 1.1718e-04\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5337e-04 - val_loss: 1.1454e-04\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5414e-04 - val_loss: 1.1601e-04\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5256e-04 - val_loss: 1.2017e-04\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5617e-04 - val_loss: 1.1726e-04\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5147e-04 - val_loss: 1.1703e-04\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4929e-04 - val_loss: 1.1033e-04\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4876e-04 - val_loss: 1.1086e-04\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4747e-04 - val_loss: 1.1086e-04\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5013e-04 - val_loss: 1.1047e-04\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4781e-04 - val_loss: 1.1902e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4458e-04 - val_loss: 1.1060e-04\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4443e-04 - val_loss: 1.1005e-04\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4500e-04 - val_loss: 1.0997e-04\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4656e-04 - val_loss: 1.1081e-04\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4014e-04 - val_loss: 1.1027e-04\n",
      "Thời gian huấn luyện:  22.24194574356079\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 10, 125)           250       \n",
      "                                                                 \n",
      " flatten_96 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,501\n",
      "Trainable params: 1,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.0247 - val_loss: 5.0703e-04\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 3.3020e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 3.1431e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 3.1261e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 2.8048e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 2.6528e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 2.7061e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.4267e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.2242e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.1598e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.0647e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.1654e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 1.9580e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.5378e-04 - val_loss: 1.9508e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.6773e-04 - val_loss: 1.9076e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.0235e-04 - val_loss: 1.9649e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.9836e-04 - val_loss: 1.8068e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.6703e-04 - val_loss: 1.7828e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.5663e-04 - val_loss: 1.7627e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.3597e-04 - val_loss: 1.7354e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.2187e-04 - val_loss: 1.7396e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.4942e-04 - val_loss: 1.6829e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.2361e-04 - val_loss: 1.6559e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.9375e-04 - val_loss: 1.6453e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.6055e-04 - val_loss: 1.6046e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.6209e-04 - val_loss: 1.5875e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.6100e-04 - val_loss: 1.6469e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.5201e-04 - val_loss: 1.5562e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3659e-04 - val_loss: 1.5465e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2976e-04 - val_loss: 1.6964e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1659e-04 - val_loss: 1.6055e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4516e-04 - val_loss: 1.4904e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2134e-04 - val_loss: 1.5516e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0822e-04 - val_loss: 1.5036e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0414e-04 - val_loss: 1.4483e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8063e-04 - val_loss: 1.4560e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8172e-04 - val_loss: 1.4373e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8289e-04 - val_loss: 1.4232e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6088e-04 - val_loss: 1.3950e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5439e-04 - val_loss: 1.3908e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5472e-04 - val_loss: 1.5479e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5701e-04 - val_loss: 1.4613e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4640e-04 - val_loss: 1.3467e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2639e-04 - val_loss: 1.4059e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.2569e-04 - val_loss: 1.3251e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3333e-04 - val_loss: 1.3147e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1618e-04 - val_loss: 1.3090e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4159e-04 - val_loss: 1.3365e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3362e-04 - val_loss: 1.3098e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1635e-04 - val_loss: 1.3489e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1221e-04 - val_loss: 1.2861e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0757e-04 - val_loss: 1.2586e-04\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9145e-04 - val_loss: 1.2542e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.6725e-04 - val_loss: 1.3443e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7405e-04 - val_loss: 1.2378e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8084e-04 - val_loss: 1.2547e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7176e-04 - val_loss: 1.2094e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7460e-04 - val_loss: 1.2700e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.5536e-04 - val_loss: 1.2275e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8116e-04 - val_loss: 1.1893e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4988e-04 - val_loss: 1.2259e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.5208e-04 - val_loss: 1.1777e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.5610e-04 - val_loss: 1.1714e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.5208e-04 - val_loss: 1.2051e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4820e-04 - val_loss: 1.1781e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.5233e-04 - val_loss: 1.1350e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.3129e-04 - val_loss: 1.1700e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.3974e-04 - val_loss: 1.1403e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2123e-04 - val_loss: 1.1296e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.5854e-04 - val_loss: 1.1787e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4026e-04 - val_loss: 1.1109e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.3257e-04 - val_loss: 1.1337e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1540e-04 - val_loss: 1.1077e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.1743e-04 - val_loss: 1.1856e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1593e-04 - val_loss: 1.1117e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1596e-04 - val_loss: 1.1066e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0258e-04 - val_loss: 1.1128e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1099e-04 - val_loss: 1.0756e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0784e-04 - val_loss: 1.1509e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0670e-04 - val_loss: 1.0573e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9262e-04 - val_loss: 1.0477e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0530e-04 - val_loss: 1.0476e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0245e-04 - val_loss: 1.1125e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0513e-04 - val_loss: 1.0458e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0381e-04 - val_loss: 1.0216e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1287e-04 - val_loss: 1.0493e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6614e-04 - val_loss: 1.0228e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8212e-04 - val_loss: 1.0555e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0657e-04 - val_loss: 1.0079e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7661e-04 - val_loss: 1.0190e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6234e-04 - val_loss: 1.0107e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.7586e-04 - val_loss: 1.0139e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5785e-04 - val_loss: 1.0258e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.3272e-04 - val_loss: 1.0947e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0845e-04 - val_loss: 1.0340e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6270e-04 - val_loss: 9.7182e-05\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4755e-04 - val_loss: 1.0099e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0455e-04 - val_loss: 1.0243e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9464e-04 - val_loss: 9.6031e-05\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6496e-04 - val_loss: 9.7243e-05\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3826e-04 - val_loss: 9.7700e-05\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4980e-04 - val_loss: 9.5838e-05\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4992e-04 - val_loss: 9.4748e-05\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.5748e-04 - val_loss: 1.0558e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4279e-04 - val_loss: 9.5651e-05\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3164e-04 - val_loss: 9.4040e-05\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4613e-04 - val_loss: 9.9349e-05\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4612e-04 - val_loss: 9.4305e-05\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5209e-04 - val_loss: 9.4158e-05\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2496e-04 - val_loss: 9.2745e-05\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2551e-04 - val_loss: 9.5001e-05\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2620e-04 - val_loss: 9.1889e-05\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2677e-04 - val_loss: 1.0659e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3516e-04 - val_loss: 9.2077e-05\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.4422e-04 - val_loss: 9.0874e-05\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2937e-04 - val_loss: 9.3542e-05\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2727e-04 - val_loss: 8.8938e-05\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1742e-04 - val_loss: 9.0356e-05\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.6685e-04 - val_loss: 9.1498e-05\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1742e-04 - val_loss: 9.3122e-05\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2179e-04 - val_loss: 8.8500e-05\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3719e-04 - val_loss: 9.2571e-05\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2661e-04 - val_loss: 9.6777e-05\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1411e-04 - val_loss: 8.8390e-05\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2449e-04 - val_loss: 8.7246e-05\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1318e-04 - val_loss: 8.8211e-05\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1417e-04 - val_loss: 8.7001e-05\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1193e-04 - val_loss: 8.8926e-05\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3476e-04 - val_loss: 8.5761e-05\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1796e-04 - val_loss: 8.7811e-05\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0437e-04 - val_loss: 8.6669e-05\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1773e-04 - val_loss: 8.5815e-05\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2454e-04 - val_loss: 8.8597e-05\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9926e-04 - val_loss: 8.9278e-05\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0352e-04 - val_loss: 8.6582e-05\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0474e-04 - val_loss: 8.5272e-05\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0330e-04 - val_loss: 9.3106e-05\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0391e-04 - val_loss: 8.4696e-05\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0754e-04 - val_loss: 8.4607e-05\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9563e-04 - val_loss: 8.3202e-05\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1092e-04 - val_loss: 8.6720e-05\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9338e-04 - val_loss: 8.5304e-05\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0463e-04 - val_loss: 8.3064e-05\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0140e-04 - val_loss: 8.5845e-05\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8601e-04 - val_loss: 8.2347e-05\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0298e-04 - val_loss: 8.7970e-05\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0340e-04 - val_loss: 8.2622e-05\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9466e-04 - val_loss: 8.6894e-05\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1112e-04 - val_loss: 8.1214e-05\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8509e-04 - val_loss: 8.2033e-05\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.8498e-04 - val_loss: 8.2109e-05\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2612e-04 - val_loss: 9.5816e-05\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0698e-04 - val_loss: 8.3401e-05\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9520e-04 - val_loss: 8.1809e-05\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8294e-04 - val_loss: 8.7049e-05\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9128e-04 - val_loss: 8.0130e-05\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7429e-04 - val_loss: 8.0057e-05\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2257e-04 - val_loss: 8.9560e-05\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9109e-04 - val_loss: 8.1793e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7924e-04 - val_loss: 8.5793e-05\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8255e-04 - val_loss: 8.8635e-05\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7218e-04 - val_loss: 7.9391e-05\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8100e-04 - val_loss: 8.3697e-05\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 3.8667e-04 - val_loss: 8.1180e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9320e-04 - val_loss: 8.2124e-05\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8945e-04 - val_loss: 7.8603e-05\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.1918e-04 - val_loss: 7.9470e-05\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7583e-04 - val_loss: 8.1894e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7326e-04 - val_loss: 7.9466e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7748e-04 - val_loss: 7.9402e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6985e-04 - val_loss: 7.8249e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7458e-04 - val_loss: 7.9128e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8848e-04 - val_loss: 7.9606e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8165e-04 - val_loss: 8.0982e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.6599e-04 - val_loss: 7.8120e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.6818e-04 - val_loss: 8.1622e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7684e-04 - val_loss: 8.2783e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6913e-04 - val_loss: 7.7695e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7261e-04 - val_loss: 7.7218e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6255e-04 - val_loss: 7.7948e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8966e-04 - val_loss: 8.5907e-05\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7899e-04 - val_loss: 9.3058e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8171e-04 - val_loss: 7.7845e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0087e-04 - val_loss: 8.1728e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9197e-04 - val_loss: 7.8118e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7259e-04 - val_loss: 7.8240e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6700e-04 - val_loss: 8.1592e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0455e-04 - val_loss: 7.7358e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9063e-04 - val_loss: 8.8512e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.6578e-04 - val_loss: 7.9456e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6763e-04 - val_loss: 7.6818e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6310e-04 - val_loss: 7.7057e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.8584e-04 - val_loss: 7.6849e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7569e-04 - val_loss: 7.7986e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6194e-04 - val_loss: 8.6793e-05\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7052e-04 - val_loss: 8.3972e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7332e-04 - val_loss: 7.6905e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7811e-04 - val_loss: 7.8207e-05\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6432e-04 - val_loss: 7.9892e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6333e-04 - val_loss: 7.7290e-05\n",
      "Thời gian huấn luyện:  46.71827149391174\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " simple_rnn_24 (SimpleRNN)   (None, 10, 125)           15875     \n",
      "                                                                 \n",
      " flatten_97 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,126\n",
      "Trainable params: 17,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 4s 21ms/step - loss: 0.0397 - val_loss: 0.0036\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0022 - val_loss: 9.4840e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 5.0871e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 3.9391e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 4.2336e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 4.2496e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 4.2118e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 3.6515e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 3.5233e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 3.4358e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 3.6562e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 5.3356e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 4.1395e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 3.9843e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 3.2161e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 3.3326e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 3.4466e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 3.5126e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 3.1522e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 3.0061e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 3.2841e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 2.9394e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 3.3077e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 3.2690e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 3.2441e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 3.0175e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 2.5853e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 2.8055e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 2.8045e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.6639e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.4854e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 3.0663e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.3228e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.8439e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.5605e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.4092e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.3856e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 0.0011 - val_loss: 2.3023e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 2.1869e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0012 - val_loss: 2.3446e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 0.0011 - val_loss: 2.1659e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 2.1806e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 2.1813e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 2.2905e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 2.2303e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.9798e-04 - val_loss: 2.0882e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 2.3226e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 2.0575e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.8690e-04 - val_loss: 2.1415e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 9.8250e-04 - val_loss: 2.2057e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.8587e-04 - val_loss: 2.0230e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.7227e-04 - val_loss: 2.0348e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.3282e-04 - val_loss: 2.1674e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.4288e-04 - val_loss: 2.0346e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 9.1911e-04 - val_loss: 2.0160e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 9.3105e-04 - val_loss: 2.0030e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 9.0364e-04 - val_loss: 1.9917e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 9.2987e-04 - val_loss: 2.0330e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.3073e-04 - val_loss: 1.9816e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.9577e-04 - val_loss: 1.9828e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 9.1488e-04 - val_loss: 1.9382e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 9.0103e-04 - val_loss: 1.9538e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 9.1340e-04 - val_loss: 2.4455e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.2566e-04 - val_loss: 1.9329e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.9634e-04 - val_loss: 2.1580e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 9.1825e-04 - val_loss: 2.0197e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.0720e-04 - val_loss: 1.8915e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.7186e-04 - val_loss: 1.9092e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.6020e-04 - val_loss: 1.9705e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.5580e-04 - val_loss: 1.9236e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.5957e-04 - val_loss: 1.8766e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.7618e-04 - val_loss: 1.8613e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.8528e-04 - val_loss: 2.1895e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.3751e-04 - val_loss: 1.8856e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.5075e-04 - val_loss: 1.9119e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.4281e-04 - val_loss: 1.8398e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.2611e-04 - val_loss: 1.9988e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.6121e-04 - val_loss: 1.8846e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.2105e-04 - val_loss: 1.8623e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.3239e-04 - val_loss: 1.8153e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.2389e-04 - val_loss: 1.8626e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.1805e-04 - val_loss: 1.9543e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.1496e-04 - val_loss: 1.9551e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.9407e-04 - val_loss: 1.9231e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.1422e-04 - val_loss: 1.7761e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.8690e-04 - val_loss: 1.7768e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.8589e-04 - val_loss: 1.7448e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.0063e-04 - val_loss: 1.8806e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.7908e-04 - val_loss: 1.8649e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.7766e-04 - val_loss: 1.7222e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.8829e-04 - val_loss: 1.9241e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.7054e-04 - val_loss: 1.7342e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.6481e-04 - val_loss: 1.7107e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.6938e-04 - val_loss: 1.7963e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.5285e-04 - val_loss: 1.7461e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.5491e-04 - val_loss: 1.7100e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.4180e-04 - val_loss: 1.7954e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.5855e-04 - val_loss: 1.8801e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.6494e-04 - val_loss: 1.7260e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.3921e-04 - val_loss: 1.7959e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 7.3549e-04 - val_loss: 1.8494e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.4145e-04 - val_loss: 1.6797e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.4399e-04 - val_loss: 1.8028e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.1841e-04 - val_loss: 1.7407e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 7.1612e-04 - val_loss: 1.6884e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.1739e-04 - val_loss: 1.6344e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.2034e-04 - val_loss: 1.8915e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.1736e-04 - val_loss: 1.7081e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.1125e-04 - val_loss: 1.7014e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.1597e-04 - val_loss: 1.6030e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.9436e-04 - val_loss: 1.7688e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.9245e-04 - val_loss: 1.9988e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.7966e-04 - val_loss: 1.6388e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.7967e-04 - val_loss: 1.6023e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.8275e-04 - val_loss: 1.7035e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 6.9183e-04 - val_loss: 1.7606e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.8489e-04 - val_loss: 1.5827e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.6789e-04 - val_loss: 1.5511e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.8076e-04 - val_loss: 1.6675e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.9424e-04 - val_loss: 1.7169e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.8013e-04 - val_loss: 1.5454e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.7187e-04 - val_loss: 1.6463e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.6732e-04 - val_loss: 1.5551e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.5614e-04 - val_loss: 1.5457e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.4502e-04 - val_loss: 1.4800e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.1063e-04 - val_loss: 1.6109e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.5580e-04 - val_loss: 1.5417e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.4137e-04 - val_loss: 1.5451e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.4237e-04 - val_loss: 1.6418e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.3089e-04 - val_loss: 1.6312e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.2157e-04 - val_loss: 1.5544e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.2683e-04 - val_loss: 1.7225e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.3792e-04 - val_loss: 1.4547e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.1575e-04 - val_loss: 1.5167e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 6.5183e-04 - val_loss: 1.7876e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.4771e-04 - val_loss: 1.5320e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.2237e-04 - val_loss: 1.6395e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.0482e-04 - val_loss: 1.5285e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.0627e-04 - val_loss: 1.5272e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 6.1156e-04 - val_loss: 1.4087e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.0012e-04 - val_loss: 1.5021e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.9891e-04 - val_loss: 1.5638e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.9334e-04 - val_loss: 1.5092e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 6.1430e-04 - val_loss: 1.4065e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.9194e-04 - val_loss: 1.4738e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.9506e-04 - val_loss: 1.5699e-04\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 10ms/step - loss: 5.8508e-04 - val_loss: 1.3588e-04\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.8535e-04 - val_loss: 1.5606e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.0489e-04 - val_loss: 1.3508e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.9054e-04 - val_loss: 1.5288e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.7532e-04 - val_loss: 1.4156e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.6737e-04 - val_loss: 1.3961e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.7710e-04 - val_loss: 1.5546e-04\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.6871e-04 - val_loss: 1.3464e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.7136e-04 - val_loss: 1.3373e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.6092e-04 - val_loss: 1.3206e-04\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.6987e-04 - val_loss: 1.4502e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.7318e-04 - val_loss: 1.3536e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.5326e-04 - val_loss: 1.5921e-04\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.6364e-04 - val_loss: 1.3303e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.5790e-04 - val_loss: 1.5774e-04\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.5721e-04 - val_loss: 1.3454e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.6098e-04 - val_loss: 1.3352e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.4520e-04 - val_loss: 1.3496e-04\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.4280e-04 - val_loss: 1.3234e-04\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.3252e-04 - val_loss: 1.4223e-04\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.7819e-04 - val_loss: 1.6782e-04\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3945e-04 - val_loss: 1.5557e-04\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3458e-04 - val_loss: 1.3813e-04\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.3987e-04 - val_loss: 1.2787e-04\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.6278e-04 - val_loss: 1.3465e-04\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.5387e-04 - val_loss: 1.5339e-04\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.9935e-04 - val_loss: 1.3889e-04\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3210e-04 - val_loss: 1.3585e-04\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.4048e-04 - val_loss: 1.4226e-04\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2824e-04 - val_loss: 1.2679e-04\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.2165e-04 - val_loss: 1.5239e-04\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.3280e-04 - val_loss: 1.6194e-04\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.2433e-04 - val_loss: 1.4444e-04\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.1064e-04 - val_loss: 1.2624e-04\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3068e-04 - val_loss: 1.2455e-04\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.0878e-04 - val_loss: 1.4410e-04\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1339e-04 - val_loss: 1.2583e-04\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.1403e-04 - val_loss: 1.3586e-04\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.0564e-04 - val_loss: 1.2111e-04\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.1804e-04 - val_loss: 1.2862e-04\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.0422e-04 - val_loss: 1.2541e-04\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.1105e-04 - val_loss: 1.2612e-04\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.0294e-04 - val_loss: 1.3473e-04\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.0784e-04 - val_loss: 1.2116e-04\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.9727e-04 - val_loss: 1.3554e-04\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.9034e-04 - val_loss: 1.2383e-04\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.0661e-04 - val_loss: 1.4031e-04\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.8593e-04 - val_loss: 1.3259e-04\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8663e-04 - val_loss: 1.6716e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.9450e-04 - val_loss: 1.1858e-04\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.8348e-04 - val_loss: 1.3736e-04\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.9878e-04 - val_loss: 1.4221e-04\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.8241e-04 - val_loss: 1.1966e-04\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8095e-04 - val_loss: 1.2414e-04\n",
      "Thời gian huấn luyện:  108.31766557693481\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_24 (LSTM)              (None, 10, 125)           63500     \n",
      "                                                                 \n",
      " flatten_98 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,751\n",
      "Trainable params: 64,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 3s 16ms/step - loss: 0.0198 - val_loss: 0.0023\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 4.3912e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 3.0533e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 2.8230e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 2.6013e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 2.7618e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 2.6474e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 2.6609e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 2.7291e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 2.3621e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 2.4045e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 2.5628e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.2448e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.2003e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.4006e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.1725e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.1232e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.0627e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.0423e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.0594e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.1700e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 1.9873e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 1.9713e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 9.8183e-04 - val_loss: 1.9002e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.5844e-04 - val_loss: 1.8838e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 9.5629e-04 - val_loss: 1.9466e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.1467e-04 - val_loss: 1.9233e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.0177e-04 - val_loss: 1.8232e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.0058e-04 - val_loss: 1.8255e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.6348e-04 - val_loss: 1.8141e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.6441e-04 - val_loss: 1.8064e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.2931e-04 - val_loss: 1.8131e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.1039e-04 - val_loss: 1.7484e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.1448e-04 - val_loss: 1.7482e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.8722e-04 - val_loss: 1.7772e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.8552e-04 - val_loss: 1.7399e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.6836e-04 - val_loss: 1.7381e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.6280e-04 - val_loss: 1.7292e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.5146e-04 - val_loss: 1.7744e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.3678e-04 - val_loss: 1.7507e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.3453e-04 - val_loss: 1.6891e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 7.4958e-04 - val_loss: 1.7059e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.3331e-04 - val_loss: 1.6978e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.2410e-04 - val_loss: 1.7551e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.0346e-04 - val_loss: 1.7889e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.0572e-04 - val_loss: 1.7543e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.0785e-04 - val_loss: 1.7029e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.8837e-04 - val_loss: 1.6451e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.0103e-04 - val_loss: 1.6235e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.8234e-04 - val_loss: 1.6533e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.8563e-04 - val_loss: 1.7022e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.7617e-04 - val_loss: 1.6056e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.8817e-04 - val_loss: 1.6747e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.6360e-04 - val_loss: 1.5837e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.7154e-04 - val_loss: 1.5687e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.5984e-04 - val_loss: 1.5721e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.6493e-04 - val_loss: 1.5640e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.4344e-04 - val_loss: 1.5488e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.3813e-04 - val_loss: 1.5487e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.3212e-04 - val_loss: 1.5199e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.3406e-04 - val_loss: 1.5264e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.2545e-04 - val_loss: 1.5348e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.5397e-04 - val_loss: 1.4901e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.1341e-04 - val_loss: 1.5658e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.2515e-04 - val_loss: 1.4753e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.0506e-04 - val_loss: 1.4711e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.1379e-04 - val_loss: 1.4687e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.9413e-04 - val_loss: 1.4126e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.0957e-04 - val_loss: 1.5716e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.0604e-04 - val_loss: 1.4151e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.9002e-04 - val_loss: 1.4926e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.9990e-04 - val_loss: 1.3903e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.7144e-04 - val_loss: 1.4678e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.8032e-04 - val_loss: 1.4603e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.9045e-04 - val_loss: 1.3803e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.8093e-04 - val_loss: 1.5380e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.6745e-04 - val_loss: 1.3443e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.6500e-04 - val_loss: 1.3396e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.0283e-04 - val_loss: 1.4043e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.0747e-04 - val_loss: 1.3705e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.5878e-04 - val_loss: 1.3366e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.5472e-04 - val_loss: 1.3225e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.5012e-04 - val_loss: 1.4615e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.4727e-04 - val_loss: 1.2994e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.3901e-04 - val_loss: 1.3347e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.4284e-04 - val_loss: 1.3853e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.5328e-04 - val_loss: 1.2828e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3949e-04 - val_loss: 1.3117e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3773e-04 - val_loss: 1.3003e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.2349e-04 - val_loss: 1.2505e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2210e-04 - val_loss: 1.2571e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1872e-04 - val_loss: 1.2552e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1679e-04 - val_loss: 1.2311e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3351e-04 - val_loss: 1.2823e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.0780e-04 - val_loss: 1.2374e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2814e-04 - val_loss: 1.3002e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.0653e-04 - val_loss: 1.1988e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.0477e-04 - val_loss: 1.2020e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.0349e-04 - val_loss: 1.2671e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.1917e-04 - val_loss: 1.3426e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.9521e-04 - val_loss: 1.2763e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1434e-04 - val_loss: 1.2162e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8888e-04 - val_loss: 1.2396e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.0059e-04 - val_loss: 1.1683e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.9105e-04 - val_loss: 1.1630e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.9309e-04 - val_loss: 1.2334e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8223e-04 - val_loss: 1.1448e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7683e-04 - val_loss: 1.1490e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.9047e-04 - val_loss: 1.1468e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7983e-04 - val_loss: 1.1579e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.7245e-04 - val_loss: 1.2203e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.6361e-04 - val_loss: 1.1460e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8477e-04 - val_loss: 1.1734e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7817e-04 - val_loss: 1.1135e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8999e-04 - val_loss: 1.1341e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8027e-04 - val_loss: 1.0982e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.6369e-04 - val_loss: 1.0930e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5913e-04 - val_loss: 1.2044e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5651e-04 - val_loss: 1.1619e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.6499e-04 - val_loss: 1.1062e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5344e-04 - val_loss: 1.0915e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5476e-04 - val_loss: 1.0745e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7531e-04 - val_loss: 1.1053e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7808e-04 - val_loss: 1.0729e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5121e-04 - val_loss: 1.0705e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5163e-04 - val_loss: 1.0590e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.4678e-04 - val_loss: 1.0610e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.4300e-04 - val_loss: 1.0621e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.4535e-04 - val_loss: 1.0542e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.4909e-04 - val_loss: 1.1207e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3750e-04 - val_loss: 1.0862e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3777e-04 - val_loss: 1.0569e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3255e-04 - val_loss: 1.0484e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3024e-04 - val_loss: 1.0266e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3346e-04 - val_loss: 1.0543e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2802e-04 - val_loss: 1.0304e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3932e-04 - val_loss: 1.0927e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3245e-04 - val_loss: 1.0100e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3456e-04 - val_loss: 1.0003e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2833e-04 - val_loss: 1.0207e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2182e-04 - val_loss: 1.0831e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2232e-04 - val_loss: 9.9910e-05\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1434e-04 - val_loss: 1.0098e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3141e-04 - val_loss: 1.0183e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3274e-04 - val_loss: 1.0873e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2223e-04 - val_loss: 9.7809e-05\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1717e-04 - val_loss: 9.9671e-05\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1472e-04 - val_loss: 1.1658e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1910e-04 - val_loss: 1.0829e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1007e-04 - val_loss: 9.7812e-05\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1296e-04 - val_loss: 1.0527e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1578e-04 - val_loss: 1.0228e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1140e-04 - val_loss: 9.8055e-05\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0546e-04 - val_loss: 9.6140e-05\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0912e-04 - val_loss: 1.0005e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1172e-04 - val_loss: 9.4979e-05\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9832e-04 - val_loss: 9.4479e-05\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0468e-04 - val_loss: 9.5649e-05\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0152e-04 - val_loss: 1.0460e-04\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1072e-04 - val_loss: 9.4492e-05\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.0535e-04 - val_loss: 9.6153e-05\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2814e-04 - val_loss: 9.3341e-05\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 3.9631e-04 - val_loss: 9.4368e-05\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0084e-04 - val_loss: 9.2868e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9767e-04 - val_loss: 1.0553e-04\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9261e-04 - val_loss: 9.2637e-05\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9547e-04 - val_loss: 9.1789e-05\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9617e-04 - val_loss: 9.4421e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0124e-04 - val_loss: 9.0617e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0387e-04 - val_loss: 9.1824e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8867e-04 - val_loss: 9.2054e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8637e-04 - val_loss: 9.9077e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0558e-04 - val_loss: 9.2189e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8650e-04 - val_loss: 9.1680e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8560e-04 - val_loss: 8.9458e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9971e-04 - val_loss: 9.4861e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8430e-04 - val_loss: 9.0814e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9142e-04 - val_loss: 9.8248e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8872e-04 - val_loss: 9.8431e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0011e-04 - val_loss: 9.2169e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8777e-04 - val_loss: 9.9255e-05\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8483e-04 - val_loss: 8.8069e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7901e-04 - val_loss: 9.0007e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 3.7752e-04 - val_loss: 8.8018e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7761e-04 - val_loss: 8.8835e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8488e-04 - val_loss: 9.0300e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8495e-04 - val_loss: 9.1943e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8528e-04 - val_loss: 8.7105e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7775e-04 - val_loss: 8.7995e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8588e-04 - val_loss: 8.7709e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 3.8506e-04 - val_loss: 8.6740e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0197e-04 - val_loss: 8.9397e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7170e-04 - val_loss: 8.7035e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7552e-04 - val_loss: 8.6538e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8105e-04 - val_loss: 8.8936e-05\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9609e-04 - val_loss: 9.3713e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8331e-04 - val_loss: 8.7658e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 3.9148e-04 - val_loss: 1.0686e-04\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8508e-04 - val_loss: 9.2267e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.6951e-04 - val_loss: 8.4613e-05\n",
      "Thời gian huấn luyện:  96.35558414459229\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_24 (GRU)                (None, 10, 125)           48000     \n",
      "                                                                 \n",
      " flatten_99 (Flatten)        (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,251\n",
      "Trainable params: 49,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 1s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "59/59 [==============================] - 1s 4ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "50/50 [==============================] - 1s 5ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 2/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 3/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 4/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 5/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 6/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 7/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 8/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 9/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 10/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 11/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 12/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 13/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 14/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 15/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 16/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 17/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 18/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 19/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 20/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 21/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 22/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 23/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 24/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 25/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 26/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 27/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 28/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 29/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 30/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 31/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 32/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 33/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 34/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 35/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 36/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 37/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 38/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 39/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 40/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 41/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 42/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 43/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 44/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 45/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 46/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 47/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 48/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 49/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 50/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 51/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 52/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 53/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 54/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 55/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 56/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 57/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 58/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 59/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 60/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 61/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 62/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 63/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 64/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 65/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 66/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 67/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 68/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 69/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 70/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 71/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 72/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 73/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 74/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 75/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 76/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 77/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 78/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 79/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 80/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 81/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 82/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 83/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 84/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 85/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 86/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 87/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 88/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 89/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 90/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 91/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 92/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 93/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 94/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 95/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 96/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 97/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 98/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 99/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 100/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 101/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 102/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 103/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 104/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 105/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 106/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 107/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 108/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 109/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 110/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 111/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 112/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 113/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 115/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 116/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 117/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 118/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 119/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 120/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 121/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 122/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 123/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 124/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 125/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 126/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 127/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 128/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 129/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 130/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 131/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 132/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 133/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 134/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 135/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 136/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 137/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 138/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 139/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 140/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 141/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 142/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 143/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 144/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 145/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 146/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 147/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 148/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 149/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 150/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 151/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 152/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 153/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 154/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 155/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 156/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 157/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 158/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 159/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 160/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 161/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 162/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 163/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 164/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 165/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 166/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 167/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 168/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 169/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 170/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 171/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 172/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 173/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 174/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 175/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 176/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 177/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 178/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 179/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 180/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 181/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 182/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 183/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 184/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 185/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 186/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 187/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 188/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 189/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 190/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 191/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 192/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 193/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 194/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 196/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 197/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 198/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 199/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 200/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Thời gian huấn luyện:  23.171623945236206\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_125 (Dense)           (None, 10, 125)           250       \n",
      "                                                                 \n",
      " flatten_100 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,501\n",
      "Trainable params: 1,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "50/50 [==============================] - 1s 8ms/step - loss: 0.0300 - val_loss: 8.4158e-04\n",
      "Epoch 2/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 6.3576e-04\n",
      "Epoch 3/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 5.6376e-04\n",
      "Epoch 4/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 5.2526e-04\n",
      "Epoch 5/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 5.1314e-04\n",
      "Epoch 6/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 4.6508e-04\n",
      "Epoch 7/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 4.3538e-04\n",
      "Epoch 8/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 4.2259e-04\n",
      "Epoch 9/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 3.8181e-04\n",
      "Epoch 10/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 3.5899e-04\n",
      "Epoch 11/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 3.4753e-04\n",
      "Epoch 12/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 3.4002e-04\n",
      "Epoch 13/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 3.2387e-04\n",
      "Epoch 14/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 3.0713e-04\n",
      "Epoch 15/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 3.0346e-04\n",
      "Epoch 16/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 2.9632e-04\n",
      "Epoch 17/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 3.1025e-04\n",
      "Epoch 18/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.8155e-04\n",
      "Epoch 19/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 2.7370e-04\n",
      "Epoch 20/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 3.0524e-04\n",
      "Epoch 21/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.8906e-04\n",
      "Epoch 22/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 2.6641e-04\n",
      "Epoch 23/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 2.9347e-04\n",
      "Epoch 24/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 3.0204e-04\n",
      "Epoch 25/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.6618e-04\n",
      "Epoch 26/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.6472e-04\n",
      "Epoch 27/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 9.7960e-04 - val_loss: 2.4269e-04\n",
      "Epoch 28/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 9.8240e-04 - val_loss: 2.6713e-04\n",
      "Epoch 29/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.4524e-04\n",
      "Epoch 30/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 9.5193e-04 - val_loss: 2.6388e-04\n",
      "Epoch 31/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 9.6408e-04 - val_loss: 2.5717e-04\n",
      "Epoch 32/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 9.3326e-04 - val_loss: 2.3523e-04\n",
      "Epoch 33/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 9.4525e-04 - val_loss: 2.6640e-04\n",
      "Epoch 34/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 9.4716e-04 - val_loss: 2.2622e-04\n",
      "Epoch 35/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.8920e-04 - val_loss: 2.1896e-04\n",
      "Epoch 36/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 9.1505e-04 - val_loss: 2.2878e-04\n",
      "Epoch 37/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 9.0839e-04 - val_loss: 2.1684e-04\n",
      "Epoch 38/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.9040e-04 - val_loss: 2.2361e-04\n",
      "Epoch 39/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.9853e-04 - val_loss: 2.7757e-04\n",
      "Epoch 40/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 9.0224e-04 - val_loss: 2.4509e-04\n",
      "Epoch 41/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.3605e-04 - val_loss: 2.2032e-04\n",
      "Epoch 42/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.3504e-04 - val_loss: 2.1697e-04\n",
      "Epoch 43/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.1246e-04 - val_loss: 2.1265e-04\n",
      "Epoch 44/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.2063e-04 - val_loss: 2.0239e-04\n",
      "Epoch 45/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.1346e-04 - val_loss: 1.9682e-04\n",
      "Epoch 46/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.0470e-04 - val_loss: 2.0829e-04\n",
      "Epoch 47/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.2112e-04 - val_loss: 2.3508e-04\n",
      "Epoch 48/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 8.3932e-04 - val_loss: 2.1321e-04\n",
      "Epoch 49/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 7.7398e-04 - val_loss: 1.9412e-04\n",
      "Epoch 50/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 7.5644e-04 - val_loss: 2.0744e-04\n",
      "Epoch 51/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 7.8076e-04 - val_loss: 2.0723e-04\n",
      "Epoch 52/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 7.4454e-04 - val_loss: 2.0176e-04\n",
      "Epoch 53/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.3577e-04 - val_loss: 1.9725e-04\n",
      "Epoch 54/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.4720e-04 - val_loss: 2.0173e-04\n",
      "Epoch 55/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.4829e-04 - val_loss: 1.8578e-04\n",
      "Epoch 56/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.4890e-04 - val_loss: 2.1610e-04\n",
      "Epoch 57/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.6598e-04 - val_loss: 1.8337e-04\n",
      "Epoch 58/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.2727e-04 - val_loss: 1.8354e-04\n",
      "Epoch 59/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.1183e-04 - val_loss: 1.7242e-04\n",
      "Epoch 60/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 7.2524e-04 - val_loss: 1.8058e-04\n",
      "Epoch 61/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.8473e-04 - val_loss: 1.9216e-04\n",
      "Epoch 62/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.7219e-04 - val_loss: 1.6435e-04\n",
      "Epoch 63/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 6.7708e-04 - val_loss: 1.6655e-04\n",
      "Epoch 64/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 6.5938e-04 - val_loss: 1.7786e-04\n",
      "Epoch 65/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.6368e-04 - val_loss: 1.6868e-04\n",
      "Epoch 66/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.8619e-04 - val_loss: 1.6030e-04\n",
      "Epoch 67/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 6.6816e-04 - val_loss: 1.6876e-04\n",
      "Epoch 68/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 7.2851e-04 - val_loss: 1.7102e-04\n",
      "Epoch 69/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.6371e-04 - val_loss: 1.6095e-04\n",
      "Epoch 70/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.5195e-04 - val_loss: 1.5446e-04\n",
      "Epoch 71/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.3760e-04 - val_loss: 1.6790e-04\n",
      "Epoch 72/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.8471e-04 - val_loss: 1.6385e-04\n",
      "Epoch 73/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.8024e-04 - val_loss: 1.6815e-04\n",
      "Epoch 74/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.4032e-04 - val_loss: 1.5497e-04\n",
      "Epoch 75/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.3049e-04 - val_loss: 1.4758e-04\n",
      "Epoch 76/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.1385e-04 - val_loss: 1.4925e-04\n",
      "Epoch 77/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.1085e-04 - val_loss: 1.5624e-04\n",
      "Epoch 78/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 6.1381e-04 - val_loss: 1.5011e-04\n",
      "Epoch 79/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 6.4874e-04 - val_loss: 1.5366e-04\n",
      "Epoch 80/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.1101e-04 - val_loss: 1.4678e-04\n",
      "Epoch 81/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.2298e-04 - val_loss: 1.7025e-04\n",
      "Epoch 82/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.9993e-04 - val_loss: 1.4370e-04\n",
      "Epoch 83/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.1145e-04 - val_loss: 1.5613e-04\n",
      "Epoch 84/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.9913e-04 - val_loss: 1.4081e-04\n",
      "Epoch 85/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.7826e-04 - val_loss: 1.3875e-04\n",
      "Epoch 86/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 6.0398e-04 - val_loss: 1.3979e-04\n",
      "Epoch 87/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.7716e-04 - val_loss: 1.4370e-04\n",
      "Epoch 88/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.6636e-04 - val_loss: 1.3615e-04\n",
      "Epoch 89/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.7303e-04 - val_loss: 1.3754e-04\n",
      "Epoch 90/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.5702e-04 - val_loss: 1.5050e-04\n",
      "Epoch 91/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.5960e-04 - val_loss: 1.3407e-04\n",
      "Epoch 92/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.7515e-04 - val_loss: 1.5207e-04\n",
      "Epoch 93/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.6790e-04 - val_loss: 1.3209e-04\n",
      "Epoch 94/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.7200e-04 - val_loss: 1.7425e-04\n",
      "Epoch 95/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.8372e-04 - val_loss: 1.3115e-04\n",
      "Epoch 96/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.6300e-04 - val_loss: 1.3689e-04\n",
      "Epoch 97/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.3685e-04 - val_loss: 1.2850e-04\n",
      "Epoch 98/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.5221e-04 - val_loss: 1.3131e-04\n",
      "Epoch 99/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.4005e-04 - val_loss: 1.4119e-04\n",
      "Epoch 100/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.4425e-04 - val_loss: 1.6291e-04\n",
      "Epoch 101/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.4643e-04 - val_loss: 1.3296e-04\n",
      "Epoch 102/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.3906e-04 - val_loss: 1.2813e-04\n",
      "Epoch 103/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.2689e-04 - val_loss: 1.3077e-04\n",
      "Epoch 104/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.3643e-04 - val_loss: 1.3049e-04\n",
      "Epoch 105/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.3113e-04 - val_loss: 1.3454e-04\n",
      "Epoch 106/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.3587e-04 - val_loss: 1.2755e-04\n",
      "Epoch 107/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.1855e-04 - val_loss: 1.2409e-04\n",
      "Epoch 108/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.1870e-04 - val_loss: 1.4021e-04\n",
      "Epoch 109/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.5456e-04 - val_loss: 1.2783e-04\n",
      "Epoch 110/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.4468e-04 - val_loss: 1.3269e-04\n",
      "Epoch 111/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.3321e-04 - val_loss: 1.2140e-04\n",
      "Epoch 112/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 5.0925e-04 - val_loss: 1.2310e-04\n",
      "Epoch 113/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.0920e-04 - val_loss: 1.2086e-04\n",
      "Epoch 114/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.9562e-04 - val_loss: 1.1893e-04\n",
      "Epoch 115/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.2987e-04 - val_loss: 1.1800e-04\n",
      "Epoch 116/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.4736e-04 - val_loss: 1.2003e-04\n",
      "Epoch 117/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.1569e-04 - val_loss: 1.2022e-04\n",
      "Epoch 118/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.0924e-04 - val_loss: 1.1956e-04\n",
      "Epoch 119/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.9917e-04 - val_loss: 1.4232e-04\n",
      "Epoch 120/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.1861e-04 - val_loss: 1.2263e-04\n",
      "Epoch 121/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.7916e-04 - val_loss: 1.1515e-04\n",
      "Epoch 122/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.7607e-04 - val_loss: 1.1865e-04\n",
      "Epoch 123/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.7413e-04 - val_loss: 1.1708e-04\n",
      "Epoch 124/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.7846e-04 - val_loss: 1.1559e-04\n",
      "Epoch 125/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.8409e-04 - val_loss: 1.1501e-04\n",
      "Epoch 126/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.0173e-04 - val_loss: 1.1732e-04\n",
      "Epoch 127/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.8591e-04 - val_loss: 1.1591e-04\n",
      "Epoch 128/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.9845e-04 - val_loss: 1.1322e-04\n",
      "Epoch 129/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.8109e-04 - val_loss: 1.1470e-04\n",
      "Epoch 130/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.7611e-04 - val_loss: 1.1572e-04\n",
      "Epoch 131/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.9061e-04 - val_loss: 1.2517e-04\n",
      "Epoch 132/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.8027e-04 - val_loss: 1.1320e-04\n",
      "Epoch 133/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.8273e-04 - val_loss: 1.1469e-04\n",
      "Epoch 134/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.6542e-04 - val_loss: 1.1188e-04\n",
      "Epoch 135/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.6141e-04 - val_loss: 1.1164e-04\n",
      "Epoch 136/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.8770e-04 - val_loss: 1.2458e-04\n",
      "Epoch 137/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.6569e-04 - val_loss: 1.1012e-04\n",
      "Epoch 138/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.6306e-04 - val_loss: 1.1155e-04\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 4ms/step - loss: 4.7191e-04 - val_loss: 1.0950e-04\n",
      "Epoch 140/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.4923e-04 - val_loss: 1.0860e-04\n",
      "Epoch 141/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.8900e-04 - val_loss: 1.0938e-04\n",
      "Epoch 142/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.4900e-04 - val_loss: 1.1010e-04\n",
      "Epoch 143/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.6520e-04 - val_loss: 1.0660e-04\n",
      "Epoch 144/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.4796e-04 - val_loss: 1.0882e-04\n",
      "Epoch 145/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.4947e-04 - val_loss: 1.1191e-04\n",
      "Epoch 146/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.4863e-04 - val_loss: 1.0712e-04\n",
      "Epoch 147/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.5622e-04 - val_loss: 1.0893e-04\n",
      "Epoch 148/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.8803e-04 - val_loss: 1.0854e-04\n",
      "Epoch 149/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.5726e-04 - val_loss: 1.0600e-04\n",
      "Epoch 150/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.4251e-04 - val_loss: 1.0727e-04\n",
      "Epoch 151/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.3382e-04 - val_loss: 1.0763e-04\n",
      "Epoch 152/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.4302e-04 - val_loss: 1.0565e-04\n",
      "Epoch 153/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.3753e-04 - val_loss: 1.0723e-04\n",
      "Epoch 154/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.3677e-04 - val_loss: 1.0654e-04\n",
      "Epoch 155/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.4807e-04 - val_loss: 1.0494e-04\n",
      "Epoch 156/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.3072e-04 - val_loss: 1.0296e-04\n",
      "Epoch 157/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.5589e-04 - val_loss: 1.0483e-04\n",
      "Epoch 158/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.4771e-04 - val_loss: 1.0604e-04\n",
      "Epoch 159/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.5184e-04 - val_loss: 1.0515e-04\n",
      "Epoch 160/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.2621e-04 - val_loss: 1.0890e-04\n",
      "Epoch 161/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.3183e-04 - val_loss: 1.0716e-04\n",
      "Epoch 162/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.2424e-04 - val_loss: 1.0966e-04\n",
      "Epoch 163/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.2669e-04 - val_loss: 1.0490e-04\n",
      "Epoch 164/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.2480e-04 - val_loss: 1.0199e-04\n",
      "Epoch 165/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.2444e-04 - val_loss: 1.0670e-04\n",
      "Epoch 166/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.4719e-04 - val_loss: 1.1165e-04\n",
      "Epoch 167/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.5699e-04 - val_loss: 9.9039e-05\n",
      "Epoch 168/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.1981e-04 - val_loss: 9.9810e-05\n",
      "Epoch 169/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.2219e-04 - val_loss: 1.0836e-04\n",
      "Epoch 170/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.2949e-04 - val_loss: 1.0281e-04\n",
      "Epoch 171/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.2393e-04 - val_loss: 1.0038e-04\n",
      "Epoch 172/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.1382e-04 - val_loss: 9.9758e-05\n",
      "Epoch 173/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.1803e-04 - val_loss: 9.9887e-05\n",
      "Epoch 174/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.3332e-04 - val_loss: 1.0050e-04\n",
      "Epoch 175/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.2042e-04 - val_loss: 9.9154e-05\n",
      "Epoch 176/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.2637e-04 - val_loss: 9.8299e-05\n",
      "Epoch 177/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.1698e-04 - val_loss: 1.0971e-04\n",
      "Epoch 178/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.1548e-04 - val_loss: 1.0479e-04\n",
      "Epoch 179/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.1268e-04 - val_loss: 1.0620e-04\n",
      "Epoch 180/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.0872e-04 - val_loss: 9.9154e-05\n",
      "Epoch 181/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.2726e-04 - val_loss: 1.1610e-04\n",
      "Epoch 182/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.3774e-04 - val_loss: 9.8240e-05\n",
      "Epoch 183/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.0304e-04 - val_loss: 9.9404e-05\n",
      "Epoch 184/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.3744e-04 - val_loss: 9.8304e-05\n",
      "Epoch 185/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.1341e-04 - val_loss: 9.6064e-05\n",
      "Epoch 186/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.1253e-04 - val_loss: 1.0042e-04\n",
      "Epoch 187/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.0808e-04 - val_loss: 9.9880e-05\n",
      "Epoch 188/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.0408e-04 - val_loss: 1.0031e-04\n",
      "Epoch 189/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 3.9797e-04 - val_loss: 9.5659e-05\n",
      "Epoch 190/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.0361e-04 - val_loss: 1.0171e-04\n",
      "Epoch 191/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 3.9605e-04 - val_loss: 9.4850e-05\n",
      "Epoch 192/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.0025e-04 - val_loss: 9.5567e-05\n",
      "Epoch 193/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 3.9583e-04 - val_loss: 9.4455e-05\n",
      "Epoch 194/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.0694e-04 - val_loss: 9.4354e-05\n",
      "Epoch 195/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 4.1888e-04 - val_loss: 9.5870e-05\n",
      "Epoch 196/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 3.9844e-04 - val_loss: 9.2972e-05\n",
      "Epoch 197/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 4.2191e-04 - val_loss: 9.7903e-05\n",
      "Epoch 198/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 3.9652e-04 - val_loss: 9.7298e-05\n",
      "Epoch 199/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 3.9208e-04 - val_loss: 9.3960e-05\n",
      "Epoch 200/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 3.9846e-04 - val_loss: 9.2601e-05\n",
      "Thời gian huấn luyện:  45.75922346115112\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_25 (SimpleRNN)   (None, 10, 125)           15875     \n",
      "                                                                 \n",
      " flatten_101 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,126\n",
      "Trainable params: 17,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "50/50 [==============================] - 3s 22ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 2/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 3/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 4/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 5/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 6/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 8/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 9/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 10/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 11/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 12/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 13/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 14/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 15/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 16/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 17/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 18/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 19/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 20/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 21/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 22/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 23/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 24/200\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 25/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 26/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 27/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 28/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 29/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 30/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 31/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 32/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 33/200\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 34/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 35/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 36/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 37/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 38/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 39/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 40/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 41/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 42/200\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 43/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 44/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 45/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 46/200\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 47/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 48/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 49/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 50/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 51/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 52/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 53/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 54/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 55/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 56/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 57/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 58/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 59/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 60/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 61/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 62/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 63/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 64/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 65/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 66/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 67/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 68/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 69/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 70/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 71/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 72/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 73/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 74/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 75/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 76/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 77/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 78/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 79/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 80/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 81/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 82/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 83/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 84/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 85/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 86/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 87/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 88/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 89/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 90/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 91/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 92/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 93/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 94/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 95/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 96/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 97/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 98/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 99/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 100/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 101/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 102/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 103/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 104/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 105/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 106/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 107/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 108/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 109/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 110/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 111/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 112/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 113/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 114/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 115/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 116/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 117/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 118/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 119/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 120/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 121/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 122/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 123/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 124/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 125/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 126/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 127/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 128/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 129/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 130/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 131/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 132/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 133/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 134/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 135/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 136/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 137/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 138/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 139/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 140/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 141/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 142/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 143/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 144/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 145/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 146/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 147/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 148/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 149/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 150/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 151/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 152/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 153/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 154/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 155/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 156/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 157/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 158/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 159/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 160/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 161/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 162/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 163/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 164/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 165/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 166/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 167/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 169/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 170/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 171/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 172/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 173/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 174/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 175/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 176/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 177/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 178/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 179/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 180/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 181/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 182/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 183/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 184/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 185/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 186/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 187/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 188/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 189/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 190/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 191/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 192/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 193/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 194/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 195/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 196/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 197/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 198/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 199/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Epoch 200/200\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.2097 - val_loss: 0.0084\n",
      "Thời gian huấn luyện:  102.94272756576538\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_25 (LSTM)              (None, 10, 125)           63500     \n",
      "                                                                 \n",
      " flatten_102 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,751\n",
      "Trainable params: 64,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "50/50 [==============================] - 3s 20ms/step - loss: 0.0181 - val_loss: 0.0024\n",
      "Epoch 2/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 5.7467e-04\n",
      "Epoch 3/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 3.7227e-04\n",
      "Epoch 4/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 3.7557e-04\n",
      "Epoch 5/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 3.4701e-04\n",
      "Epoch 6/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 3.2981e-04\n",
      "Epoch 7/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 3.6211e-04\n",
      "Epoch 8/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 3.2369e-04\n",
      "Epoch 9/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 3.1058e-04\n",
      "Epoch 10/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 3.2791e-04\n",
      "Epoch 11/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 3.0301e-04\n",
      "Epoch 12/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 3.0075e-04\n",
      "Epoch 13/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 3.0304e-04\n",
      "Epoch 14/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.8266e-04\n",
      "Epoch 15/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.1528e-04\n",
      "Epoch 16/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.7986e-04\n",
      "Epoch 17/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.7950e-04\n",
      "Epoch 18/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 3.0143e-04\n",
      "Epoch 19/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.5955e-04\n",
      "Epoch 20/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.7086e-04\n",
      "Epoch 21/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.4842e-04\n",
      "Epoch 22/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.9487e-04 - val_loss: 2.4124e-04\n",
      "Epoch 23/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.8003e-04 - val_loss: 2.3878e-04\n",
      "Epoch 24/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 9.3963e-04 - val_loss: 2.3588e-04\n",
      "Epoch 25/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2097e-04 - val_loss: 2.4541e-04\n",
      "Epoch 26/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0740e-04 - val_loss: 2.3610e-04\n",
      "Epoch 27/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8129e-04 - val_loss: 2.3211e-04\n",
      "Epoch 28/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6231e-04 - val_loss: 2.3144e-04\n",
      "Epoch 29/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5117e-04 - val_loss: 2.3073e-04\n",
      "Epoch 30/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.3135e-04 - val_loss: 2.3820e-04\n",
      "Epoch 31/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6512e-04 - val_loss: 2.2984e-04\n",
      "Epoch 32/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5501e-04 - val_loss: 2.4442e-04\n",
      "Epoch 33/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.2650e-04 - val_loss: 2.2384e-04\n",
      "Epoch 34/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.1471e-04 - val_loss: 2.3493e-04\n",
      "Epoch 35/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 7.9655e-04 - val_loss: 2.2697e-04\n",
      "Epoch 36/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.9603e-04 - val_loss: 2.2428e-04\n",
      "Epoch 37/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.8856e-04 - val_loss: 2.3761e-04\n",
      "Epoch 38/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.7722e-04 - val_loss: 2.3912e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.8197e-04 - val_loss: 2.2327e-04\n",
      "Epoch 40/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.6589e-04 - val_loss: 2.5181e-04\n",
      "Epoch 41/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.9059e-04 - val_loss: 2.1696e-04\n",
      "Epoch 42/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 7.6665e-04 - val_loss: 2.1692e-04\n",
      "Epoch 43/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 7.4447e-04 - val_loss: 2.3355e-04\n",
      "Epoch 44/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 7.5523e-04 - val_loss: 2.1342e-04\n",
      "Epoch 45/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.5088e-04 - val_loss: 2.2433e-04\n",
      "Epoch 46/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 7.5780e-04 - val_loss: 2.1813e-04\n",
      "Epoch 47/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 7.2157e-04 - val_loss: 2.1521e-04\n",
      "Epoch 48/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 7.3286e-04 - val_loss: 2.1205e-04\n",
      "Epoch 49/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 7.2967e-04 - val_loss: 2.3166e-04\n",
      "Epoch 50/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 7.1554e-04 - val_loss: 2.2945e-04\n",
      "Epoch 51/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 7.0971e-04 - val_loss: 2.0200e-04\n",
      "Epoch 52/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.0155e-04 - val_loss: 2.0033e-04\n",
      "Epoch 53/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.0476e-04 - val_loss: 2.0503e-04\n",
      "Epoch 54/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.0336e-04 - val_loss: 1.9874e-04\n",
      "Epoch 55/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.8068e-04 - val_loss: 2.1308e-04\n",
      "Epoch 56/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.8678e-04 - val_loss: 1.9783e-04\n",
      "Epoch 57/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.7883e-04 - val_loss: 2.1584e-04\n",
      "Epoch 58/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.8421e-04 - val_loss: 2.0113e-04\n",
      "Epoch 59/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.7419e-04 - val_loss: 1.9313e-04\n",
      "Epoch 60/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.6513e-04 - val_loss: 1.9280e-04\n",
      "Epoch 61/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.5661e-04 - val_loss: 1.8732e-04\n",
      "Epoch 62/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.6440e-04 - val_loss: 1.8626e-04\n",
      "Epoch 63/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.5190e-04 - val_loss: 1.8677e-04\n",
      "Epoch 64/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.5937e-04 - val_loss: 1.8609e-04\n",
      "Epoch 65/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.6887e-04 - val_loss: 1.8281e-04\n",
      "Epoch 66/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.4901e-04 - val_loss: 2.1171e-04\n",
      "Epoch 67/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.4298e-04 - val_loss: 1.8248e-04\n",
      "Epoch 68/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.3523e-04 - val_loss: 2.0821e-04\n",
      "Epoch 69/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.4249e-04 - val_loss: 1.8674e-04\n",
      "Epoch 70/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.3709e-04 - val_loss: 1.8233e-04\n",
      "Epoch 71/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.1445e-04 - val_loss: 1.7874e-04\n",
      "Epoch 72/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.2107e-04 - val_loss: 1.7679e-04\n",
      "Epoch 73/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.1486e-04 - val_loss: 1.7650e-04\n",
      "Epoch 74/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.4362e-04 - val_loss: 1.7549e-04\n",
      "Epoch 75/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.0647e-04 - val_loss: 1.7543e-04\n",
      "Epoch 76/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.0308e-04 - val_loss: 1.7368e-04\n",
      "Epoch 77/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.0007e-04 - val_loss: 1.6902e-04\n",
      "Epoch 78/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 6.1001e-04 - val_loss: 1.6731e-04\n",
      "Epoch 79/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.0139e-04 - val_loss: 1.6669e-04\n",
      "Epoch 80/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.9879e-04 - val_loss: 1.6937e-04\n",
      "Epoch 81/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.0468e-04 - val_loss: 1.6274e-04\n",
      "Epoch 82/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.0600e-04 - val_loss: 1.8463e-04\n",
      "Epoch 83/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.9080e-04 - val_loss: 1.6051e-04\n",
      "Epoch 84/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.8466e-04 - val_loss: 1.6249e-04\n",
      "Epoch 85/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.7261e-04 - val_loss: 1.6559e-04\n",
      "Epoch 86/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.8382e-04 - val_loss: 2.0180e-04\n",
      "Epoch 87/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.8926e-04 - val_loss: 1.5962e-04\n",
      "Epoch 88/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 5.6985e-04 - val_loss: 1.6377e-04\n",
      "Epoch 89/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.6353e-04 - val_loss: 1.5632e-04\n",
      "Epoch 90/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 5.5370e-04 - val_loss: 1.6047e-04\n",
      "Epoch 91/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.6325e-04 - val_loss: 1.5550e-04\n",
      "Epoch 92/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.5910e-04 - val_loss: 1.5717e-04\n",
      "Epoch 93/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.6035e-04 - val_loss: 1.5274e-04\n",
      "Epoch 94/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.5426e-04 - val_loss: 1.6469e-04\n",
      "Epoch 95/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.5588e-04 - val_loss: 1.5127e-04\n",
      "Epoch 96/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 5.4418e-04 - val_loss: 1.5733e-04\n",
      "Epoch 97/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 5.4398e-04 - val_loss: 1.4923e-04\n",
      "Epoch 98/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 5.4945e-04 - val_loss: 1.6129e-04\n",
      "Epoch 99/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.6109e-04 - val_loss: 1.4972e-04\n",
      "Epoch 100/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 5.3535e-04 - val_loss: 1.4716e-04\n",
      "Epoch 101/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.2689e-04 - val_loss: 1.4763e-04\n",
      "Epoch 102/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 5.5646e-04 - val_loss: 1.4641e-04\n",
      "Epoch 103/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.2992e-04 - val_loss: 1.4577e-04\n",
      "Epoch 104/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 5.2175e-04 - val_loss: 1.4701e-04\n",
      "Epoch 105/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 5.3790e-04 - val_loss: 1.4401e-04\n",
      "Epoch 106/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.3272e-04 - val_loss: 1.4191e-04\n",
      "Epoch 107/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.2994e-04 - val_loss: 1.4343e-04\n",
      "Epoch 108/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.2590e-04 - val_loss: 1.4230e-04\n",
      "Epoch 109/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.0719e-04 - val_loss: 1.4173e-04\n",
      "Epoch 110/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.3033e-04 - val_loss: 1.3963e-04\n",
      "Epoch 111/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 5.0758e-04 - val_loss: 1.3991e-04\n",
      "Epoch 112/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.1173e-04 - val_loss: 1.4035e-04\n",
      "Epoch 113/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 5.1055e-04 - val_loss: 1.3846e-04\n",
      "Epoch 114/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.9891e-04 - val_loss: 1.3767e-04\n",
      "Epoch 115/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.0683e-04 - val_loss: 1.3620e-04\n",
      "Epoch 116/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.9282e-04 - val_loss: 1.3516e-04\n",
      "Epoch 117/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.9620e-04 - val_loss: 1.3517e-04\n",
      "Epoch 118/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.1127e-04 - val_loss: 1.3694e-04\n",
      "Epoch 119/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.9235e-04 - val_loss: 1.3276e-04\n",
      "Epoch 120/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 5.0736e-04 - val_loss: 1.3747e-04\n",
      "Epoch 121/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 5.0718e-04 - val_loss: 1.3814e-04\n",
      "Epoch 122/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.8862e-04 - val_loss: 1.4249e-04\n",
      "Epoch 123/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.9479e-04 - val_loss: 1.3724e-04\n",
      "Epoch 124/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 5.0728e-04 - val_loss: 1.3821e-04\n",
      "Epoch 125/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.9176e-04 - val_loss: 1.2972e-04\n",
      "Epoch 126/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.9912e-04 - val_loss: 1.3095e-04\n",
      "Epoch 127/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.8644e-04 - val_loss: 1.3098e-04\n",
      "Epoch 128/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.8600e-04 - val_loss: 1.3489e-04\n",
      "Epoch 129/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.9018e-04 - val_loss: 1.2809e-04\n",
      "Epoch 130/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.7927e-04 - val_loss: 1.3243e-04\n",
      "Epoch 131/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.7640e-04 - val_loss: 1.3369e-04\n",
      "Epoch 132/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.7531e-04 - val_loss: 1.2785e-04\n",
      "Epoch 133/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.6735e-04 - val_loss: 1.2683e-04\n",
      "Epoch 134/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.6934e-04 - val_loss: 1.2941e-04\n",
      "Epoch 135/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.8360e-04 - val_loss: 1.2547e-04\n",
      "Epoch 136/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.6695e-04 - val_loss: 1.2477e-04\n",
      "Epoch 137/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.6878e-04 - val_loss: 1.2853e-04\n",
      "Epoch 138/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.5988e-04 - val_loss: 1.2463e-04\n",
      "Epoch 139/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.5619e-04 - val_loss: 1.2510e-04\n",
      "Epoch 140/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.7420e-04 - val_loss: 1.2314e-04\n",
      "Epoch 141/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.6006e-04 - val_loss: 1.2307e-04\n",
      "Epoch 142/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.6244e-04 - val_loss: 1.2372e-04\n",
      "Epoch 143/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.5006e-04 - val_loss: 1.2599e-04\n",
      "Epoch 144/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.6581e-04 - val_loss: 1.2179e-04\n",
      "Epoch 145/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.5327e-04 - val_loss: 1.2376e-04\n",
      "Epoch 146/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.4163e-04 - val_loss: 1.2066e-04\n",
      "Epoch 147/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.4604e-04 - val_loss: 1.2022e-04\n",
      "Epoch 148/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.6588e-04 - val_loss: 1.2140e-04\n",
      "Epoch 149/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.4819e-04 - val_loss: 1.2021e-04\n",
      "Epoch 150/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.6503e-04 - val_loss: 1.2676e-04\n",
      "Epoch 151/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.4916e-04 - val_loss: 1.1919e-04\n",
      "Epoch 152/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.6935e-04 - val_loss: 1.1978e-04\n",
      "Epoch 153/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.4795e-04 - val_loss: 1.1979e-04\n",
      "Epoch 154/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.4113e-04 - val_loss: 1.1784e-04\n",
      "Epoch 155/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.4120e-04 - val_loss: 1.1921e-04\n",
      "Epoch 156/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.6832e-04 - val_loss: 1.1645e-04\n",
      "Epoch 157/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.3650e-04 - val_loss: 1.1748e-04\n",
      "Epoch 158/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.3528e-04 - val_loss: 1.1575e-04\n",
      "Epoch 159/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.3115e-04 - val_loss: 1.1540e-04\n",
      "Epoch 160/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.3520e-04 - val_loss: 1.1441e-04\n",
      "Epoch 161/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.3332e-04 - val_loss: 1.1486e-04\n",
      "Epoch 162/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.3296e-04 - val_loss: 1.2159e-04\n",
      "Epoch 163/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.3993e-04 - val_loss: 1.3164e-04\n",
      "Epoch 164/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.4644e-04 - val_loss: 1.1360e-04\n",
      "Epoch 165/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.3723e-04 - val_loss: 1.1327e-04\n",
      "Epoch 166/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.3598e-04 - val_loss: 1.1649e-04\n",
      "Epoch 167/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.2393e-04 - val_loss: 1.1966e-04\n",
      "Epoch 168/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.3865e-04 - val_loss: 1.2134e-04\n",
      "Epoch 169/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.3278e-04 - val_loss: 1.1195e-04\n",
      "Epoch 170/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.2294e-04 - val_loss: 1.4348e-04\n",
      "Epoch 171/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.3628e-04 - val_loss: 1.1097e-04\n",
      "Epoch 172/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.2958e-04 - val_loss: 1.1458e-04\n",
      "Epoch 173/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.2423e-04 - val_loss: 1.1107e-04\n",
      "Epoch 174/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.2941e-04 - val_loss: 1.0994e-04\n",
      "Epoch 175/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.2213e-04 - val_loss: 1.0955e-04\n",
      "Epoch 176/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.1086e-04 - val_loss: 1.1454e-04\n",
      "Epoch 177/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.0919e-04 - val_loss: 1.0902e-04\n",
      "Epoch 178/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.1100e-04 - val_loss: 1.1057e-04\n",
      "Epoch 179/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.2789e-04 - val_loss: 1.1020e-04\n",
      "Epoch 180/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.1855e-04 - val_loss: 1.0811e-04\n",
      "Epoch 181/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.1598e-04 - val_loss: 1.0966e-04\n",
      "Epoch 182/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.1864e-04 - val_loss: 1.1469e-04\n",
      "Epoch 183/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.2094e-04 - val_loss: 1.0749e-04\n",
      "Epoch 184/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.0280e-04 - val_loss: 1.1255e-04\n",
      "Epoch 185/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.1114e-04 - val_loss: 1.1185e-04\n",
      "Epoch 186/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.0676e-04 - val_loss: 1.1025e-04\n",
      "Epoch 187/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.1188e-04 - val_loss: 1.0561e-04\n",
      "Epoch 188/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.0143e-04 - val_loss: 1.0613e-04\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 9ms/step - loss: 4.0751e-04 - val_loss: 1.0578e-04\n",
      "Epoch 190/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.0326e-04 - val_loss: 1.0914e-04\n",
      "Epoch 191/200\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 3.9827e-04 - val_loss: 1.0593e-04\n",
      "Epoch 192/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.1141e-04 - val_loss: 1.0592e-04\n",
      "Epoch 193/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 3.9427e-04 - val_loss: 1.0690e-04\n",
      "Epoch 194/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.1031e-04 - val_loss: 1.0376e-04\n",
      "Epoch 195/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 3.9658e-04 - val_loss: 1.0415e-04\n",
      "Epoch 196/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 3.9881e-04 - val_loss: 1.1085e-04\n",
      "Epoch 197/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.0614e-04 - val_loss: 1.0319e-04\n",
      "Epoch 198/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 4.0146e-04 - val_loss: 1.1099e-04\n",
      "Epoch 199/200\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.1315e-04 - val_loss: 1.0319e-04\n",
      "Epoch 200/200\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 3.9300e-04 - val_loss: 1.0237e-04\n",
      "Thời gian huấn luyện:  89.45582795143127\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_25 (GRU)                (None, 10, 125)           48000     \n",
      "                                                                 \n",
      " flatten_103 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,251\n",
      "Trainable params: 49,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 1s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "47/47 [==============================] - 1s 5ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 2/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 8/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 21/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 29/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 48/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 56/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 57/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 138/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 0.0150\n",
      "Thời gian huấn luyện:  22.21964120864868\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 10, 125)           250       \n",
      "                                                                 \n",
      " flatten_104 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,501\n",
      "Trainable params: 1,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "47/47 [==============================] - 1s 9ms/step - loss: 0.0145 - val_loss: 8.7684e-04\n",
      "Epoch 2/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 8.0604e-04\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 7.2630e-04\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 6.3280e-04\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 5.8195e-04\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 5.1365e-04\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 4.9112e-04\n",
      "Epoch 8/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 4.7028e-04\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 4.3092e-04\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.3972e-04\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 4.0570e-04\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 9.9571e-04 - val_loss: 4.5651e-04\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 4.3377e-04\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 4.1672e-04\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 9.3431e-04 - val_loss: 3.7412e-04\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 9.3969e-04 - val_loss: 4.0052e-04\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.8010e-04 - val_loss: 3.7124e-04\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.8296e-04 - val_loss: 3.7402e-04\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 8.9824e-04 - val_loss: 3.5378e-04\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.6267e-04 - val_loss: 3.6433e-04\n",
      "Epoch 21/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 8.8909e-04 - val_loss: 3.4927e-04\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.0240e-04 - val_loss: 4.0935e-04\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 8.2568e-04 - val_loss: 3.5452e-04\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.7507e-04 - val_loss: 3.2784e-04\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 8.1399e-04 - val_loss: 3.2138e-04\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.6387e-04 - val_loss: 3.5369e-04\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.9610e-04 - val_loss: 3.3502e-04\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.3158e-04 - val_loss: 3.7819e-04\n",
      "Epoch 29/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.8090e-04 - val_loss: 3.6145e-04\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 8.3896e-04 - val_loss: 2.9460e-04\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.3533e-04 - val_loss: 3.1734e-04\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.2060e-04 - val_loss: 2.9689e-04\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.7622e-04 - val_loss: 2.9254e-04\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.1771e-04 - val_loss: 3.3502e-04\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.3699e-04 - val_loss: 2.8136e-04\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 7.1896e-04 - val_loss: 2.8095e-04\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 7.0513e-04 - val_loss: 2.9199e-04\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.7078e-04 - val_loss: 2.7633e-04\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.7175e-04 - val_loss: 2.7940e-04\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.5032e-04 - val_loss: 2.7060e-04\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.6418e-04 - val_loss: 2.8814e-04\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.3402e-04 - val_loss: 2.6818e-04\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.4592e-04 - val_loss: 2.5748e-04\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.4152e-04 - val_loss: 2.7967e-04\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.2353e-04 - val_loss: 2.4782e-04\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.4810e-04 - val_loss: 2.7545e-04\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.0399e-04 - val_loss: 2.6191e-04\n",
      "Epoch 48/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.5321e-04 - val_loss: 2.7437e-04\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.9589e-04 - val_loss: 2.9067e-04\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.0241e-04 - val_loss: 2.5129e-04\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.0076e-04 - val_loss: 2.4605e-04\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.0642e-04 - val_loss: 2.5167e-04\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.5399e-04 - val_loss: 2.4852e-04\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.3855e-04 - val_loss: 2.2631e-04\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.5059e-04 - val_loss: 2.3533e-04\n",
      "Epoch 56/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 6.1886e-04 - val_loss: 2.4926e-04\n",
      "Epoch 57/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.9524e-04 - val_loss: 2.3317e-04\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 6.0526e-04 - val_loss: 2.7561e-04\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.8113e-04 - val_loss: 2.2726e-04\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.6570e-04 - val_loss: 2.2109e-04\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.6883e-04 - val_loss: 2.2783e-04\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.5920e-04 - val_loss: 2.3923e-04\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.7414e-04 - val_loss: 2.4490e-04\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.5767e-04 - val_loss: 2.2802e-04\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.6770e-04 - val_loss: 2.3280e-04\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.3070e-04 - val_loss: 2.2230e-04\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.4666e-04 - val_loss: 2.0783e-04\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.4847e-04 - val_loss: 2.2327e-04\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.3304e-04 - val_loss: 2.4823e-04\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.3908e-04 - val_loss: 2.1588e-04\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.1489e-04 - val_loss: 2.0202e-04\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.3168e-04 - val_loss: 2.0030e-04\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.8281e-04 - val_loss: 1.9711e-04\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.1094e-04 - val_loss: 2.0165e-04\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.2129e-04 - val_loss: 2.1436e-04\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.3075e-04 - val_loss: 1.9966e-04\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.3538e-04 - val_loss: 1.9585e-04\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.0775e-04 - val_loss: 1.9097e-04\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.2196e-04 - val_loss: 2.0477e-04\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.2322e-04 - val_loss: 1.9498e-04\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.0275e-04 - val_loss: 1.9543e-04\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.1814e-04 - val_loss: 1.9637e-04\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.0038e-04 - val_loss: 1.9503e-04\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.9352e-04 - val_loss: 1.9746e-04\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.7630e-04 - val_loss: 1.8727e-04\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 4ms/step - loss: 5.1091e-04 - val_loss: 1.9561e-04\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 5.0882e-04 - val_loss: 1.8854e-04\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6959e-04 - val_loss: 1.9018e-04\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.9057e-04 - val_loss: 1.8097e-04\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8561e-04 - val_loss: 1.8085e-04\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8619e-04 - val_loss: 2.0159e-04\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 5.0607e-04 - val_loss: 1.7817e-04\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6258e-04 - val_loss: 1.9319e-04\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.9166e-04 - val_loss: 1.8156e-04\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8094e-04 - val_loss: 1.9284e-04\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5564e-04 - val_loss: 1.7815e-04\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.7437e-04 - val_loss: 1.7411e-04\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5135e-04 - val_loss: 1.8485e-04\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.6779e-04 - val_loss: 1.8083e-04\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8030e-04 - val_loss: 1.7805e-04\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.9211e-04 - val_loss: 1.7107e-04\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.4984e-04 - val_loss: 1.7018e-04\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.5019e-04 - val_loss: 1.7156e-04\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5874e-04 - val_loss: 1.7244e-04\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3611e-04 - val_loss: 1.6704e-04\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5359e-04 - val_loss: 1.7633e-04\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5385e-04 - val_loss: 1.6389e-04\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.6304e-04 - val_loss: 1.7806e-04\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5528e-04 - val_loss: 1.6452e-04\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5712e-04 - val_loss: 1.6274e-04\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8177e-04 - val_loss: 1.6158e-04\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3857e-04 - val_loss: 1.6080e-04\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.7563e-04 - val_loss: 1.6072e-04\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2756e-04 - val_loss: 1.6009e-04\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.4422e-04 - val_loss: 1.6644e-04\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.5065e-04 - val_loss: 1.6620e-04\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3445e-04 - val_loss: 1.5922e-04\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.7006e-04 - val_loss: 1.6137e-04\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3372e-04 - val_loss: 1.5599e-04\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3103e-04 - val_loss: 1.6926e-04\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1624e-04 - val_loss: 1.5819e-04\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2607e-04 - val_loss: 1.5428e-04\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2156e-04 - val_loss: 1.5600e-04\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.3530e-04 - val_loss: 1.6098e-04\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3198e-04 - val_loss: 1.5701e-04\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2431e-04 - val_loss: 1.6699e-04\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2177e-04 - val_loss: 1.6150e-04\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.4010e-04 - val_loss: 1.6944e-04\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2361e-04 - val_loss: 1.5328e-04\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1267e-04 - val_loss: 1.5133e-04\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2760e-04 - val_loss: 1.5462e-04\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0700e-04 - val_loss: 1.7467e-04\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3888e-04 - val_loss: 1.5034e-04\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0552e-04 - val_loss: 1.5015e-04\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.3806e-04 - val_loss: 1.5073e-04\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1062e-04 - val_loss: 1.5198e-04\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0548e-04 - val_loss: 1.5653e-04\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0109e-04 - val_loss: 1.6028e-04\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2615e-04 - val_loss: 1.6754e-04\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.2498e-04 - val_loss: 1.5821e-04\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1645e-04 - val_loss: 1.5180e-04\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0288e-04 - val_loss: 1.4845e-04\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2268e-04 - val_loss: 1.4663e-04\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1807e-04 - val_loss: 1.5379e-04\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3175e-04 - val_loss: 1.4664e-04\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1425e-04 - val_loss: 1.4989e-04\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9831e-04 - val_loss: 1.4674e-04\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3308e-04 - val_loss: 1.5144e-04\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2989e-04 - val_loss: 1.4476e-04\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2462e-04 - val_loss: 1.4474e-04\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 4.1765e-04 - val_loss: 1.4244e-04\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.8640e-04 - val_loss: 1.4598e-04\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0373e-04 - val_loss: 1.4746e-04\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2504e-04 - val_loss: 1.6676e-04\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2377e-04 - val_loss: 1.4303e-04\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.9260e-04 - val_loss: 1.6801e-04\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0946e-04 - val_loss: 1.5379e-04\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1938e-04 - val_loss: 1.3985e-04\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0183e-04 - val_loss: 1.5039e-04\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.2463e-04 - val_loss: 1.4056e-04\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.3869e-04 - val_loss: 1.4016e-04\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.8835e-04 - val_loss: 1.4411e-04\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9156e-04 - val_loss: 1.4204e-04\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9985e-04 - val_loss: 1.4178e-04\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.8776e-04 - val_loss: 1.4730e-04\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.8333e-04 - val_loss: 1.4126e-04\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9098e-04 - val_loss: 1.3768e-04\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0695e-04 - val_loss: 1.3859e-04\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0418e-04 - val_loss: 1.4531e-04\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.8902e-04 - val_loss: 1.4449e-04\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9735e-04 - val_loss: 1.5298e-04\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.8708e-04 - val_loss: 1.3691e-04\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9365e-04 - val_loss: 1.3883e-04\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0047e-04 - val_loss: 1.3788e-04\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9943e-04 - val_loss: 1.3820e-04\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1432e-04 - val_loss: 1.9587e-04\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9592e-04 - val_loss: 1.3782e-04\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1048e-04 - val_loss: 1.4015e-04\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9267e-04 - val_loss: 1.5091e-04\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.9193e-04 - val_loss: 1.5783e-04\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.1386e-04 - val_loss: 1.4439e-04\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9347e-04 - val_loss: 1.3853e-04\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.8586e-04 - val_loss: 1.4063e-04\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.8722e-04 - val_loss: 1.3605e-04\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.8932e-04 - val_loss: 1.3737e-04\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.8469e-04 - val_loss: 1.3737e-04\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.8666e-04 - val_loss: 1.4338e-04\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.8406e-04 - val_loss: 1.3582e-04\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.9232e-04 - val_loss: 1.4955e-04\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0175e-04 - val_loss: 1.4666e-04\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0182e-04 - val_loss: 1.5431e-04\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.8683e-04 - val_loss: 1.3858e-04\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9167e-04 - val_loss: 1.3848e-04\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0469e-04 - val_loss: 1.3465e-04\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9740e-04 - val_loss: 1.4269e-04\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 4.0813e-04 - val_loss: 1.3674e-04\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.8247e-04 - val_loss: 1.3444e-04\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9139e-04 - val_loss: 1.3842e-04\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 3.9322e-04 - val_loss: 1.3489e-04\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 3.9369e-04 - val_loss: 1.4122e-04\n",
      "Thời gian huấn luyện:  42.69977569580078\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_26 (SimpleRNN)   (None, 10, 125)           15875     \n",
      "                                                                 \n",
      " flatten_105 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,126\n",
      "Trainable params: 17,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "47/47 [==============================] - 2s 18ms/step - loss: 0.0258 - val_loss: 0.0028\n",
      "Epoch 2/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 9.5906e-04\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 8.7211e-04\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 7.5601e-04\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 7.9236e-04\n",
      "Epoch 8/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 7.8235e-04\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 7.7951e-04\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 7.1732e-04\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 8.1110e-04\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 8.1372e-04\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 8.1651e-04\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 7.3424e-04\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 7.3419e-04\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 8.5609e-04\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 7.0685e-04\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 8.0152e-04\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 7.1425e-04\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 7.9565e-04\n",
      "Epoch 21/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 8.4958e-04\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 6.8136e-04\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 7.3018e-04\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 7.2042e-04\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 7.0521e-04\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 7.5089e-04\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 7.1974e-04\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 6.7202e-04\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 6.2807e-04\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 6.7079e-04\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 7.6225e-04\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 6.9164e-04\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 6.0578e-04\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 7.1087e-04\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 6.4292e-04\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0013 - val_loss: 6.3345e-04\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0013 - val_loss: 5.9073e-04\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 6.5428e-04\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 5.7080e-04\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 6.9870e-04\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.8939e-04\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 6.3940e-04\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 6.0508e-04\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 5.7448e-04\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 5.2498e-04\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 5.2860e-04\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 5.3169e-04\n",
      "Epoch 48/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 5.4162e-04\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 5.5584e-04\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 5.0954e-04\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 5.4861e-04\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 4.9602e-04\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.9517e-04 - val_loss: 4.5295e-04\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.8535e-04 - val_loss: 4.8588e-04\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 4.4082e-04\n",
      "Epoch 56/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 5.3884e-04\n",
      "Epoch 57/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.7094e-04 - val_loss: 4.3352e-04\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 9.9308e-04 - val_loss: 4.0071e-04\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.9959e-04 - val_loss: 3.9208e-04\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.7386e-04 - val_loss: 4.0647e-04\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.6755e-04 - val_loss: 4.3929e-04\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.3532e-04 - val_loss: 4.3038e-04\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.2314e-04 - val_loss: 5.3231e-04\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.3740e-04 - val_loss: 4.3052e-04\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.1702e-04 - val_loss: 4.5808e-04\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.4776e-04 - val_loss: 3.9898e-04\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.0239e-04 - val_loss: 4.5579e-04\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.0453e-04 - val_loss: 3.8998e-04\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.0632e-04 - val_loss: 4.7633e-04\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.2014e-04 - val_loss: 4.1720e-04\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.0660e-04 - val_loss: 4.0826e-04\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.2812e-04 - val_loss: 4.2541e-04\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 9.0656e-04 - val_loss: 3.7448e-04\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.2157e-04 - val_loss: 4.3989e-04\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 8.9223e-04 - val_loss: 4.0166e-04\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.7880e-04 - val_loss: 4.1086e-04\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 8.8349e-04 - val_loss: 4.2388e-04\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.6292e-04 - val_loss: 4.0840e-04\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.5931e-04 - val_loss: 3.7486e-04\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.7924e-04 - val_loss: 4.2185e-04\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.6808e-04 - val_loss: 4.1630e-04\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.5933e-04 - val_loss: 4.4565e-04\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.1216e-04 - val_loss: 4.1313e-04\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 8.7951e-04 - val_loss: 4.1716e-04\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 9.1501e-04 - val_loss: 3.6750e-04\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.5902e-04 - val_loss: 4.1133e-04\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.3170e-04 - val_loss: 3.8680e-04\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 8.4150e-04 - val_loss: 3.9734e-04\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.6318e-04 - val_loss: 3.9061e-04\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.5023e-04 - val_loss: 4.3144e-04\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.3271e-04 - val_loss: 3.8691e-04\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.2428e-04 - val_loss: 4.1862e-04\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 8.5031e-04 - val_loss: 3.7194e-04\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.3976e-04 - val_loss: 4.0496e-04\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.1808e-04 - val_loss: 4.2402e-04\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.9769e-04 - val_loss: 3.8399e-04\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.1263e-04 - val_loss: 3.7994e-04\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.0468e-04 - val_loss: 3.9572e-04\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.8805e-04 - val_loss: 3.5466e-04\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.9911e-04 - val_loss: 4.7722e-04\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.5478e-04 - val_loss: 4.3657e-04\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.9649e-04 - val_loss: 3.4717e-04\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 8.3296e-04 - val_loss: 4.1791e-04\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.8110e-04 - val_loss: 4.2343e-04\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 1s 16ms/step - loss: 7.7064e-04 - val_loss: 3.5609e-04\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.8982e-04 - val_loss: 4.0786e-04\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.6688e-04 - val_loss: 3.6168e-04\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 7.6412e-04 - val_loss: 3.7822e-04\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 7.5690e-04 - val_loss: 3.5735e-04\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.9726e-04 - val_loss: 3.6867e-04\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.5295e-04 - val_loss: 4.0581e-04\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 7.5177e-04 - val_loss: 3.7856e-04\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.4887e-04 - val_loss: 4.0787e-04\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.4822e-04 - val_loss: 3.4134e-04\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.3674e-04 - val_loss: 3.8537e-04\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 7.3163e-04 - val_loss: 3.4739e-04\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.6569e-04 - val_loss: 3.3004e-04\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.6334e-04 - val_loss: 3.7381e-04\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 7.3022e-04 - val_loss: 3.4764e-04\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 7.2613e-04 - val_loss: 3.4327e-04\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.1102e-04 - val_loss: 4.0129e-04\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 7.0751e-04 - val_loss: 3.3745e-04\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 1s 15ms/step - loss: 7.1605e-04 - val_loss: 3.5895e-04\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.0881e-04 - val_loss: 3.2094e-04\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.1956e-04 - val_loss: 3.2974e-04\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 6.9651e-04 - val_loss: 3.4911e-04\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 7.1303e-04 - val_loss: 3.4394e-04\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.9545e-04 - val_loss: 3.7043e-04\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.9047e-04 - val_loss: 3.3337e-04\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 7.2924e-04 - val_loss: 3.6431e-04\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 7.3964e-04 - val_loss: 4.0960e-04\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.3428e-04 - val_loss: 3.7351e-04\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.8695e-04 - val_loss: 3.5370e-04\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.6772e-04 - val_loss: 3.5042e-04\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.6917e-04 - val_loss: 3.4850e-04\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.6277e-04 - val_loss: 3.2590e-04\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.7091e-04 - val_loss: 3.1561e-04\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.6292e-04 - val_loss: 3.4941e-04\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 6.6075e-04 - val_loss: 3.4199e-04\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.5001e-04 - val_loss: 3.8753e-04\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.4950e-04 - val_loss: 3.5224e-04\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.6346e-04 - val_loss: 3.1489e-04\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.4785e-04 - val_loss: 3.3123e-04\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 6.6161e-04 - val_loss: 3.1531e-04\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.4629e-04 - val_loss: 3.6261e-04\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.3174e-04 - val_loss: 3.0250e-04\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.5033e-04 - val_loss: 3.2876e-04\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 6.2576e-04 - val_loss: 3.3318e-04\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.2986e-04 - val_loss: 3.2400e-04\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.2095e-04 - val_loss: 3.2321e-04\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.1705e-04 - val_loss: 3.4627e-04\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 6.1598e-04 - val_loss: 3.3414e-04\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.1276e-04 - val_loss: 3.4448e-04\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.2947e-04 - val_loss: 3.3149e-04\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.6733e-04 - val_loss: 3.6819e-04\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.1761e-04 - val_loss: 2.9985e-04\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.4120e-04 - val_loss: 3.6784e-04\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.0730e-04 - val_loss: 3.1419e-04\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.9221e-04 - val_loss: 3.3767e-04\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 5.9485e-04 - val_loss: 3.4037e-04\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.0443e-04 - val_loss: 3.2825e-04\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.1153e-04 - val_loss: 3.6625e-04\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.9378e-04 - val_loss: 2.8818e-04\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.5297e-04 - val_loss: 3.2775e-04\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.9357e-04 - val_loss: 2.9769e-04\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.7471e-04 - val_loss: 3.2105e-04\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.9631e-04 - val_loss: 2.7620e-04\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 6.2314e-04 - val_loss: 2.7524e-04\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.8087e-04 - val_loss: 3.1640e-04\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 5.6409e-04 - val_loss: 3.0912e-04\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.7014e-04 - val_loss: 3.2327e-04\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.6815e-04 - val_loss: 2.8377e-04\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.0178e-04 - val_loss: 3.2170e-04\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.5913e-04 - val_loss: 3.0166e-04\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.5966e-04 - val_loss: 2.8314e-04\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.6152e-04 - val_loss: 3.2252e-04\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.5976e-04 - val_loss: 2.8827e-04\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.0726e-04 - val_loss: 3.2532e-04\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 11ms/step - loss: 5.5895e-04 - val_loss: 3.1992e-04\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.8151e-04 - val_loss: 3.2158e-04\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 5.6634e-04 - val_loss: 2.9086e-04\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.6359e-04 - val_loss: 3.1552e-04\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 6.0279e-04 - val_loss: 2.7970e-04\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.5154e-04 - val_loss: 3.2044e-04\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.4500e-04 - val_loss: 2.8071e-04\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.5823e-04 - val_loss: 2.8818e-04\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 5.5246e-04 - val_loss: 3.1502e-04\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.3457e-04 - val_loss: 3.0509e-04\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.3852e-04 - val_loss: 3.7388e-04\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.3747e-04 - val_loss: 2.7855e-04\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.3013e-04 - val_loss: 2.7875e-04\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.4162e-04 - val_loss: 2.8295e-04\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.2651e-04 - val_loss: 2.7636e-04\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.4976e-04 - val_loss: 3.1126e-04\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.2146e-04 - val_loss: 2.9939e-04\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.2234e-04 - val_loss: 2.9636e-04\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.2458e-04 - val_loss: 2.6167e-04\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 5.3358e-04 - val_loss: 2.7463e-04\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.2042e-04 - val_loss: 3.0561e-04\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 5.2411e-04 - val_loss: 3.0420e-04\n",
      "Thời gian huấn luyện:  103.2872359752655\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_26 (LSTM)              (None, 10, 125)           63500     \n",
      "                                                                 \n",
      " flatten_106 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,751\n",
      "Trainable params: 64,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "47/47 [==============================] - 4s 23ms/step - loss: 0.1330 - val_loss: 0.0079\n",
      "Epoch 2/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 9.3140e-04\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 7.4873e-04\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 7.4642e-04\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 6.0558e-04\n",
      "Epoch 8/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 6.6253e-04\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 6.2729e-04\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 5.9527e-04\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 6.5019e-04\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 6.2601e-04\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 5.9100e-04\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.9345e-04\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 5.5572e-04\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 6.3180e-04\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 5.6069e-04\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.8343e-04\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.1447e-04\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 5.1499e-04\n",
      "Epoch 21/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 5.6956e-04\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 5.1231e-04\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 4.8966e-04\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 5.1785e-04\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 4.9799e-04\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.5325e-04\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.5859e-04\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.3732e-04\n",
      "Epoch 29/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.5363e-04\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.5333e-04\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.6625e-04\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.8873e-04\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 4.2068e-04\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 3.8607e-04\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.7790e-04 - val_loss: 3.9722e-04\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 9.6031e-04 - val_loss: 4.0873e-04\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.5260e-04 - val_loss: 3.9530e-04\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 9.1135e-04 - val_loss: 3.8941e-04\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.8578e-04 - val_loss: 3.6114e-04\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.7429e-04 - val_loss: 3.6279e-04\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.5481e-04 - val_loss: 3.6403e-04\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.4010e-04 - val_loss: 3.6777e-04\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.2365e-04 - val_loss: 3.7066e-04\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.2648e-04 - val_loss: 3.5400e-04\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.0352e-04 - val_loss: 3.4781e-04\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 8.0714e-04 - val_loss: 3.4790e-04\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.9675e-04 - val_loss: 3.5562e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 8.0009e-04 - val_loss: 3.4912e-04\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.6566e-04 - val_loss: 3.4963e-04\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.5851e-04 - val_loss: 3.5373e-04\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.5340e-04 - val_loss: 3.4148e-04\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.7626e-04 - val_loss: 3.5371e-04\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.4844e-04 - val_loss: 3.4208e-04\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.3669e-04 - val_loss: 3.3992e-04\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.2873e-04 - val_loss: 3.4265e-04\n",
      "Epoch 56/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.3117e-04 - val_loss: 3.4018e-04\n",
      "Epoch 57/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.3300e-04 - val_loss: 3.3375e-04\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.2115e-04 - val_loss: 3.3286e-04\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.1885e-04 - val_loss: 3.4260e-04\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.2684e-04 - val_loss: 3.2749e-04\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 7.1592e-04 - val_loss: 3.2495e-04\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.0539e-04 - val_loss: 3.2152e-04\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 7.1907e-04 - val_loss: 3.1537e-04\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.8734e-04 - val_loss: 3.2647e-04\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.8943e-04 - val_loss: 3.1794e-04\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.9322e-04 - val_loss: 3.1291e-04\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.7761e-04 - val_loss: 3.1522e-04\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.8504e-04 - val_loss: 3.1028e-04\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.7877e-04 - val_loss: 3.1787e-04\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.7530e-04 - val_loss: 3.0801e-04\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.6812e-04 - val_loss: 3.0543e-04\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.7141e-04 - val_loss: 3.0620e-04\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.6309e-04 - val_loss: 3.0031e-04\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.4823e-04 - val_loss: 2.9766e-04\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.4008e-04 - val_loss: 2.9353e-04\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.3892e-04 - val_loss: 2.9829e-04\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.3769e-04 - val_loss: 2.9056e-04\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.3149e-04 - val_loss: 2.9058e-04\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.4601e-04 - val_loss: 2.9014e-04\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.5393e-04 - val_loss: 3.0175e-04\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.2747e-04 - val_loss: 2.7996e-04\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.1635e-04 - val_loss: 2.8598e-04\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.1152e-04 - val_loss: 2.8561e-04\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.1411e-04 - val_loss: 2.7884e-04\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.0819e-04 - val_loss: 2.8231e-04\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.0172e-04 - val_loss: 2.7327e-04\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.0968e-04 - val_loss: 2.7145e-04\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.9325e-04 - val_loss: 2.7235e-04\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.9242e-04 - val_loss: 2.7088e-04\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 6.0166e-04 - val_loss: 2.6750e-04\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.9157e-04 - val_loss: 2.7438e-04\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.8809e-04 - val_loss: 2.6828e-04\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.0368e-04 - val_loss: 2.5965e-04\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.8326e-04 - val_loss: 2.7145e-04\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.9201e-04 - val_loss: 2.6482e-04\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 6.0044e-04 - val_loss: 2.5988e-04\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.8522e-04 - val_loss: 2.9243e-04\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.9078e-04 - val_loss: 2.7700e-04\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.9126e-04 - val_loss: 2.5200e-04\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.5695e-04 - val_loss: 2.5119e-04\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.6009e-04 - val_loss: 2.7603e-04\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.5202e-04 - val_loss: 2.6605e-04\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.6934e-04 - val_loss: 2.5926e-04\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.4799e-04 - val_loss: 2.4348e-04\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.4876e-04 - val_loss: 2.5894e-04\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.4429e-04 - val_loss: 2.4432e-04\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.3916e-04 - val_loss: 2.4200e-04\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.3705e-04 - val_loss: 2.4442e-04\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.3443e-04 - val_loss: 2.3731e-04\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.4052e-04 - val_loss: 2.3620e-04\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.5025e-04 - val_loss: 2.3911e-04\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.3116e-04 - val_loss: 2.3204e-04\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.1838e-04 - val_loss: 2.3957e-04\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.2113e-04 - val_loss: 2.3160e-04\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.2575e-04 - val_loss: 2.3141e-04\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.2379e-04 - val_loss: 2.3209e-04\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.2621e-04 - val_loss: 2.3816e-04\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.4648e-04 - val_loss: 2.2665e-04\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.3090e-04 - val_loss: 2.2711e-04\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.2078e-04 - val_loss: 2.2704e-04\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.1348e-04 - val_loss: 2.2890e-04\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.9980e-04 - val_loss: 2.4220e-04\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.1503e-04 - val_loss: 2.1987e-04\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.9805e-04 - val_loss: 2.3032e-04\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.9910e-04 - val_loss: 2.1730e-04\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.0011e-04 - val_loss: 2.1754e-04\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 5.0059e-04 - val_loss: 2.1738e-04\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.9748e-04 - val_loss: 2.1704e-04\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.9239e-04 - val_loss: 2.2182e-04\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 5.0637e-04 - val_loss: 2.1561e-04\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.9312e-04 - val_loss: 2.2019e-04\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.8672e-04 - val_loss: 2.2049e-04\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.8121e-04 - val_loss: 2.1739e-04\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.8477e-04 - val_loss: 2.1878e-04\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.8046e-04 - val_loss: 2.1565e-04\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.8238e-04 - val_loss: 2.1199e-04\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.8294e-04 - val_loss: 2.2946e-04\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.7617e-04 - val_loss: 2.0837e-04\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.6709e-04 - val_loss: 2.1364e-04\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.7279e-04 - val_loss: 2.0304e-04\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.6383e-04 - val_loss: 2.0437e-04\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.7782e-04 - val_loss: 2.0246e-04\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.6748e-04 - val_loss: 2.0329e-04\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.6440e-04 - val_loss: 1.9984e-04\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.6272e-04 - val_loss: 2.1062e-04\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.6165e-04 - val_loss: 1.9906e-04\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.6070e-04 - val_loss: 1.9670e-04\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.6026e-04 - val_loss: 2.2268e-04\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.5952e-04 - val_loss: 1.9635e-04\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.5420e-04 - val_loss: 1.9369e-04\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.5810e-04 - val_loss: 1.9231e-04\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.6339e-04 - val_loss: 2.1509e-04\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.5735e-04 - val_loss: 1.9162e-04\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.4703e-04 - val_loss: 1.9837e-04\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.4288e-04 - val_loss: 2.1002e-04\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.4918e-04 - val_loss: 1.9170e-04\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.4877e-04 - val_loss: 1.8873e-04\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.4908e-04 - val_loss: 1.8770e-04\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.4246e-04 - val_loss: 1.8597e-04\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.3632e-04 - val_loss: 1.8470e-04\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.4482e-04 - val_loss: 1.9140e-04\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.7533e-04 - val_loss: 1.9968e-04\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.4562e-04 - val_loss: 1.8271e-04\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.3650e-04 - val_loss: 1.8246e-04\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.6032e-04 - val_loss: 1.8587e-04\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.4789e-04 - val_loss: 1.8901e-04\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.2658e-04 - val_loss: 2.1541e-04\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.3571e-04 - val_loss: 1.8046e-04\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.2690e-04 - val_loss: 1.8349e-04\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.2396e-04 - val_loss: 1.7911e-04\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.3375e-04 - val_loss: 1.8074e-04\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.3435e-04 - val_loss: 1.8541e-04\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.3471e-04 - val_loss: 1.7799e-04\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.2921e-04 - val_loss: 1.7374e-04\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.2600e-04 - val_loss: 2.0323e-04\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.3145e-04 - val_loss: 1.7451e-04\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.2258e-04 - val_loss: 1.7317e-04\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.3227e-04 - val_loss: 1.7909e-04\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.2073e-04 - val_loss: 1.8642e-04\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.3224e-04 - val_loss: 1.8316e-04\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.3235e-04 - val_loss: 1.7144e-04\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.3104e-04 - val_loss: 1.7273e-04\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.3899e-04 - val_loss: 2.0250e-04\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.4276e-04 - val_loss: 1.6836e-04\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.2456e-04 - val_loss: 1.6833e-04\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.3300e-04 - val_loss: 1.6828e-04\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.4305e-04 - val_loss: 1.6976e-04\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.1059e-04 - val_loss: 1.6828e-04\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.2295e-04 - val_loss: 1.6704e-04\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.1091e-04 - val_loss: 1.7102e-04\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.0693e-04 - val_loss: 1.7084e-04\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.0669e-04 - val_loss: 1.6360e-04\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.2190e-04 - val_loss: 1.6822e-04\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.1309e-04 - val_loss: 1.7942e-04\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.2463e-04 - val_loss: 1.6378e-04\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.1714e-04 - val_loss: 1.6759e-04\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.0527e-04 - val_loss: 1.6323e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.0502e-04 - val_loss: 1.7197e-04\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 4.0490e-04 - val_loss: 1.7517e-04\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 4.1352e-04 - val_loss: 1.6140e-04\n",
      "Thời gian huấn luyện:  94.21643686294556\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_26 (GRU)                (None, 10, 125)           48000     \n",
      "                                                                 \n",
      " flatten_107 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,251\n",
      "Trainable params: 49,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 1s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#dataset_ratio, epoch, batch_size, validation\n",
    "information_FFNN_df = []\n",
    "information_RNN_df = []\n",
    "information_LSTM_df = []\n",
    "information_GRU_df = []\n",
    "params = [[0.6, 0.7, 0.8], [50, 100, 200], [32], [0.1, 0.15, 0.2]]\n",
    "# params = [[0.8], [1, 2], [32], [0.15]]\n",
    "params = get_combinations(params)\n",
    "for p in params:\n",
    "    ratio = p[0]\n",
    "    train_size = int(len(ds) * ratio)\n",
    "    test_size = len(ds) - train_size\n",
    "    train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]\n",
    "    trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)\n",
    "    \n",
    "    epochs = p[1]\n",
    "    batch_size= p[2]\n",
    "    validation_split= p[3]\n",
    "    \n",
    "    \n",
    "    delta_ffnn, model_ffnn = create_ffnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    delta_rnn, model_rnn = create_rnn_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    delta_lstm, model_lstm = create_lstm_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    delta_gru, model_gru =create_gru_model(trainX, trainY, look_back, opt, epochs, batch_size, validation_split)\n",
    "    \n",
    "    models_bag = {\n",
    "        \"FFNN\": model_ffnn,\n",
    "        \"RNN\": model_rnn,\n",
    "        \"LSTM\": model_lstm,\n",
    "        \"GRU\": model_gru\n",
    "    }\n",
    "    \n",
    "    accuracy_bag = {}\n",
    "    \n",
    "    for model_name, trained_model in models_bag.items():\n",
    "        if model_name == 'FFNN':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_ffnn]\n",
    "            information_FFNN_df.append(info)\n",
    "        elif model_name == 'RNN':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_rnn]\n",
    "            information_RNN_df.append(info)\n",
    "        elif model_name == 'LSTM':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_lstm]\n",
    "            information_LSTM_df.append(info)\n",
    "        elif model_name == 'GRU':\n",
    "            mse, mae, mape, rmse, trainPredict, testPredict = create_accuracy(trained_model, scaler, trainX, trainY, testX, testY)\n",
    "            info = [model_name] + list(p) + [mse, mae] + [delta_gru]\n",
    "            information_GRU_df.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c830b6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training ratio</th>\n",
       "      <th>epcoch</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Validation</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Time Executing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>87.762</td>\n",
       "      <td>8.670</td>\n",
       "      <td>4.192961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.501</td>\n",
       "      <td>4.809002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.503</td>\n",
       "      <td>4.868796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.374</td>\n",
       "      <td>9.619330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.392</td>\n",
       "      <td>8.018003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.415</td>\n",
       "      <td>8.808713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>87.762</td>\n",
       "      <td>8.670</td>\n",
       "      <td>18.878388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>87.762</td>\n",
       "      <td>8.670</td>\n",
       "      <td>19.294446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>87.762</td>\n",
       "      <td>8.670</td>\n",
       "      <td>18.644840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.477</td>\n",
       "      <td>4.920663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.468</td>\n",
       "      <td>5.562841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.442</td>\n",
       "      <td>5.297574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>77.705</td>\n",
       "      <td>7.979</td>\n",
       "      <td>10.577302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.355</td>\n",
       "      <td>9.542097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>77.705</td>\n",
       "      <td>7.979</td>\n",
       "      <td>9.553059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.317</td>\n",
       "      <td>20.208054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>77.705</td>\n",
       "      <td>7.979</td>\n",
       "      <td>18.231304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.304</td>\n",
       "      <td>19.856682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.401</td>\n",
       "      <td>6.252704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>6.083088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>6.090253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>11.879942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>10.422551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.338</td>\n",
       "      <td>11.395113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.285</td>\n",
       "      <td>22.253567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>23.182521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>22.230667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Training ratio  epcoch  Batch_size  Validation     MSE    MAE  \\\n",
       "0   FFNN             0.6      50          32        0.10  87.762  8.670   \n",
       "1   FFNN             0.6      50          32        0.15   0.471  0.501   \n",
       "2   FFNN             0.6      50          32        0.20   0.475  0.503   \n",
       "3   FFNN             0.6     100          32        0.10   0.267  0.374   \n",
       "4   FFNN             0.6     100          32        0.15   0.292  0.392   \n",
       "5   FFNN             0.6     100          32        0.20   0.327  0.415   \n",
       "6   FFNN             0.6     200          32        0.10  87.762  8.670   \n",
       "7   FFNN             0.6     200          32        0.15  87.762  8.670   \n",
       "8   FFNN             0.6     200          32        0.20  87.762  8.670   \n",
       "9   FFNN             0.7      50          32        0.10   0.425  0.477   \n",
       "10  FFNN             0.7      50          32        0.15   0.411  0.468   \n",
       "11  FFNN             0.7      50          32        0.20   0.368  0.442   \n",
       "12  FFNN             0.7     100          32        0.10  77.705  7.979   \n",
       "13  FFNN             0.7     100          32        0.15   0.239  0.355   \n",
       "14  FFNN             0.7     100          32        0.20  77.705  7.979   \n",
       "15  FFNN             0.7     200          32        0.10   0.186  0.317   \n",
       "16  FFNN             0.7     200          32        0.15  77.705  7.979   \n",
       "17  FFNN             0.7     200          32        0.20   0.172  0.304   \n",
       "18  FFNN             0.8      50          32        0.10   0.312  0.401   \n",
       "19  FFNN             0.8      50          32        0.15  68.364  7.193   \n",
       "20  FFNN             0.8      50          32        0.20  68.364  7.193   \n",
       "21  FFNN             0.8     100          32        0.10  68.364  7.193   \n",
       "22  FFNN             0.8     100          32        0.15  68.364  7.193   \n",
       "23  FFNN             0.8     100          32        0.20   0.213  0.338   \n",
       "24  FFNN             0.8     200          32        0.10   0.155  0.285   \n",
       "25  FFNN             0.8     200          32        0.15  68.364  7.193   \n",
       "26  FFNN             0.8     200          32        0.20  68.364  7.193   \n",
       "\n",
       "    Time Executing  \n",
       "0         4.192961  \n",
       "1         4.809002  \n",
       "2         4.868796  \n",
       "3         9.619330  \n",
       "4         8.018003  \n",
       "5         8.808713  \n",
       "6        18.878388  \n",
       "7        19.294446  \n",
       "8        18.644840  \n",
       "9         4.920663  \n",
       "10        5.562841  \n",
       "11        5.297574  \n",
       "12       10.577302  \n",
       "13        9.542097  \n",
       "14        9.553059  \n",
       "15       20.208054  \n",
       "16       18.231304  \n",
       "17       19.856682  \n",
       "18        6.252704  \n",
       "19        6.083088  \n",
       "20        6.090253  \n",
       "21       11.879942  \n",
       "22       10.422551  \n",
       "23       11.395113  \n",
       "24       22.253567  \n",
       "25       23.182521  \n",
       "26       22.230667  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_FFNN_df = pd.DataFrame(information_FFNN_df)\n",
    "information_FFNN_df.columns = ['Model', 'Training ratio', 'epcoch', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Time Executing']\n",
    "information_FFNN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7adadef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training ratio</th>\n",
       "      <th>epcoch</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Validation</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Time Executing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.403</td>\n",
       "      <td>7.088230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.376</td>\n",
       "      <td>8.186879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.405</td>\n",
       "      <td>7.933184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.431</td>\n",
       "      <td>15.966108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.314</td>\n",
       "      <td>15.094843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.355</td>\n",
       "      <td>16.136653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.295</td>\n",
       "      <td>34.084484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.295</td>\n",
       "      <td>32.567603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.313</td>\n",
       "      <td>33.078066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.361</td>\n",
       "      <td>9.735254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.390</td>\n",
       "      <td>10.553859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.343</td>\n",
       "      <td>9.540067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.294</td>\n",
       "      <td>20.371657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.323</td>\n",
       "      <td>18.517444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.336</td>\n",
       "      <td>17.601528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.297</td>\n",
       "      <td>36.257563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.281</td>\n",
       "      <td>36.257745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.277</td>\n",
       "      <td>35.204292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.340</td>\n",
       "      <td>13.418200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.335</td>\n",
       "      <td>11.899765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.350</td>\n",
       "      <td>12.213168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.297</td>\n",
       "      <td>23.955798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.295</td>\n",
       "      <td>22.119392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.300</td>\n",
       "      <td>23.419957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.259</td>\n",
       "      <td>46.729383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.274</td>\n",
       "      <td>45.770260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.267</td>\n",
       "      <td>42.710835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Training ratio  epcoch  Batch_size  Validation    MSE    MAE  \\\n",
       "0    RNN             0.6      50          32        0.10  0.306  0.403   \n",
       "1    RNN             0.6      50          32        0.15  0.260  0.376   \n",
       "2    RNN             0.6      50          32        0.20  0.302  0.405   \n",
       "3    RNN             0.6     100          32        0.10  0.313  0.431   \n",
       "4    RNN             0.6     100          32        0.15  0.181  0.314   \n",
       "5    RNN             0.6     100          32        0.20  0.229  0.355   \n",
       "6    RNN             0.6     200          32        0.10  0.157  0.295   \n",
       "7    RNN             0.6     200          32        0.15  0.161  0.295   \n",
       "8    RNN             0.6     200          32        0.20  0.176  0.313   \n",
       "9    RNN             0.7      50          32        0.10  0.240  0.361   \n",
       "10   RNN             0.7      50          32        0.15  0.279  0.390   \n",
       "11   RNN             0.7      50          32        0.20  0.217  0.343   \n",
       "12   RNN             0.7     100          32        0.10  0.160  0.294   \n",
       "13   RNN             0.7     100          32        0.15  0.186  0.323   \n",
       "14   RNN             0.7     100          32        0.20  0.202  0.336   \n",
       "15   RNN             0.7     200          32        0.10  0.161  0.297   \n",
       "16   RNN             0.7     200          32        0.15  0.145  0.281   \n",
       "17   RNN             0.7     200          32        0.20  0.142  0.277   \n",
       "18   RNN             0.8      50          32        0.10  0.219  0.340   \n",
       "19   RNN             0.8      50          32        0.15  0.213  0.335   \n",
       "20   RNN             0.8      50          32        0.20  0.226  0.350   \n",
       "21   RNN             0.8     100          32        0.10  0.166  0.297   \n",
       "22   RNN             0.8     100          32        0.15  0.162  0.295   \n",
       "23   RNN             0.8     100          32        0.20  0.171  0.300   \n",
       "24   RNN             0.8     200          32        0.10  0.126  0.259   \n",
       "25   RNN             0.8     200          32        0.15  0.143  0.274   \n",
       "26   RNN             0.8     200          32        0.20  0.133  0.267   \n",
       "\n",
       "    Time Executing  \n",
       "0         7.088230  \n",
       "1         8.186879  \n",
       "2         7.933184  \n",
       "3        15.966108  \n",
       "4        15.094843  \n",
       "5        16.136653  \n",
       "6        34.084484  \n",
       "7        32.567603  \n",
       "8        33.078066  \n",
       "9         9.735254  \n",
       "10       10.553859  \n",
       "11        9.540067  \n",
       "12       20.371657  \n",
       "13       18.517444  \n",
       "14       17.601528  \n",
       "15       36.257563  \n",
       "16       36.257745  \n",
       "17       35.204292  \n",
       "18       13.418200  \n",
       "19       11.899765  \n",
       "20       12.213168  \n",
       "21       23.955798  \n",
       "22       22.119392  \n",
       "23       23.419957  \n",
       "24       46.729383  \n",
       "25       45.770260  \n",
       "26       42.710835  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_RNN_df = pd.DataFrame(information_RNN_df)\n",
    "information_RNN_df.columns = ['Model', 'Training ratio', 'epcoch', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Time Executing']\n",
    "information_RNN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52633989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training ratio</th>\n",
       "      <th>epcoch</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Validation</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Time Executing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.483</td>\n",
       "      <td>16.414404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.537</td>\n",
       "      <td>21.450934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.510</td>\n",
       "      <td>18.889996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.422</td>\n",
       "      <td>36.810789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.457</td>\n",
       "      <td>34.376699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.453</td>\n",
       "      <td>34.574759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>87.762</td>\n",
       "      <td>8.670</td>\n",
       "      <td>76.554250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.364</td>\n",
       "      <td>77.108086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>87.762</td>\n",
       "      <td>8.670</td>\n",
       "      <td>72.894176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.452</td>\n",
       "      <td>22.853036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>77.705</td>\n",
       "      <td>7.979</td>\n",
       "      <td>25.192710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.471</td>\n",
       "      <td>23.028481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>77.705</td>\n",
       "      <td>7.979</td>\n",
       "      <td>49.081808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>77.705</td>\n",
       "      <td>7.979</td>\n",
       "      <td>46.059479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.425</td>\n",
       "      <td>40.220409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.340</td>\n",
       "      <td>92.976053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.347</td>\n",
       "      <td>84.910344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.359</td>\n",
       "      <td>76.918080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>29.563162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>27.548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.435</td>\n",
       "      <td>27.679547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.368</td>\n",
       "      <td>52.277868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>54.995370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.386</td>\n",
       "      <td>53.893937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.298</td>\n",
       "      <td>108.327705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>102.956358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.319</td>\n",
       "      <td>103.298280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Training ratio  epcoch  Batch_size  Validation     MSE    MAE  \\\n",
       "0   LSTM             0.6      50          32        0.10   0.431  0.483   \n",
       "1   LSTM             0.6      50          32        0.15   0.532  0.537   \n",
       "2   LSTM             0.6      50          32        0.20   0.487  0.510   \n",
       "3   LSTM             0.6     100          32        0.10   0.328  0.422   \n",
       "4   LSTM             0.6     100          32        0.15   0.381  0.457   \n",
       "5   LSTM             0.6     100          32        0.20   0.370  0.453   \n",
       "6   LSTM             0.6     200          32        0.10  87.762  8.670   \n",
       "7   LSTM             0.6     200          32        0.15   0.241  0.364   \n",
       "8   LSTM             0.6     200          32        0.20  87.762  8.670   \n",
       "9   LSTM             0.7      50          32        0.10   0.379  0.452   \n",
       "10  LSTM             0.7      50          32        0.15  77.705  7.979   \n",
       "11  LSTM             0.7      50          32        0.20   0.409  0.471   \n",
       "12  LSTM             0.7     100          32        0.10  77.705  7.979   \n",
       "13  LSTM             0.7     100          32        0.15  77.705  7.979   \n",
       "14  LSTM             0.7     100          32        0.20   0.330  0.425   \n",
       "15  LSTM             0.7     200          32        0.10   0.210  0.340   \n",
       "16  LSTM             0.7     200          32        0.15   0.218  0.347   \n",
       "17  LSTM             0.7     200          32        0.20   0.227  0.359   \n",
       "18  LSTM             0.8      50          32        0.10  68.364  7.193   \n",
       "19  LSTM             0.8      50          32        0.15  68.364  7.193   \n",
       "20  LSTM             0.8      50          32        0.20   0.353  0.435   \n",
       "21  LSTM             0.8     100          32        0.10   0.255  0.368   \n",
       "22  LSTM             0.8     100          32        0.15  68.364  7.193   \n",
       "23  LSTM             0.8     100          32        0.20   0.278  0.386   \n",
       "24  LSTM             0.8     200          32        0.10   0.164  0.298   \n",
       "25  LSTM             0.8     200          32        0.15  68.364  7.193   \n",
       "26  LSTM             0.8     200          32        0.20   0.183  0.319   \n",
       "\n",
       "    Time Executing  \n",
       "0        16.414404  \n",
       "1        21.450934  \n",
       "2        18.889996  \n",
       "3        36.810789  \n",
       "4        34.376699  \n",
       "5        34.574759  \n",
       "6        76.554250  \n",
       "7        77.108086  \n",
       "8        72.894176  \n",
       "9        22.853036  \n",
       "10       25.192710  \n",
       "11       23.028481  \n",
       "12       49.081808  \n",
       "13       46.059479  \n",
       "14       40.220409  \n",
       "15       92.976053  \n",
       "16       84.910344  \n",
       "17       76.918080  \n",
       "18       29.563162  \n",
       "19       27.548000  \n",
       "20       27.679547  \n",
       "21       52.277868  \n",
       "22       54.995370  \n",
       "23       53.893937  \n",
       "24      108.327705  \n",
       "25      102.956358  \n",
       "26      103.298280  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_LSTM_df = pd.DataFrame(information_LSTM_df)\n",
    "information_LSTM_df.columns = ['Model', 'Training ratio', 'epcoch', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Time Executing']\n",
    "information_LSTM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "768ef36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training ratio</th>\n",
       "      <th>epcoch</th>\n",
       "      <th>Batch_size</th>\n",
       "      <th>Validation</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Time Executing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.405</td>\n",
       "      <td>16.043660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.419</td>\n",
       "      <td>20.513111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.417</td>\n",
       "      <td>19.019539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.367</td>\n",
       "      <td>36.066112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.354</td>\n",
       "      <td>35.805887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.364</td>\n",
       "      <td>29.442881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.301</td>\n",
       "      <td>77.559877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.316</td>\n",
       "      <td>76.045173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>87.762</td>\n",
       "      <td>8.670</td>\n",
       "      <td>70.128849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.396</td>\n",
       "      <td>20.552711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.387</td>\n",
       "      <td>23.977171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>77.705</td>\n",
       "      <td>7.979</td>\n",
       "      <td>20.222956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.352</td>\n",
       "      <td>44.923515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.350</td>\n",
       "      <td>43.620208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>77.705</td>\n",
       "      <td>7.979</td>\n",
       "      <td>36.165551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.296</td>\n",
       "      <td>85.434810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>77.705</td>\n",
       "      <td>7.979</td>\n",
       "      <td>81.799756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.298</td>\n",
       "      <td>69.946570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>26.911085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>23.698453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>26.120980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.311</td>\n",
       "      <td>45.649223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.309</td>\n",
       "      <td>48.916633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.319</td>\n",
       "      <td>48.240120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.264</td>\n",
       "      <td>96.365623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.263</td>\n",
       "      <td>89.468909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.269</td>\n",
       "      <td>94.227474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Training ratio  epcoch  Batch_size  Validation     MSE    MAE  \\\n",
       "0    GRU             0.6      50          32        0.10   0.305  0.405   \n",
       "1    GRU             0.6      50          32        0.15   0.327  0.419   \n",
       "2    GRU             0.6      50          32        0.20   0.323  0.417   \n",
       "3    GRU             0.6     100          32        0.10   0.244  0.367   \n",
       "4    GRU             0.6     100          32        0.15   0.227  0.354   \n",
       "5    GRU             0.6     100          32        0.20   0.241  0.364   \n",
       "6    GRU             0.6     200          32        0.10   0.167  0.301   \n",
       "7    GRU             0.6     200          32        0.15   0.178  0.316   \n",
       "8    GRU             0.6     200          32        0.20  87.762  8.670   \n",
       "9    GRU             0.7      50          32        0.10   0.286  0.396   \n",
       "10   GRU             0.7      50          32        0.15   0.276  0.387   \n",
       "11   GRU             0.7      50          32        0.20  77.705  7.979   \n",
       "12   GRU             0.7     100          32        0.10   0.224  0.352   \n",
       "13   GRU             0.7     100          32        0.15   0.223  0.350   \n",
       "14   GRU             0.7     100          32        0.20  77.705  7.979   \n",
       "15   GRU             0.7     200          32        0.10   0.162  0.296   \n",
       "16   GRU             0.7     200          32        0.15  77.705  7.979   \n",
       "17   GRU             0.7     200          32        0.20   0.159  0.298   \n",
       "18   GRU             0.8      50          32        0.10  68.364  7.193   \n",
       "19   GRU             0.8      50          32        0.15  68.364  7.193   \n",
       "20   GRU             0.8      50          32        0.20  68.364  7.193   \n",
       "21   GRU             0.8     100          32        0.10   0.180  0.311   \n",
       "22   GRU             0.8     100          32        0.15   0.178  0.309   \n",
       "23   GRU             0.8     100          32        0.20   0.189  0.319   \n",
       "24   GRU             0.8     200          32        0.10   0.132  0.264   \n",
       "25   GRU             0.8     200          32        0.15   0.132  0.263   \n",
       "26   GRU             0.8     200          32        0.20   0.138  0.269   \n",
       "\n",
       "    Time Executing  \n",
       "0        16.043660  \n",
       "1        20.513111  \n",
       "2        19.019539  \n",
       "3        36.066112  \n",
       "4        35.805887  \n",
       "5        29.442881  \n",
       "6        77.559877  \n",
       "7        76.045173  \n",
       "8        70.128849  \n",
       "9        20.552711  \n",
       "10       23.977171  \n",
       "11       20.222956  \n",
       "12       44.923515  \n",
       "13       43.620208  \n",
       "14       36.165551  \n",
       "15       85.434810  \n",
       "16       81.799756  \n",
       "17       69.946570  \n",
       "18       26.911085  \n",
       "19       23.698453  \n",
       "20       26.120980  \n",
       "21       45.649223  \n",
       "22       48.916633  \n",
       "23       48.240120  \n",
       "24       96.365623  \n",
       "25       89.468909  \n",
       "26       94.227474  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_GRU_df = pd.DataFrame(information_GRU_df)\n",
    "information_GRU_df.columns = ['Model', 'Training ratio', 'epcoch', 'Batch_size', 'Validation', 'MSE', 'MAE', 'Time Executing']\n",
    "information_GRU_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f959e",
   "metadata": {},
   "source": [
    "## Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c148fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_best_params(info_df, ds, look_back, opt):\n",
    "    index = info_df.MSE.argmin()\n",
    "    ratio = info_df.iloc[index, 1]\n",
    "    epochs = info_df.iloc[index, 2]\n",
    "    batch_size = info_df.iloc[index, 3]\n",
    "    validation = info_df.iloc[index, 4]\n",
    "    \n",
    "    train_size = int(len(ds) * ratio)\n",
    "    test_size = len(ds) - train_size\n",
    "    train, test = ds[0:train_size,:], ds[train_size:len(ds)+1,:]\n",
    "    trainX, trainY, testX, testY = create_train_test_data(train, test, look_back)\n",
    "    \n",
    "    return [trainX, trainY, testX, testY], [trainX, trainY, look_back, opt, epochs, batch_size, validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52707d6e",
   "metadata": {},
   "source": [
    "### Chose the best look_back in (1,3,5,10,20,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96cfdfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "54/54 [==============================] - 1s 5ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 2/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 3/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 4/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 5/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 6/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 7/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 8/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 9/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 10/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 11/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 12/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 13/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 14/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 15/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 16/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 17/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 18/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 19/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 20/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 21/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 22/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 23/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 24/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 25/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 26/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 27/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 28/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 29/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 30/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 31/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 32/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 33/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 34/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 35/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 36/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 37/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 38/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 39/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 40/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 41/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 42/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 43/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 44/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 45/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 46/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 47/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 48/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 49/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 50/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 51/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 52/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 53/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 54/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 55/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 56/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 57/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 58/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 59/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 60/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 61/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 62/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 63/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 64/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 65/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 66/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 67/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 68/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 69/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 70/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 71/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 72/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 73/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 74/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 75/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 76/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 77/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 78/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 79/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 80/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 81/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 82/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 84/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 85/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 86/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 87/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 88/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 89/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 90/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 91/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 92/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 93/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 94/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 95/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 96/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 97/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 98/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 99/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 100/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 101/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 102/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 103/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 104/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 105/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 106/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 107/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 108/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 109/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 110/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 111/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 112/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 113/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 114/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 115/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 116/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 117/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 118/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 119/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 120/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 121/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 122/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 123/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 124/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 125/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 126/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 127/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 128/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 129/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 130/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 131/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 132/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 133/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 134/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 135/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 136/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 137/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 138/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 139/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 140/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 141/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 142/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 143/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 144/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 145/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 146/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 147/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 148/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 149/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 150/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 151/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 152/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 153/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 154/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 155/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 156/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 157/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 158/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 159/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 160/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 161/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 162/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 163/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 164/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 165/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 166/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 167/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 168/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 169/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 170/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 171/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 172/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 173/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 174/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 175/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 176/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 177/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 178/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 179/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 180/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 181/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 182/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 183/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 184/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 185/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 186/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 187/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 188/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 189/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 190/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 191/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 192/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 193/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 194/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 195/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 196/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 197/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 198/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 199/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 200/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Thời gian huấn luyện:  21.275781393051147\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_135 (Dense)           (None, 1, 125)            250       \n",
      "                                                                 \n",
      " flatten_108 (Flatten)       (None, 125)               0         \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 1)                 126       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376\n",
      "Trainable params: 376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 901us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "54/54 [==============================] - 1s 7ms/step - loss: 0.0524 - val_loss: 0.0404\n",
      "Epoch 2/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0231\n",
      "Epoch 3/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0163\n",
      "Epoch 4/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0112\n",
      "Epoch 5/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0078\n",
      "Epoch 6/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 7/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 8/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 9/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 9.5155e-04 - val_loss: 0.0015\n",
      "Epoch 10/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 7.2982e-04 - val_loss: 9.3883e-04\n",
      "Epoch 11/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 5.8905e-04 - val_loss: 5.8625e-04\n",
      "Epoch 12/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 5.0059e-04 - val_loss: 3.8538e-04\n",
      "Epoch 13/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 4.4433e-04 - val_loss: 2.6765e-04\n",
      "Epoch 14/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 4.1098e-04 - val_loss: 1.8394e-04\n",
      "Epoch 15/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.9021e-04 - val_loss: 1.4180e-04\n",
      "Epoch 16/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7880e-04 - val_loss: 1.3061e-04\n",
      "Epoch 17/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7536e-04 - val_loss: 9.3552e-05\n",
      "Epoch 18/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6648e-04 - val_loss: 9.3537e-05\n",
      "Epoch 19/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6541e-04 - val_loss: 8.2890e-05\n",
      "Epoch 20/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6285e-04 - val_loss: 7.9978e-05\n",
      "Epoch 21/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6777e-04 - val_loss: 7.4884e-05\n",
      "Epoch 22/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6294e-04 - val_loss: 7.6426e-05\n",
      "Epoch 23/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6167e-04 - val_loss: 7.4532e-05\n",
      "Epoch 24/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6168e-04 - val_loss: 7.5971e-05\n",
      "Epoch 25/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6182e-04 - val_loss: 7.4523e-05\n",
      "Epoch 26/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6103e-04 - val_loss: 7.5459e-05\n",
      "Epoch 27/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6251e-04 - val_loss: 7.4604e-05\n",
      "Epoch 28/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6201e-04 - val_loss: 7.5595e-05\n",
      "Epoch 29/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6238e-04 - val_loss: 7.5467e-05\n",
      "Epoch 30/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6373e-04 - val_loss: 7.4668e-05\n",
      "Epoch 31/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6363e-04 - val_loss: 7.4620e-05\n",
      "Epoch 32/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6264e-04 - val_loss: 7.6050e-05\n",
      "Epoch 33/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6275e-04 - val_loss: 7.4857e-05\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6286e-04 - val_loss: 7.4726e-05\n",
      "Epoch 35/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6189e-04 - val_loss: 7.4643e-05\n",
      "Epoch 36/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6319e-04 - val_loss: 7.5361e-05\n",
      "Epoch 37/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6264e-04 - val_loss: 7.6075e-05\n",
      "Epoch 38/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6163e-04 - val_loss: 7.5853e-05\n",
      "Epoch 39/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6597e-04 - val_loss: 7.5150e-05\n",
      "Epoch 40/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6269e-04 - val_loss: 7.4962e-05\n",
      "Epoch 41/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6282e-04 - val_loss: 7.4796e-05\n",
      "Epoch 42/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6457e-04 - val_loss: 7.4575e-05\n",
      "Epoch 43/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6184e-04 - val_loss: 7.6104e-05\n",
      "Epoch 44/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6248e-04 - val_loss: 7.4648e-05\n",
      "Epoch 45/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6179e-04 - val_loss: 7.5122e-05\n",
      "Epoch 46/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6322e-04 - val_loss: 7.4670e-05\n",
      "Epoch 47/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6176e-04 - val_loss: 7.6036e-05\n",
      "Epoch 48/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6406e-04 - val_loss: 7.5715e-05\n",
      "Epoch 49/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6349e-04 - val_loss: 7.4647e-05\n",
      "Epoch 50/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6236e-04 - val_loss: 7.4568e-05\n",
      "Epoch 51/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6232e-04 - val_loss: 7.4688e-05\n",
      "Epoch 52/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6251e-04 - val_loss: 7.4786e-05\n",
      "Epoch 53/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6225e-04 - val_loss: 7.4712e-05\n",
      "Epoch 54/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6226e-04 - val_loss: 7.4837e-05\n",
      "Epoch 55/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6214e-04 - val_loss: 7.4907e-05\n",
      "Epoch 56/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6331e-04 - val_loss: 7.5766e-05\n",
      "Epoch 57/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6696e-04 - val_loss: 7.5501e-05\n",
      "Epoch 58/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6225e-04 - val_loss: 7.7793e-05\n",
      "Epoch 59/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6576e-04 - val_loss: 7.6131e-05\n",
      "Epoch 60/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6674e-04 - val_loss: 7.4491e-05\n",
      "Epoch 61/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6265e-04 - val_loss: 7.6392e-05\n",
      "Epoch 62/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7062e-04 - val_loss: 7.5079e-05\n",
      "Epoch 63/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6323e-04 - val_loss: 7.5323e-05\n",
      "Epoch 64/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6400e-04 - val_loss: 8.1429e-05\n",
      "Epoch 65/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6574e-04 - val_loss: 7.4712e-05\n",
      "Epoch 66/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6240e-04 - val_loss: 7.4602e-05\n",
      "Epoch 67/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6289e-04 - val_loss: 7.6161e-05\n",
      "Epoch 68/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6174e-04 - val_loss: 7.5003e-05\n",
      "Epoch 69/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6765e-04 - val_loss: 7.4855e-05\n",
      "Epoch 70/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6328e-04 - val_loss: 7.4592e-05\n",
      "Epoch 71/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6965e-04 - val_loss: 7.4391e-05\n",
      "Epoch 72/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6187e-04 - val_loss: 7.4679e-05\n",
      "Epoch 73/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6365e-04 - val_loss: 7.5196e-05\n",
      "Epoch 74/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7105e-04 - val_loss: 7.5341e-05\n",
      "Epoch 75/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7456e-04 - val_loss: 8.3210e-05\n",
      "Epoch 76/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6171e-04 - val_loss: 8.1452e-05\n",
      "Epoch 77/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6309e-04 - val_loss: 7.6815e-05\n",
      "Epoch 78/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6443e-04 - val_loss: 7.4669e-05\n",
      "Epoch 79/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6782e-04 - val_loss: 7.4906e-05\n",
      "Epoch 80/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6384e-04 - val_loss: 7.4991e-05\n",
      "Epoch 81/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6452e-04 - val_loss: 7.4657e-05\n",
      "Epoch 82/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6853e-04 - val_loss: 7.4827e-05\n",
      "Epoch 83/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6958e-04 - val_loss: 8.2134e-05\n",
      "Epoch 84/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6517e-04 - val_loss: 7.6531e-05\n",
      "Epoch 85/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6849e-04 - val_loss: 7.4715e-05\n",
      "Epoch 86/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6536e-04 - val_loss: 7.4720e-05\n",
      "Epoch 87/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6219e-04 - val_loss: 7.4871e-05\n",
      "Epoch 88/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6843e-04 - val_loss: 7.4828e-05\n",
      "Epoch 89/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7526e-04 - val_loss: 7.6011e-05\n",
      "Epoch 90/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6289e-04 - val_loss: 7.6989e-05\n",
      "Epoch 91/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6826e-04 - val_loss: 8.2927e-05\n",
      "Epoch 92/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6310e-04 - val_loss: 7.5466e-05\n",
      "Epoch 93/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6634e-04 - val_loss: 7.5713e-05\n",
      "Epoch 94/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6242e-04 - val_loss: 7.5348e-05\n",
      "Epoch 95/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6369e-04 - val_loss: 7.6730e-05\n",
      "Epoch 96/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6646e-04 - val_loss: 7.5239e-05\n",
      "Epoch 97/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6318e-04 - val_loss: 7.5282e-05\n",
      "Epoch 98/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6565e-04 - val_loss: 7.5788e-05\n",
      "Epoch 99/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6313e-04 - val_loss: 7.4546e-05\n",
      "Epoch 100/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6527e-04 - val_loss: 7.4816e-05\n",
      "Epoch 101/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6349e-04 - val_loss: 7.5684e-05\n",
      "Epoch 102/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6262e-04 - val_loss: 7.4759e-05\n",
      "Epoch 103/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6450e-04 - val_loss: 7.8767e-05\n",
      "Epoch 104/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6540e-04 - val_loss: 7.5265e-05\n",
      "Epoch 105/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7527e-04 - val_loss: 9.0026e-05\n",
      "Epoch 106/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6586e-04 - val_loss: 7.5885e-05\n",
      "Epoch 107/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6446e-04 - val_loss: 7.5071e-05\n",
      "Epoch 108/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6717e-04 - val_loss: 7.4667e-05\n",
      "Epoch 109/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7035e-04 - val_loss: 8.2965e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6231e-04 - val_loss: 7.4824e-05\n",
      "Epoch 111/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6569e-04 - val_loss: 7.4906e-05\n",
      "Epoch 112/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6608e-04 - val_loss: 7.4749e-05\n",
      "Epoch 113/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6476e-04 - val_loss: 8.0579e-05\n",
      "Epoch 114/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6787e-04 - val_loss: 7.4931e-05\n",
      "Epoch 115/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6299e-04 - val_loss: 7.5186e-05\n",
      "Epoch 116/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6298e-04 - val_loss: 7.4775e-05\n",
      "Epoch 117/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7024e-04 - val_loss: 7.5438e-05\n",
      "Epoch 118/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6473e-04 - val_loss: 7.5121e-05\n",
      "Epoch 119/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6298e-04 - val_loss: 8.2463e-05\n",
      "Epoch 120/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7328e-04 - val_loss: 7.9908e-05\n",
      "Epoch 121/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6638e-04 - val_loss: 8.6356e-05\n",
      "Epoch 122/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6565e-04 - val_loss: 7.8273e-05\n",
      "Epoch 123/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6268e-04 - val_loss: 7.6118e-05\n",
      "Epoch 124/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.8112e-04 - val_loss: 7.4537e-05\n",
      "Epoch 125/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6369e-04 - val_loss: 7.4643e-05\n",
      "Epoch 126/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6833e-04 - val_loss: 7.6648e-05\n",
      "Epoch 127/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6394e-04 - val_loss: 7.5621e-05\n",
      "Epoch 128/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6872e-04 - val_loss: 8.0628e-05\n",
      "Epoch 129/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6383e-04 - val_loss: 7.4683e-05\n",
      "Epoch 130/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6304e-04 - val_loss: 7.6791e-05\n",
      "Epoch 131/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6785e-04 - val_loss: 7.6231e-05\n",
      "Epoch 132/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6542e-04 - val_loss: 7.5290e-05\n",
      "Epoch 133/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6287e-04 - val_loss: 7.7332e-05\n",
      "Epoch 134/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6483e-04 - val_loss: 7.5220e-05\n",
      "Epoch 135/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6847e-04 - val_loss: 7.4693e-05\n",
      "Epoch 136/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7534e-04 - val_loss: 7.5106e-05\n",
      "Epoch 137/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6282e-04 - val_loss: 7.4713e-05\n",
      "Epoch 138/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6348e-04 - val_loss: 7.5096e-05\n",
      "Epoch 139/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7172e-04 - val_loss: 7.5912e-05\n",
      "Epoch 140/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6557e-04 - val_loss: 7.6244e-05\n",
      "Epoch 141/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6674e-04 - val_loss: 7.5410e-05\n",
      "Epoch 142/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6837e-04 - val_loss: 7.4528e-05\n",
      "Epoch 143/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6071e-04 - val_loss: 8.4414e-05\n",
      "Epoch 144/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7367e-04 - val_loss: 7.5909e-05\n",
      "Epoch 145/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6288e-04 - val_loss: 7.5941e-05\n",
      "Epoch 146/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6392e-04 - val_loss: 7.6362e-05\n",
      "Epoch 147/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6439e-04 - val_loss: 7.4544e-05\n",
      "Epoch 148/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6564e-04 - val_loss: 7.5354e-05\n",
      "Epoch 149/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6219e-04 - val_loss: 7.5469e-05\n",
      "Epoch 150/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7057e-04 - val_loss: 8.0246e-05\n",
      "Epoch 151/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7576e-04 - val_loss: 7.4924e-05\n",
      "Epoch 152/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6393e-04 - val_loss: 7.5013e-05\n",
      "Epoch 153/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6434e-04 - val_loss: 7.4907e-05\n",
      "Epoch 154/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6991e-04 - val_loss: 7.4624e-05\n",
      "Epoch 155/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6180e-04 - val_loss: 7.8484e-05\n",
      "Epoch 156/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6683e-04 - val_loss: 7.4711e-05\n",
      "Epoch 157/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6376e-04 - val_loss: 7.6495e-05\n",
      "Epoch 158/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6575e-04 - val_loss: 7.4663e-05\n",
      "Epoch 159/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6270e-04 - val_loss: 7.5031e-05\n",
      "Epoch 160/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6738e-04 - val_loss: 7.5423e-05\n",
      "Epoch 161/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6921e-04 - val_loss: 7.8603e-05\n",
      "Epoch 162/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6469e-04 - val_loss: 8.0414e-05\n",
      "Epoch 163/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6740e-04 - val_loss: 7.6060e-05\n",
      "Epoch 164/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6583e-04 - val_loss: 7.4730e-05\n",
      "Epoch 165/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6342e-04 - val_loss: 7.6932e-05\n",
      "Epoch 166/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6222e-04 - val_loss: 7.4692e-05\n",
      "Epoch 167/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6222e-04 - val_loss: 8.4283e-05\n",
      "Epoch 168/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.8358e-04 - val_loss: 7.5527e-05\n",
      "Epoch 169/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6391e-04 - val_loss: 7.7000e-05\n",
      "Epoch 170/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6525e-04 - val_loss: 7.4800e-05\n",
      "Epoch 171/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6439e-04 - val_loss: 7.4823e-05\n",
      "Epoch 172/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6298e-04 - val_loss: 7.9415e-05\n",
      "Epoch 173/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6597e-04 - val_loss: 8.0837e-05\n",
      "Epoch 174/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6822e-04 - val_loss: 7.4744e-05\n",
      "Epoch 175/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6417e-04 - val_loss: 7.6468e-05\n",
      "Epoch 176/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7047e-04 - val_loss: 7.8314e-05\n",
      "Epoch 177/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6859e-04 - val_loss: 7.4742e-05\n",
      "Epoch 178/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6473e-04 - val_loss: 7.4517e-05\n",
      "Epoch 179/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6302e-04 - val_loss: 7.7851e-05\n",
      "Epoch 180/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6419e-04 - val_loss: 7.4720e-05\n",
      "Epoch 181/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6635e-04 - val_loss: 7.4678e-05\n",
      "Epoch 182/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7339e-04 - val_loss: 7.5592e-05\n",
      "Epoch 183/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6882e-04 - val_loss: 8.1025e-05\n",
      "Epoch 184/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7162e-04 - val_loss: 7.5398e-05\n",
      "Epoch 185/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6814e-04 - val_loss: 7.5004e-05\n",
      "Epoch 186/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6365e-04 - val_loss: 7.8302e-05\n",
      "Epoch 187/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6344e-04 - val_loss: 7.6569e-05\n",
      "Epoch 188/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6419e-04 - val_loss: 7.6962e-05\n",
      "Epoch 189/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6502e-04 - val_loss: 7.7136e-05\n",
      "Epoch 190/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6271e-04 - val_loss: 8.0549e-05\n",
      "Epoch 191/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7916e-04 - val_loss: 7.4943e-05\n",
      "Epoch 192/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6253e-04 - val_loss: 7.9080e-05\n",
      "Epoch 193/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7755e-04 - val_loss: 7.5072e-05\n",
      "Epoch 194/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6190e-04 - val_loss: 7.4607e-05\n",
      "Epoch 195/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6537e-04 - val_loss: 7.4728e-05\n",
      "Epoch 196/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6980e-04 - val_loss: 7.4606e-05\n",
      "Epoch 197/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6283e-04 - val_loss: 7.8292e-05\n",
      "Epoch 198/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6562e-04 - val_loss: 7.4740e-05\n",
      "Epoch 199/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6391e-04 - val_loss: 7.7825e-05\n",
      "Epoch 200/200\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6833e-04 - val_loss: 7.4708e-05\n",
      "Thời gian huấn luyện:  27.80546259880066\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_27 (SimpleRNN)   (None, 1, 125)            15875     \n",
      "                                                                 \n",
      " flatten_109 (Flatten)       (None, 125)               0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 1)                 126       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,001\n",
      "Trainable params: 16,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "54/54 [==============================] - 3s 14ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 2/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 3/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 4/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 5/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 6/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 7/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 8/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 9/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 10/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 11/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 12/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 13/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 14/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 15/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 16/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 17/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 18/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 19/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 20/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 21/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 22/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 23/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 24/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 25/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 26/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 27/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 28/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 29/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 30/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 31/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 32/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 33/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 34/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 35/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 36/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 37/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 38/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 39/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 40/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 41/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 42/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 43/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 44/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 45/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 46/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 47/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 48/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 49/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 50/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 51/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 52/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 53/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 54/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 55/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 57/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 58/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 59/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 60/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 61/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 62/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 63/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 64/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 65/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 66/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 67/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 68/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 69/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 70/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 71/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 72/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 73/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 74/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 75/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 76/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 77/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 78/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 79/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 80/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 81/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 82/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 83/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 84/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 85/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 86/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 87/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 88/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 89/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 90/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 91/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 92/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 93/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 94/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 95/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 96/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 97/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 98/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 99/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 100/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 101/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 102/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 103/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 104/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 105/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 106/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 107/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 108/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 109/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 110/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 111/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 112/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 113/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 114/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 115/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 116/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 117/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 118/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 119/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 120/200\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 121/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 122/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 123/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 124/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 125/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 126/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 127/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 128/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 129/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 130/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 131/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 132/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 133/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 134/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 135/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 136/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 137/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 138/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 139/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 140/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 141/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 142/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 143/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 144/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 145/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 146/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 147/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 148/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 149/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 150/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 151/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 152/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 153/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 154/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 155/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 156/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 157/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 158/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 159/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 160/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 161/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 162/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 163/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 164/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 165/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 166/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 167/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 168/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 169/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 170/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 171/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 172/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 173/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 174/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 175/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 176/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 177/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 178/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 179/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 180/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 181/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 182/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 183/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 184/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 185/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 186/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 187/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 188/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 189/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 190/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 191/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 192/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 193/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 194/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 195/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 196/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 197/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 198/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 199/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Epoch 200/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.0094\n",
      "Thời gian huấn luyện:  41.46220660209656\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_27 (LSTM)              (None, 1, 125)            63500     \n",
      "                                                                 \n",
      " flatten_110 (Flatten)       (None, 125)               0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 1)                 126       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63,626\n",
      "Trainable params: 63,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "54/54 [==============================] - 3s 15ms/step - loss: 0.0680 - val_loss: 0.0438\n",
      "Epoch 2/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.0426\n",
      "Epoch 3/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0347\n",
      "Epoch 4/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0297\n",
      "Epoch 5/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0240\n",
      "Epoch 6/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0202\n",
      "Epoch 7/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0156\n",
      "Epoch 8/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0098\n",
      "Epoch 10/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0074\n",
      "Epoch 11/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 12/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 13/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 14/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 15/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 8.3158e-04 - val_loss: 0.0015\n",
      "Epoch 16/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 6.6645e-04 - val_loss: 9.3865e-04\n",
      "Epoch 17/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 5.5472e-04 - val_loss: 7.2171e-04\n",
      "Epoch 18/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.8445e-04 - val_loss: 5.4147e-04\n",
      "Epoch 19/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 4.3951e-04 - val_loss: 4.1414e-04\n",
      "Epoch 20/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.0993e-04 - val_loss: 2.7383e-04\n",
      "Epoch 21/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.9265e-04 - val_loss: 2.2964e-04\n",
      "Epoch 22/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.8304e-04 - val_loss: 2.0922e-04\n",
      "Epoch 23/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7894e-04 - val_loss: 1.6171e-04\n",
      "Epoch 24/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7179e-04 - val_loss: 1.4954e-04\n",
      "Epoch 25/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7047e-04 - val_loss: 1.3901e-04\n",
      "Epoch 26/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6899e-04 - val_loss: 1.1646e-04\n",
      "Epoch 27/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6767e-04 - val_loss: 1.2767e-04\n",
      "Epoch 28/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6772e-04 - val_loss: 1.0943e-04\n",
      "Epoch 29/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6755e-04 - val_loss: 1.0412e-04\n",
      "Epoch 30/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6781e-04 - val_loss: 1.1594e-04\n",
      "Epoch 31/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6988e-04 - val_loss: 9.5487e-05\n",
      "Epoch 32/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6774e-04 - val_loss: 8.9795e-05\n",
      "Epoch 33/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6861e-04 - val_loss: 9.1612e-05\n",
      "Epoch 34/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6890e-04 - val_loss: 9.9386e-05\n",
      "Epoch 35/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6784e-04 - val_loss: 9.6207e-05\n",
      "Epoch 36/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6711e-04 - val_loss: 9.3989e-05\n",
      "Epoch 37/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6766e-04 - val_loss: 1.0876e-04\n",
      "Epoch 38/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6850e-04 - val_loss: 1.1065e-04\n",
      "Epoch 39/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6802e-04 - val_loss: 9.9400e-05\n",
      "Epoch 40/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6757e-04 - val_loss: 9.9173e-05\n",
      "Epoch 41/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6812e-04 - val_loss: 1.0897e-04\n",
      "Epoch 42/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6733e-04 - val_loss: 9.7949e-05\n",
      "Epoch 43/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6751e-04 - val_loss: 9.4249e-05\n",
      "Epoch 44/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6711e-04 - val_loss: 1.0332e-04\n",
      "Epoch 45/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6701e-04 - val_loss: 1.1436e-04\n",
      "Epoch 46/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6767e-04 - val_loss: 8.2116e-05\n",
      "Epoch 47/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7015e-04 - val_loss: 1.0939e-04\n",
      "Epoch 48/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7025e-04 - val_loss: 1.1242e-04\n",
      "Epoch 49/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7301e-04 - val_loss: 1.1192e-04\n",
      "Epoch 50/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6766e-04 - val_loss: 9.5360e-05\n",
      "Epoch 51/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6684e-04 - val_loss: 9.5464e-05\n",
      "Epoch 52/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6781e-04 - val_loss: 9.6698e-05\n",
      "Epoch 53/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6782e-04 - val_loss: 9.7874e-05\n",
      "Epoch 54/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6677e-04 - val_loss: 1.0993e-04\n",
      "Epoch 55/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6842e-04 - val_loss: 1.1597e-04\n",
      "Epoch 56/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6938e-04 - val_loss: 8.4162e-05\n",
      "Epoch 57/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6770e-04 - val_loss: 1.0043e-04\n",
      "Epoch 58/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7207e-04 - val_loss: 1.1083e-04\n",
      "Epoch 59/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6883e-04 - val_loss: 9.3218e-05\n",
      "Epoch 60/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6853e-04 - val_loss: 9.0960e-05\n",
      "Epoch 61/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7247e-04 - val_loss: 9.6393e-05\n",
      "Epoch 62/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6741e-04 - val_loss: 9.9222e-05\n",
      "Epoch 63/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6785e-04 - val_loss: 1.0039e-04\n",
      "Epoch 64/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6895e-04 - val_loss: 1.0068e-04\n",
      "Epoch 65/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6756e-04 - val_loss: 9.5507e-05\n",
      "Epoch 66/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6760e-04 - val_loss: 9.8918e-05\n",
      "Epoch 67/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7161e-04 - val_loss: 9.6664e-05\n",
      "Epoch 68/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6931e-04 - val_loss: 1.0298e-04\n",
      "Epoch 69/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6943e-04 - val_loss: 9.5644e-05\n",
      "Epoch 70/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6954e-04 - val_loss: 9.4887e-05\n",
      "Epoch 71/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6786e-04 - val_loss: 1.2487e-04\n",
      "Epoch 72/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7547e-04 - val_loss: 1.0950e-04\n",
      "Epoch 73/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6990e-04 - val_loss: 1.1266e-04\n",
      "Epoch 74/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6754e-04 - val_loss: 9.3319e-05\n",
      "Epoch 75/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6692e-04 - val_loss: 7.8788e-05\n",
      "Epoch 76/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.8489e-04 - val_loss: 8.7220e-05\n",
      "Epoch 77/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7314e-04 - val_loss: 1.0365e-04\n",
      "Epoch 78/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6781e-04 - val_loss: 1.4791e-04\n",
      "Epoch 79/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7152e-04 - val_loss: 1.0100e-04\n",
      "Epoch 80/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6805e-04 - val_loss: 9.0805e-05\n",
      "Epoch 81/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7084e-04 - val_loss: 1.1927e-04\n",
      "Epoch 82/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6850e-04 - val_loss: 9.0137e-05\n",
      "Epoch 83/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6917e-04 - val_loss: 9.9587e-05\n",
      "Epoch 84/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7040e-04 - val_loss: 9.8850e-05\n",
      "Epoch 85/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6737e-04 - val_loss: 9.4162e-05\n",
      "Epoch 86/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6704e-04 - val_loss: 1.1269e-04\n",
      "Epoch 87/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6907e-04 - val_loss: 7.9320e-05\n",
      "Epoch 88/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6772e-04 - val_loss: 9.5724e-05\n",
      "Epoch 89/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6710e-04 - val_loss: 8.4845e-05\n",
      "Epoch 90/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7123e-04 - val_loss: 1.0179e-04\n",
      "Epoch 91/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6862e-04 - val_loss: 8.9491e-05\n",
      "Epoch 92/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6955e-04 - val_loss: 9.2302e-05\n",
      "Epoch 93/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6766e-04 - val_loss: 1.1487e-04\n",
      "Epoch 94/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7645e-04 - val_loss: 9.0861e-05\n",
      "Epoch 95/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6667e-04 - val_loss: 8.9100e-05\n",
      "Epoch 96/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7118e-04 - val_loss: 1.0910e-04\n",
      "Epoch 97/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6923e-04 - val_loss: 9.5800e-05\n",
      "Epoch 98/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7140e-04 - val_loss: 9.3881e-05\n",
      "Epoch 99/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6768e-04 - val_loss: 1.1152e-04\n",
      "Epoch 100/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6665e-04 - val_loss: 8.7034e-05\n",
      "Epoch 101/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6905e-04 - val_loss: 8.1279e-05\n",
      "Epoch 102/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6897e-04 - val_loss: 1.1216e-04\n",
      "Epoch 103/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6688e-04 - val_loss: 9.2268e-05\n",
      "Epoch 104/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6601e-04 - val_loss: 9.5503e-05\n",
      "Epoch 105/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6902e-04 - val_loss: 1.1110e-04\n",
      "Epoch 106/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6960e-04 - val_loss: 8.7516e-05\n",
      "Epoch 107/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6776e-04 - val_loss: 1.0493e-04\n",
      "Epoch 108/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6913e-04 - val_loss: 9.7397e-05\n",
      "Epoch 109/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6721e-04 - val_loss: 8.9325e-05\n",
      "Epoch 110/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6650e-04 - val_loss: 9.5027e-05\n",
      "Epoch 111/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7134e-04 - val_loss: 8.7034e-05\n",
      "Epoch 112/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6928e-04 - val_loss: 1.0266e-04\n",
      "Epoch 113/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6748e-04 - val_loss: 1.1698e-04\n",
      "Epoch 114/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7182e-04 - val_loss: 1.0074e-04\n",
      "Epoch 115/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6769e-04 - val_loss: 9.2816e-05\n",
      "Epoch 116/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7003e-04 - val_loss: 1.0870e-04\n",
      "Epoch 117/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6792e-04 - val_loss: 9.0661e-05\n",
      "Epoch 118/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6634e-04 - val_loss: 9.3823e-05\n",
      "Epoch 119/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7532e-04 - val_loss: 8.4085e-05\n",
      "Epoch 120/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6633e-04 - val_loss: 9.6898e-05\n",
      "Epoch 121/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6799e-04 - val_loss: 9.9529e-05\n",
      "Epoch 122/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7023e-04 - val_loss: 9.8296e-05\n",
      "Epoch 123/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6918e-04 - val_loss: 8.9774e-05\n",
      "Epoch 124/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6745e-04 - val_loss: 9.2803e-05\n",
      "Epoch 125/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6606e-04 - val_loss: 1.1489e-04\n",
      "Epoch 126/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6832e-04 - val_loss: 1.0626e-04\n",
      "Epoch 127/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7012e-04 - val_loss: 8.7542e-05\n",
      "Epoch 128/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6767e-04 - val_loss: 9.7231e-05\n",
      "Epoch 129/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6744e-04 - val_loss: 8.3656e-05\n",
      "Epoch 130/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6596e-04 - val_loss: 8.7733e-05\n",
      "Epoch 131/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6619e-04 - val_loss: 8.4119e-05\n",
      "Epoch 132/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6995e-04 - val_loss: 1.1442e-04\n",
      "Epoch 133/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6901e-04 - val_loss: 9.9939e-05\n",
      "Epoch 134/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6882e-04 - val_loss: 8.6694e-05\n",
      "Epoch 135/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7108e-04 - val_loss: 1.0519e-04\n",
      "Epoch 136/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7241e-04 - val_loss: 1.1585e-04\n",
      "Epoch 137/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6838e-04 - val_loss: 8.6103e-05\n",
      "Epoch 138/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6533e-04 - val_loss: 1.2745e-04\n",
      "Epoch 139/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7037e-04 - val_loss: 1.0117e-04\n",
      "Epoch 140/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6627e-04 - val_loss: 9.8279e-05\n",
      "Epoch 141/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6848e-04 - val_loss: 8.4885e-05\n",
      "Epoch 142/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6704e-04 - val_loss: 9.4386e-05\n",
      "Epoch 143/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6644e-04 - val_loss: 9.1022e-05\n",
      "Epoch 144/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6532e-04 - val_loss: 9.8188e-05\n",
      "Epoch 145/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6807e-04 - val_loss: 8.3192e-05\n",
      "Epoch 146/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6692e-04 - val_loss: 1.5187e-04\n",
      "Epoch 147/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6819e-04 - val_loss: 8.4126e-05\n",
      "Epoch 148/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6888e-04 - val_loss: 8.4862e-05\n",
      "Epoch 149/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6686e-04 - val_loss: 8.8304e-05\n",
      "Epoch 150/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7923e-04 - val_loss: 9.1175e-05\n",
      "Epoch 151/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6572e-04 - val_loss: 9.0967e-05\n",
      "Epoch 152/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6824e-04 - val_loss: 9.1394e-05\n",
      "Epoch 153/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6564e-04 - val_loss: 9.4621e-05\n",
      "Epoch 154/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6613e-04 - val_loss: 1.0932e-04\n",
      "Epoch 155/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7460e-04 - val_loss: 1.0765e-04\n",
      "Epoch 156/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6546e-04 - val_loss: 7.4667e-05\n",
      "Epoch 157/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7089e-04 - val_loss: 7.8571e-05\n",
      "Epoch 158/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6881e-04 - val_loss: 7.3816e-05\n",
      "Epoch 159/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.8115e-04 - val_loss: 1.1215e-04\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6938e-04 - val_loss: 7.6345e-05\n",
      "Epoch 161/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6547e-04 - val_loss: 9.5331e-05\n",
      "Epoch 162/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6573e-04 - val_loss: 8.1614e-05\n",
      "Epoch 163/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6621e-04 - val_loss: 8.6941e-05\n",
      "Epoch 164/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7125e-04 - val_loss: 9.1854e-05\n",
      "Epoch 165/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6597e-04 - val_loss: 1.0324e-04\n",
      "Epoch 166/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 3.6671e-04 - val_loss: 8.3741e-05\n",
      "Epoch 167/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 3.6644e-04 - val_loss: 7.6776e-05\n",
      "Epoch 168/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6740e-04 - val_loss: 8.5696e-05\n",
      "Epoch 169/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6484e-04 - val_loss: 7.3682e-05\n",
      "Epoch 170/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7048e-04 - val_loss: 1.1511e-04\n",
      "Epoch 171/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7810e-04 - val_loss: 7.5343e-05\n",
      "Epoch 172/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6878e-04 - val_loss: 8.5819e-05\n",
      "Epoch 173/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6573e-04 - val_loss: 1.1565e-04\n",
      "Epoch 174/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7621e-04 - val_loss: 8.0169e-05\n",
      "Epoch 175/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6763e-04 - val_loss: 8.1631e-05\n",
      "Epoch 176/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6695e-04 - val_loss: 9.8910e-05\n",
      "Epoch 177/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6456e-04 - val_loss: 8.1048e-05\n",
      "Epoch 178/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6668e-04 - val_loss: 1.2876e-04\n",
      "Epoch 179/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7675e-04 - val_loss: 9.2561e-05\n",
      "Epoch 180/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6553e-04 - val_loss: 8.2705e-05\n",
      "Epoch 181/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6484e-04 - val_loss: 8.1411e-05\n",
      "Epoch 182/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6685e-04 - val_loss: 7.5445e-05\n",
      "Epoch 183/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 3.7482e-04 - val_loss: 9.9726e-05\n",
      "Epoch 184/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6596e-04 - val_loss: 9.2767e-05\n",
      "Epoch 185/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6455e-04 - val_loss: 7.5058e-05\n",
      "Epoch 186/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6908e-04 - val_loss: 8.4886e-05\n",
      "Epoch 187/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6535e-04 - val_loss: 9.0559e-05\n",
      "Epoch 188/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6641e-04 - val_loss: 7.4893e-05\n",
      "Epoch 189/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6692e-04 - val_loss: 9.1142e-05\n",
      "Epoch 190/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6867e-04 - val_loss: 7.4387e-05\n",
      "Epoch 191/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.6737e-04 - val_loss: 7.6607e-05\n",
      "Epoch 192/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6772e-04 - val_loss: 9.1999e-05\n",
      "Epoch 193/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6817e-04 - val_loss: 8.3376e-05\n",
      "Epoch 194/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6350e-04 - val_loss: 1.2051e-04\n",
      "Epoch 195/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7462e-04 - val_loss: 7.8320e-05\n",
      "Epoch 196/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7716e-04 - val_loss: 9.0785e-05\n",
      "Epoch 197/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6872e-04 - val_loss: 8.4617e-05\n",
      "Epoch 198/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6116e-04 - val_loss: 7.7393e-05\n",
      "Epoch 199/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.7882e-04 - val_loss: 8.5428e-05\n",
      "Epoch 200/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6889e-04 - val_loss: 8.2772e-05\n",
      "Thời gian huấn luyện:  41.39469790458679\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_27 (GRU)                (None, 1, 125)            48000     \n",
      "                                                                 \n",
      " flatten_111 (Flatten)       (None, 125)               0         \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 1)                 126       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,126\n",
      "Trainable params: 48,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 1s 5ms/step - loss: 0.0762 - val_loss: 0.0223\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0314\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0258\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0216\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0176\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0137\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0110\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0081\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0061\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.9585e-04 - val_loss: 0.0017\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.4234e-04 - val_loss: 0.0012\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.4266e-04 - val_loss: 9.1825e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.7791e-04 - val_loss: 7.3052e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.3902e-04 - val_loss: 5.6729e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.1503e-04 - val_loss: 4.7965e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9856e-04 - val_loss: 3.8790e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9133e-04 - val_loss: 3.4823e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.8601e-04 - val_loss: 2.9898e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.8283e-04 - val_loss: 2.7807e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.8084e-04 - val_loss: 2.7209e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7903e-04 - val_loss: 2.3874e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7688e-04 - val_loss: 2.3470e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7576e-04 - val_loss: 2.1679e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7516e-04 - val_loss: 2.1835e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.7181e-04 - val_loss: 2.2835e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.7392e-04 - val_loss: 2.0840e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7058e-04 - val_loss: 1.9566e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7222e-04 - val_loss: 1.9883e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6990e-04 - val_loss: 1.9806e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6911e-04 - val_loss: 1.8890e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7026e-04 - val_loss: 1.8826e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6897e-04 - val_loss: 1.9091e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6736e-04 - val_loss: 1.8474e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6800e-04 - val_loss: 1.7736e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6774e-04 - val_loss: 1.7805e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6609e-04 - val_loss: 1.7607e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6621e-04 - val_loss: 1.7156e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6374e-04 - val_loss: 1.6560e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6413e-04 - val_loss: 1.7073e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6359e-04 - val_loss: 1.6501e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6577e-04 - val_loss: 1.7567e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6118e-04 - val_loss: 1.6361e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5984e-04 - val_loss: 1.5696e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6157e-04 - val_loss: 1.5495e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5747e-04 - val_loss: 1.6740e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.5804e-04 - val_loss: 1.5437e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5673e-04 - val_loss: 1.6147e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5781e-04 - val_loss: 1.5096e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5793e-04 - val_loss: 1.5268e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5533e-04 - val_loss: 1.5262e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5435e-04 - val_loss: 1.5723e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5491e-04 - val_loss: 1.5154e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5686e-04 - val_loss: 1.5252e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5103e-04 - val_loss: 1.5385e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5027e-04 - val_loss: 1.4564e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.5047e-04 - val_loss: 1.4043e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4783e-04 - val_loss: 1.4577e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4720e-04 - val_loss: 1.4709e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4747e-04 - val_loss: 1.4756e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4591e-04 - val_loss: 1.4304e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4580e-04 - val_loss: 1.4185e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4442e-04 - val_loss: 1.4613e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4259e-04 - val_loss: 1.3991e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4317e-04 - val_loss: 1.4329e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4573e-04 - val_loss: 1.4457e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4498e-04 - val_loss: 1.3545e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4041e-04 - val_loss: 1.4300e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3963e-04 - val_loss: 1.3308e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4301e-04 - val_loss: 1.4340e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3836e-04 - val_loss: 1.3270e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3767e-04 - val_loss: 1.3468e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3554e-04 - val_loss: 1.3260e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3551e-04 - val_loss: 1.3632e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3632e-04 - val_loss: 1.3086e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3448e-04 - val_loss: 1.3317e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3103e-04 - val_loss: 1.4357e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3220e-04 - val_loss: 1.3288e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2970e-04 - val_loss: 1.2627e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3235e-04 - val_loss: 1.4284e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3238e-04 - val_loss: 1.3835e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3048e-04 - val_loss: 1.3704e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2614e-04 - val_loss: 1.3316e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2636e-04 - val_loss: 1.3601e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2583e-04 - val_loss: 1.2420e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2408e-04 - val_loss: 1.2763e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2245e-04 - val_loss: 1.3053e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2360e-04 - val_loss: 1.2953e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1883e-04 - val_loss: 1.2387e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2142e-04 - val_loss: 1.4898e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.2041e-04 - val_loss: 1.4138e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1877e-04 - val_loss: 1.2295e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1893e-04 - val_loss: 1.2492e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1782e-04 - val_loss: 1.1995e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1329e-04 - val_loss: 1.1872e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1472e-04 - val_loss: 1.1785e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1458e-04 - val_loss: 1.2587e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1340e-04 - val_loss: 1.1796e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1486e-04 - val_loss: 1.2632e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0995e-04 - val_loss: 1.2574e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1171e-04 - val_loss: 1.1977e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1201e-04 - val_loss: 1.3009e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1066e-04 - val_loss: 1.1897e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0409e-04 - val_loss: 1.1528e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0447e-04 - val_loss: 1.1756e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0295e-04 - val_loss: 1.1543e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0525e-04 - val_loss: 1.1403e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0163e-04 - val_loss: 1.1903e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0020e-04 - val_loss: 1.1386e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0536e-04 - val_loss: 1.1535e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9721e-04 - val_loss: 1.1899e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0011e-04 - val_loss: 1.1360e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9687e-04 - val_loss: 1.1384e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9488e-04 - val_loss: 1.1623e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9457e-04 - val_loss: 1.1186e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9525e-04 - val_loss: 1.1854e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9620e-04 - val_loss: 1.2351e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9571e-04 - val_loss: 1.1031e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9003e-04 - val_loss: 1.1113e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8744e-04 - val_loss: 1.1004e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9025e-04 - val_loss: 1.1692e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8939e-04 - val_loss: 1.1624e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8739e-04 - val_loss: 1.2388e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8494e-04 - val_loss: 1.0976e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8535e-04 - val_loss: 1.1159e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8372e-04 - val_loss: 1.0903e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9046e-04 - val_loss: 1.2045e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8223e-04 - val_loss: 1.0987e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8048e-04 - val_loss: 1.1375e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8120e-04 - val_loss: 1.0750e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7998e-04 - val_loss: 1.2212e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7628e-04 - val_loss: 1.1767e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8136e-04 - val_loss: 1.0701e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7897e-04 - val_loss: 1.1197e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8045e-04 - val_loss: 1.0665e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7921e-04 - val_loss: 1.0618e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7687e-04 - val_loss: 1.0901e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7243e-04 - val_loss: 1.0552e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7578e-04 - val_loss: 1.0902e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7397e-04 - val_loss: 1.1122e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6805e-04 - val_loss: 1.1738e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7029e-04 - val_loss: 1.0966e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6846e-04 - val_loss: 1.2342e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7467e-04 - val_loss: 1.2332e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7122e-04 - val_loss: 1.0884e-04\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6690e-04 - val_loss: 1.0663e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6622e-04 - val_loss: 1.0437e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6692e-04 - val_loss: 1.1287e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6905e-04 - val_loss: 1.1254e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6040e-04 - val_loss: 1.0490e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6576e-04 - val_loss: 1.0792e-04\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6533e-04 - val_loss: 1.0285e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6042e-04 - val_loss: 1.0781e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6020e-04 - val_loss: 1.0654e-04\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6263e-04 - val_loss: 1.0521e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5974e-04 - val_loss: 1.0627e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.5816e-04 - val_loss: 1.0355e-04\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6152e-04 - val_loss: 1.0177e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5807e-04 - val_loss: 1.0987e-04\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5782e-04 - val_loss: 1.0116e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5527e-04 - val_loss: 1.1348e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5528e-04 - val_loss: 1.0402e-04\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5529e-04 - val_loss: 1.1107e-04\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5295e-04 - val_loss: 1.0088e-04\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5217e-04 - val_loss: 1.0099e-04\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5159e-04 - val_loss: 1.1740e-04\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5486e-04 - val_loss: 1.0775e-04\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5276e-04 - val_loss: 1.0779e-04\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4989e-04 - val_loss: 1.0436e-04\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4756e-04 - val_loss: 1.0114e-04\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4682e-04 - val_loss: 9.9154e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4530e-04 - val_loss: 9.9958e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5036e-04 - val_loss: 9.8826e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4907e-04 - val_loss: 1.0024e-04\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4604e-04 - val_loss: 9.8790e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4596e-04 - val_loss: 9.8476e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4733e-04 - val_loss: 1.0265e-04\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4403e-04 - val_loss: 9.8291e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4227e-04 - val_loss: 1.0068e-04\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4162e-04 - val_loss: 1.0582e-04\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4840e-04 - val_loss: 1.0200e-04\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4724e-04 - val_loss: 1.1139e-04\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3923e-04 - val_loss: 1.0279e-04\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4263e-04 - val_loss: 9.7055e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4251e-04 - val_loss: 9.6963e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3824e-04 - val_loss: 1.0176e-04\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3599e-04 - val_loss: 1.0403e-04\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.3599e-04 - val_loss: 9.6533e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3759e-04 - val_loss: 9.6427e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3524e-04 - val_loss: 9.9719e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3668e-04 - val_loss: 9.6524e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3689e-04 - val_loss: 9.9205e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3578e-04 - val_loss: 1.0682e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3662e-04 - val_loss: 9.5713e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3285e-04 - val_loss: 9.7940e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3093e-04 - val_loss: 9.5705e-05\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3046e-04 - val_loss: 1.0544e-04\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3375e-04 - val_loss: 9.5819e-05\n",
      "Thời gian huấn luyện:  21.42715072631836\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_140 (Dense)           (None, 3, 125)            250       \n",
      "                                                                 \n",
      " flatten_112 (Flatten)       (None, 375)               0         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 1)                 376       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 626\n",
      "Trainable params: 626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 881us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 3.5134e-04\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.0955e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.5038e-04 - val_loss: 2.0233e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 9.2740e-04 - val_loss: 2.0860e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 9.1596e-04 - val_loss: 2.0495e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.9419e-04 - val_loss: 2.2851e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.9151e-04 - val_loss: 2.0054e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.7387e-04 - val_loss: 2.0076e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.5883e-04 - val_loss: 1.9749e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.4762e-04 - val_loss: 2.1153e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.2730e-04 - val_loss: 2.0337e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.2895e-04 - val_loss: 1.8722e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.0728e-04 - val_loss: 1.9537e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.9471e-04 - val_loss: 1.9223e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.8797e-04 - val_loss: 1.9258e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.7456e-04 - val_loss: 1.9366e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.6081e-04 - val_loss: 1.7711e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.6205e-04 - val_loss: 1.7128e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.5073e-04 - val_loss: 1.8359e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.3981e-04 - val_loss: 1.7669e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.4109e-04 - val_loss: 1.6300e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1555e-04 - val_loss: 1.5795e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1341e-04 - val_loss: 1.6550e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.1887e-04 - val_loss: 1.5941e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9701e-04 - val_loss: 1.5679e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8900e-04 - val_loss: 1.5864e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0486e-04 - val_loss: 1.6116e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.6836e-04 - val_loss: 1.6072e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8763e-04 - val_loss: 1.6290e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.5248e-04 - val_loss: 1.4986e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4996e-04 - val_loss: 1.5904e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.3951e-04 - val_loss: 1.4602e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.3226e-04 - val_loss: 1.4804e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.3034e-04 - val_loss: 1.4150e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.2981e-04 - val_loss: 1.4681e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.4165e-04 - val_loss: 1.4454e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.1709e-04 - val_loss: 1.3750e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.0423e-04 - val_loss: 1.4503e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.0075e-04 - val_loss: 1.3915e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.9338e-04 - val_loss: 1.3941e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.9382e-04 - val_loss: 1.3303e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.0677e-04 - val_loss: 1.4058e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.9020e-04 - val_loss: 1.2846e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.7948e-04 - val_loss: 1.2887e-04\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 3ms/step - loss: 5.9080e-04 - val_loss: 1.2599e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.7010e-04 - val_loss: 1.3018e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.7208e-04 - val_loss: 1.3256e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.7409e-04 - val_loss: 1.3764e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.5890e-04 - val_loss: 1.2261e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.7586e-04 - val_loss: 1.2847e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.6930e-04 - val_loss: 1.2024e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.5760e-04 - val_loss: 1.2018e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.4982e-04 - val_loss: 1.3059e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.4155e-04 - val_loss: 1.2231e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.3819e-04 - val_loss: 1.2225e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.3760e-04 - val_loss: 1.1893e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.3628e-04 - val_loss: 1.1561e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.5134e-04 - val_loss: 1.1676e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.1782e-04 - val_loss: 1.1447e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.1153e-04 - val_loss: 1.1208e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.0897e-04 - val_loss: 1.1004e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.2534e-04 - val_loss: 1.1276e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.1130e-04 - val_loss: 1.1255e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.2113e-04 - val_loss: 1.1047e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9817e-04 - val_loss: 1.0925e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.1204e-04 - val_loss: 1.0579e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.9609e-04 - val_loss: 1.0858e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.9269e-04 - val_loss: 1.0775e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.9322e-04 - val_loss: 1.0963e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.9213e-04 - val_loss: 1.0255e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.7480e-04 - val_loss: 1.0567e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.8035e-04 - val_loss: 1.0353e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.7066e-04 - val_loss: 1.0263e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.7898e-04 - val_loss: 1.0337e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.8706e-04 - val_loss: 1.1239e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.8109e-04 - val_loss: 1.0071e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.5823e-04 - val_loss: 1.0171e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.6177e-04 - val_loss: 1.0057e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.6226e-04 - val_loss: 9.8979e-05\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4847e-04 - val_loss: 9.5533e-05\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.5103e-04 - val_loss: 9.6047e-05\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.6757e-04 - val_loss: 9.7233e-05\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4267e-04 - val_loss: 9.4506e-05\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4266e-04 - val_loss: 9.4779e-05\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.5054e-04 - val_loss: 9.5548e-05\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.3801e-04 - val_loss: 9.4138e-05\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4046e-04 - val_loss: 9.5536e-05\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.5292e-04 - val_loss: 1.0114e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.8820e-04 - val_loss: 9.2494e-05\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3941e-04 - val_loss: 9.1337e-05\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4581e-04 - val_loss: 9.7299e-05\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4143e-04 - val_loss: 8.9536e-05\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4540e-04 - val_loss: 8.8459e-05\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1992e-04 - val_loss: 8.8874e-05\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3542e-04 - val_loss: 8.8555e-05\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2058e-04 - val_loss: 9.1199e-05\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2893e-04 - val_loss: 8.7046e-05\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4962e-04 - val_loss: 9.6743e-05\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.3102e-04 - val_loss: 8.6568e-05\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1019e-04 - val_loss: 8.8821e-05\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1283e-04 - val_loss: 8.7284e-05\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1113e-04 - val_loss: 8.5950e-05\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1063e-04 - val_loss: 9.3050e-05\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1043e-04 - val_loss: 8.4350e-05\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1151e-04 - val_loss: 8.5845e-05\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0236e-04 - val_loss: 8.4978e-05\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0403e-04 - val_loss: 8.5495e-05\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2011e-04 - val_loss: 8.4354e-05\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.9396e-04 - val_loss: 8.3129e-05\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2437e-04 - val_loss: 8.3079e-05\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1215e-04 - val_loss: 8.1915e-05\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.9209e-04 - val_loss: 8.1663e-05\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0508e-04 - val_loss: 8.3194e-05\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8560e-04 - val_loss: 8.1956e-05\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.9538e-04 - val_loss: 8.7015e-05\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0673e-04 - val_loss: 8.1211e-05\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0581e-04 - val_loss: 8.0632e-05\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.9329e-04 - val_loss: 8.5148e-05\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2487e-04 - val_loss: 7.9620e-05\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8688e-04 - val_loss: 8.1631e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2153e-04 - val_loss: 8.1457e-05\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8170e-04 - val_loss: 8.1818e-05\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.9051e-04 - val_loss: 8.0066e-05\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8066e-04 - val_loss: 7.9504e-05\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8377e-04 - val_loss: 8.4767e-05\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0122e-04 - val_loss: 8.0550e-05\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.9239e-04 - val_loss: 7.9075e-05\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7763e-04 - val_loss: 8.1207e-05\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7731e-04 - val_loss: 7.8614e-05\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0338e-04 - val_loss: 7.7978e-05\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8960e-04 - val_loss: 7.8363e-05\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7544e-04 - val_loss: 8.1324e-05\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2754e-04 - val_loss: 7.7235e-05\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0107e-04 - val_loss: 7.8777e-05\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.9625e-04 - val_loss: 9.0684e-05\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8832e-04 - val_loss: 7.6827e-05\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8372e-04 - val_loss: 7.7552e-05\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7408e-04 - val_loss: 7.6774e-05\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0660e-04 - val_loss: 8.0777e-05\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1111e-04 - val_loss: 7.6543e-05\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7002e-04 - val_loss: 7.7639e-05\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7203e-04 - val_loss: 7.5758e-05\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8228e-04 - val_loss: 7.8346e-05\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7805e-04 - val_loss: 7.8517e-05\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7466e-04 - val_loss: 7.6157e-05\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8711e-04 - val_loss: 7.6777e-05\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8469e-04 - val_loss: 8.5520e-05\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8139e-04 - val_loss: 7.7987e-05\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7611e-04 - val_loss: 7.5782e-05\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8102e-04 - val_loss: 8.2256e-05\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8380e-04 - val_loss: 7.5998e-05\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8360e-04 - val_loss: 7.7229e-05\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8022e-04 - val_loss: 7.6090e-05\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0945e-04 - val_loss: 7.6890e-05\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8071e-04 - val_loss: 7.9878e-05\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7123e-04 - val_loss: 7.9188e-05\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8173e-04 - val_loss: 9.2479e-05\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9129e-04 - val_loss: 7.4821e-05\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7306e-04 - val_loss: 7.5629e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7158e-04 - val_loss: 7.5808e-05\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8764e-04 - val_loss: 7.5106e-05\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.9712e-04 - val_loss: 7.5367e-05\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8441e-04 - val_loss: 8.7228e-05\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2403e-04 - val_loss: 7.5045e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.9755e-04 - val_loss: 7.6224e-05\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7635e-04 - val_loss: 7.5182e-05\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7910e-04 - val_loss: 7.9198e-05\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7038e-04 - val_loss: 7.5629e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7046e-04 - val_loss: 7.4699e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7265e-04 - val_loss: 7.6736e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7094e-04 - val_loss: 7.6221e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 3.8221e-04 - val_loss: 7.6517e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8006e-04 - val_loss: 7.5533e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7690e-04 - val_loss: 7.7461e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.9820e-04 - val_loss: 7.6771e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.6816e-04 - val_loss: 7.4380e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7379e-04 - val_loss: 7.5144e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7230e-04 - val_loss: 8.0433e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7082e-04 - val_loss: 7.5993e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7547e-04 - val_loss: 7.8098e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.6725e-04 - val_loss: 7.4615e-05\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8916e-04 - val_loss: 7.8829e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7562e-04 - val_loss: 7.4657e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7419e-04 - val_loss: 8.0228e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8080e-04 - val_loss: 7.4957e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.9734e-04 - val_loss: 8.1677e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.6645e-04 - val_loss: 7.5521e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7160e-04 - val_loss: 7.6498e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8236e-04 - val_loss: 7.4359e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7844e-04 - val_loss: 7.5596e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7578e-04 - val_loss: 7.9041e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7318e-04 - val_loss: 7.3806e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7427e-04 - val_loss: 7.5778e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7076e-04 - val_loss: 7.7957e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7615e-04 - val_loss: 7.9548e-05\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.8728e-04 - val_loss: 7.5049e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7767e-04 - val_loss: 7.7227e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.7934e-04 - val_loss: 7.4394e-05\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.6525e-04 - val_loss: 7.4789e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.6634e-04 - val_loss: 7.7380e-05\n",
      "Thời gian huấn luyện:  32.47873497009277\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_28 (SimpleRNN)   (None, 3, 125)            15875     \n",
      "                                                                 \n",
      " flatten_113 (Flatten)       (None, 375)               0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 1)                 376       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,251\n",
      "Trainable params: 16,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 3s 14ms/step - loss: 0.1847 - val_loss: 9.1504e-04\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0169\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0102\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 9.1932e-04 - val_loss: 0.0011\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.7220e-04 - val_loss: 8.7294e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.5733e-04 - val_loss: 7.3111e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.5291e-04 - val_loss: 6.5772e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.4668e-04 - val_loss: 6.1915e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.4371e-04 - val_loss: 5.9995e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.4126e-04 - val_loss: 6.6141e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.4072e-04 - val_loss: 6.3964e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.4269e-04 - val_loss: 5.0655e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.3573e-04 - val_loss: 5.3780e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.3093e-04 - val_loss: 6.0261e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.3058e-04 - val_loss: 5.2465e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.2629e-04 - val_loss: 4.8182e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.3314e-04 - val_loss: 4.9530e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.2178e-04 - val_loss: 5.1598e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 8.2410e-04 - val_loss: 5.0475e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.2345e-04 - val_loss: 5.1454e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.1853e-04 - val_loss: 4.2924e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.0857e-04 - val_loss: 4.8264e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.1037e-04 - val_loss: 4.2730e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 8.1005e-04 - val_loss: 4.4703e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.0684e-04 - val_loss: 4.3447e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.0752e-04 - val_loss: 3.7435e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.0222e-04 - val_loss: 4.4874e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.0189e-04 - val_loss: 4.3611e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.9975e-04 - val_loss: 3.7696e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.9310e-04 - val_loss: 3.9535e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.9405e-04 - val_loss: 3.6962e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.8836e-04 - val_loss: 3.8629e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.8840e-04 - val_loss: 3.6008e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.8225e-04 - val_loss: 3.4650e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.8290e-04 - val_loss: 3.3686e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.8142e-04 - val_loss: 3.1403e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.7757e-04 - val_loss: 2.9990e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.7887e-04 - val_loss: 3.5396e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.7255e-04 - val_loss: 3.5263e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.7561e-04 - val_loss: 3.4487e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.7507e-04 - val_loss: 3.2070e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.7139e-04 - val_loss: 3.1601e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.7262e-04 - val_loss: 2.8215e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.6389e-04 - val_loss: 3.4118e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.6747e-04 - val_loss: 3.2248e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.6530e-04 - val_loss: 3.0394e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.6492e-04 - val_loss: 2.4567e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.6134e-04 - val_loss: 2.8386e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.5640e-04 - val_loss: 2.4549e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.5080e-04 - val_loss: 2.4215e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.5066e-04 - val_loss: 2.2571e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.5503e-04 - val_loss: 2.5958e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.4922e-04 - val_loss: 2.0800e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.5032e-04 - val_loss: 2.7714e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.4901e-04 - val_loss: 2.3014e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.4458e-04 - val_loss: 2.8302e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.4729e-04 - val_loss: 2.5760e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.4154e-04 - val_loss: 2.3679e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.4399e-04 - val_loss: 2.2656e-04\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 6ms/step - loss: 7.3702e-04 - val_loss: 2.0924e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.3749e-04 - val_loss: 2.2746e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3716e-04 - val_loss: 2.5102e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.4076e-04 - val_loss: 1.8039e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.5990e-04 - val_loss: 1.8516e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.3569e-04 - val_loss: 2.1207e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3020e-04 - val_loss: 2.0710e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3142e-04 - val_loss: 2.0898e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.2930e-04 - val_loss: 2.3536e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.2914e-04 - val_loss: 1.7526e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3173e-04 - val_loss: 1.9039e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3277e-04 - val_loss: 2.6485e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.2288e-04 - val_loss: 1.9657e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.2384e-04 - val_loss: 1.8276e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.2718e-04 - val_loss: 1.8415e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.2577e-04 - val_loss: 2.0517e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.1672e-04 - val_loss: 1.5741e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.2070e-04 - val_loss: 2.3418e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.1368e-04 - val_loss: 2.0117e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3389e-04 - val_loss: 1.8088e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.1510e-04 - val_loss: 1.8216e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.1504e-04 - val_loss: 1.8017e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.0304e-04 - val_loss: 2.0103e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.1667e-04 - val_loss: 1.7021e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.1202e-04 - val_loss: 2.0307e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.0674e-04 - val_loss: 1.8632e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.0517e-04 - val_loss: 1.5581e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.1107e-04 - val_loss: 1.8599e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.0275e-04 - val_loss: 1.4936e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.0165e-04 - val_loss: 1.6454e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.1330e-04 - val_loss: 1.8875e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.0309e-04 - val_loss: 1.8141e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.9603e-04 - val_loss: 1.5197e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.9921e-04 - val_loss: 1.5116e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.9819e-04 - val_loss: 2.0054e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.0808e-04 - val_loss: 1.6131e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.9355e-04 - val_loss: 1.6181e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.9352e-04 - val_loss: 1.6191e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.9068e-04 - val_loss: 1.5875e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.8780e-04 - val_loss: 1.4767e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.9403e-04 - val_loss: 1.4570e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.0297e-04 - val_loss: 1.5836e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.8670e-04 - val_loss: 1.6254e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.8862e-04 - val_loss: 1.5216e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.8194e-04 - val_loss: 1.5160e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.8089e-04 - val_loss: 1.4711e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.8220e-04 - val_loss: 1.5413e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.7953e-04 - val_loss: 1.5440e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.7760e-04 - val_loss: 1.7008e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.8603e-04 - val_loss: 1.5879e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.7463e-04 - val_loss: 1.6388e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.8256e-04 - val_loss: 1.9973e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.7296e-04 - val_loss: 1.4058e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.8212e-04 - val_loss: 1.5599e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.6794e-04 - val_loss: 1.4824e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6843e-04 - val_loss: 1.3981e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6833e-04 - val_loss: 1.4670e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.6468e-04 - val_loss: 1.4656e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.7083e-04 - val_loss: 1.4431e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.5912e-04 - val_loss: 1.5266e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6372e-04 - val_loss: 1.6354e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.5632e-04 - val_loss: 1.5984e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.5685e-04 - val_loss: 1.4197e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.5410e-04 - val_loss: 1.5343e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.5746e-04 - val_loss: 1.4414e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.5646e-04 - val_loss: 1.3677e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.5532e-04 - val_loss: 1.5825e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.5836e-04 - val_loss: 1.5068e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.4886e-04 - val_loss: 1.3747e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.5392e-04 - val_loss: 1.8492e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.5124e-04 - val_loss: 1.4085e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.5319e-04 - val_loss: 1.5734e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.4101e-04 - val_loss: 1.3920e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.3737e-04 - val_loss: 1.3999e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.3799e-04 - val_loss: 1.4428e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.3889e-04 - val_loss: 1.4676e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.3836e-04 - val_loss: 1.4550e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.3596e-04 - val_loss: 1.3904e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.3125e-04 - val_loss: 1.3995e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.3560e-04 - val_loss: 1.6355e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.3432e-04 - val_loss: 1.4385e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.2687e-04 - val_loss: 1.5797e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.3067e-04 - val_loss: 1.5711e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.2936e-04 - val_loss: 1.4872e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.2526e-04 - val_loss: 1.3774e-04\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.2331e-04 - val_loss: 1.3278e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.2153e-04 - val_loss: 1.4209e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.2320e-04 - val_loss: 1.4170e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.1843e-04 - val_loss: 1.5314e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.1953e-04 - val_loss: 1.3177e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.1570e-04 - val_loss: 1.3619e-04\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.1400e-04 - val_loss: 1.3151e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.1397e-04 - val_loss: 1.3103e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.1097e-04 - val_loss: 1.4610e-04\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.0943e-04 - val_loss: 1.4092e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0477e-04 - val_loss: 1.3478e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0948e-04 - val_loss: 1.4226e-04\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.0064e-04 - val_loss: 1.3321e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.0680e-04 - val_loss: 1.2843e-04\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.0172e-04 - val_loss: 1.3028e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.9933e-04 - val_loss: 1.4691e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.0102e-04 - val_loss: 1.2619e-04\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0122e-04 - val_loss: 1.2715e-04\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.9204e-04 - val_loss: 1.6282e-04\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.9085e-04 - val_loss: 1.5131e-04\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.9292e-04 - val_loss: 1.4600e-04\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.9343e-04 - val_loss: 1.3364e-04\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.9256e-04 - val_loss: 1.2560e-04\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.9096e-04 - val_loss: 1.4199e-04\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.8711e-04 - val_loss: 1.6750e-04\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0028e-04 - val_loss: 1.2363e-04\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.9465e-04 - val_loss: 1.2663e-04\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.8350e-04 - val_loss: 1.4560e-04\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.8560e-04 - val_loss: 1.2408e-04\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.7436e-04 - val_loss: 1.3369e-04\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.7562e-04 - val_loss: 1.2937e-04\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.7519e-04 - val_loss: 1.3537e-04\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.7702e-04 - val_loss: 1.4464e-04\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.7434e-04 - val_loss: 1.2192e-04\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.7004e-04 - val_loss: 1.2354e-04\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.6743e-04 - val_loss: 1.3207e-04\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.6415e-04 - val_loss: 1.2996e-04\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.6803e-04 - val_loss: 1.2364e-04\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.6264e-04 - val_loss: 1.3466e-04\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.5795e-04 - val_loss: 1.1964e-04\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.6102e-04 - val_loss: 1.3624e-04\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.5839e-04 - val_loss: 1.1912e-04\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.5779e-04 - val_loss: 1.2025e-04\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.5206e-04 - val_loss: 1.2407e-04\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.5664e-04 - val_loss: 1.1845e-04\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.4913e-04 - val_loss: 1.3953e-04\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.5616e-04 - val_loss: 1.1788e-04\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.4866e-04 - val_loss: 1.1893e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.5055e-04 - val_loss: 1.2782e-04\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.4019e-04 - val_loss: 1.1768e-04\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.4313e-04 - val_loss: 1.2052e-04\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.3939e-04 - val_loss: 1.2154e-04\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.3924e-04 - val_loss: 1.2682e-04\n",
      "Thời gian huấn luyện:  60.00114846229553\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_28 (LSTM)              (None, 3, 125)            63500     \n",
      "                                                                 \n",
      " flatten_114 (Flatten)       (None, 375)               0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 1)                 376       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63,876\n",
      "Trainable params: 63,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 3s 14ms/step - loss: 0.0333 - val_loss: 0.0115\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 5ms/step - loss: 8.5243e-04 - val_loss: 5.3218e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.5866e-04 - val_loss: 2.6861e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.5118e-04 - val_loss: 3.1720e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.4153e-04 - val_loss: 2.4393e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3899e-04 - val_loss: 2.2839e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4361e-04 - val_loss: 2.1023e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3892e-04 - val_loss: 2.4256e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3597e-04 - val_loss: 2.4396e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3498e-04 - val_loss: 2.0612e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3233e-04 - val_loss: 2.7040e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3187e-04 - val_loss: 2.0850e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3433e-04 - val_loss: 2.2876e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.2429e-04 - val_loss: 2.6793e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3205e-04 - val_loss: 1.7019e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3035e-04 - val_loss: 2.6020e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2089e-04 - val_loss: 2.6147e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2083e-04 - val_loss: 2.3456e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.1869e-04 - val_loss: 2.0662e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.1535e-04 - val_loss: 2.2168e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.1908e-04 - val_loss: 1.8511e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.1915e-04 - val_loss: 2.2291e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.0988e-04 - val_loss: 1.7077e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 7.1314e-04 - val_loss: 1.9664e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 7.1143e-04 - val_loss: 2.0132e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.1118e-04 - val_loss: 1.8793e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.0602e-04 - val_loss: 1.8482e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.0584e-04 - val_loss: 1.8662e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.0138e-04 - val_loss: 2.0031e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9860e-04 - val_loss: 1.8849e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.9744e-04 - val_loss: 2.0397e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.9491e-04 - val_loss: 2.5223e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.0284e-04 - val_loss: 2.0507e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.9303e-04 - val_loss: 1.8655e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.8963e-04 - val_loss: 1.6872e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.9257e-04 - val_loss: 1.8635e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.9066e-04 - val_loss: 1.9288e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.8641e-04 - val_loss: 1.6988e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.8810e-04 - val_loss: 1.9311e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7792e-04 - val_loss: 1.5140e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7798e-04 - val_loss: 2.0521e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.7629e-04 - val_loss: 1.6145e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.8947e-04 - val_loss: 1.6592e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.8277e-04 - val_loss: 2.2941e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.7621e-04 - val_loss: 2.2415e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.8184e-04 - val_loss: 2.2897e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6787e-04 - val_loss: 1.8089e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6487e-04 - val_loss: 1.8526e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.7463e-04 - val_loss: 1.9540e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.5959e-04 - val_loss: 1.7112e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6087e-04 - val_loss: 1.4620e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6018e-04 - val_loss: 1.5908e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.5486e-04 - val_loss: 1.5621e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6246e-04 - val_loss: 2.0026e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6175e-04 - val_loss: 2.0986e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5980e-04 - val_loss: 1.7459e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4773e-04 - val_loss: 1.9103e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4809e-04 - val_loss: 1.7302e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4881e-04 - val_loss: 1.7232e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4833e-04 - val_loss: 1.5805e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4326e-04 - val_loss: 1.5870e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4123e-04 - val_loss: 1.6648e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4051e-04 - val_loss: 1.7770e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3951e-04 - val_loss: 1.3694e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4293e-04 - val_loss: 1.6114e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4797e-04 - val_loss: 1.6765e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4400e-04 - val_loss: 1.4281e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3341e-04 - val_loss: 1.6838e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.2953e-04 - val_loss: 1.5768e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3232e-04 - val_loss: 1.7140e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.2427e-04 - val_loss: 1.5819e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.1994e-04 - val_loss: 1.6750e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.2064e-04 - val_loss: 1.6606e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2166e-04 - val_loss: 1.6462e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0933e-04 - val_loss: 1.4075e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.1251e-04 - val_loss: 1.4113e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0617e-04 - val_loss: 1.5619e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.1375e-04 - val_loss: 1.4386e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0328e-04 - val_loss: 1.2892e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.1072e-04 - val_loss: 1.2992e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0099e-04 - val_loss: 1.4617e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.9596e-04 - val_loss: 1.2759e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.9672e-04 - val_loss: 1.2597e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0137e-04 - val_loss: 1.2670e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0068e-04 - val_loss: 1.2470e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8996e-04 - val_loss: 1.2489e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.9190e-04 - val_loss: 1.2973e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.8869e-04 - val_loss: 1.3200e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8155e-04 - val_loss: 1.2429e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.8706e-04 - val_loss: 1.3287e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.7793e-04 - val_loss: 1.2898e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.7516e-04 - val_loss: 1.2705e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7269e-04 - val_loss: 1.2689e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.7299e-04 - val_loss: 1.3966e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.6570e-04 - val_loss: 1.2637e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7154e-04 - val_loss: 1.3991e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.6673e-04 - val_loss: 1.4733e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8190e-04 - val_loss: 1.2109e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.6409e-04 - val_loss: 1.1831e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.6016e-04 - val_loss: 1.3521e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.5045e-04 - val_loss: 1.1821e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.6106e-04 - val_loss: 1.1694e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.7520e-04 - val_loss: 1.8951e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.5657e-04 - val_loss: 1.1618e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.5255e-04 - val_loss: 1.2376e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.4848e-04 - val_loss: 1.3259e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.3864e-04 - val_loss: 1.1911e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.3677e-04 - val_loss: 1.1891e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.3814e-04 - val_loss: 1.2056e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.3279e-04 - val_loss: 1.3982e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.3433e-04 - val_loss: 1.1714e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.2960e-04 - val_loss: 1.1952e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.2702e-04 - val_loss: 1.2808e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.3163e-04 - val_loss: 1.1586e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2487e-04 - val_loss: 1.2650e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2696e-04 - val_loss: 1.2434e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.2343e-04 - val_loss: 1.1140e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.2657e-04 - val_loss: 1.2976e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1145e-04 - val_loss: 1.1271e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.0681e-04 - val_loss: 1.2653e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.0689e-04 - val_loss: 1.3767e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.0327e-04 - val_loss: 1.1501e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.0162e-04 - val_loss: 1.0896e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.0247e-04 - val_loss: 1.1300e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.9854e-04 - val_loss: 1.0769e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.9495e-04 - val_loss: 1.1215e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.9199e-04 - val_loss: 1.1951e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.8993e-04 - val_loss: 1.1782e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.9310e-04 - val_loss: 1.1299e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.9225e-04 - val_loss: 1.1044e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8903e-04 - val_loss: 1.1115e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.8185e-04 - val_loss: 1.1172e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.8106e-04 - val_loss: 1.0804e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.7673e-04 - val_loss: 1.0430e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.7156e-04 - val_loss: 1.4202e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.8444e-04 - val_loss: 1.0349e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.9815e-04 - val_loss: 1.0574e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.1095e-04 - val_loss: 1.0295e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.7223e-04 - val_loss: 1.0202e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.6770e-04 - val_loss: 1.1384e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.6341e-04 - val_loss: 1.0441e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6346e-04 - val_loss: 1.0181e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6129e-04 - val_loss: 1.0577e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6158e-04 - val_loss: 1.0271e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.5502e-04 - val_loss: 1.0367e-04\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.5666e-04 - val_loss: 1.0550e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.5878e-04 - val_loss: 1.0130e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.5731e-04 - val_loss: 1.0397e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5650e-04 - val_loss: 9.9436e-05\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.4586e-04 - val_loss: 1.0445e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.4864e-04 - val_loss: 1.0094e-04\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.5038e-04 - val_loss: 1.0273e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4197e-04 - val_loss: 9.8062e-05\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4829e-04 - val_loss: 9.7979e-05\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4537e-04 - val_loss: 9.8944e-05\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.3804e-04 - val_loss: 9.7815e-05\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.3971e-04 - val_loss: 9.7836e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.3743e-04 - val_loss: 1.2643e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.3868e-04 - val_loss: 9.7468e-05\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3358e-04 - val_loss: 9.6142e-05\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3733e-04 - val_loss: 9.5706e-05\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.4751e-04 - val_loss: 9.5473e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2561e-04 - val_loss: 9.5487e-05\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2955e-04 - val_loss: 9.5954e-05\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2854e-04 - val_loss: 9.5118e-05\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2621e-04 - val_loss: 9.5039e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2979e-04 - val_loss: 1.0069e-04\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.2624e-04 - val_loss: 9.5405e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2315e-04 - val_loss: 9.6550e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.2442e-04 - val_loss: 9.9890e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2493e-04 - val_loss: 9.4087e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.2248e-04 - val_loss: 9.3593e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.2551e-04 - val_loss: 9.5868e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.2271e-04 - val_loss: 9.6351e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.2106e-04 - val_loss: 9.8803e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2040e-04 - val_loss: 9.3167e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2262e-04 - val_loss: 9.9143e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.2436e-04 - val_loss: 9.3234e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2528e-04 - val_loss: 1.0381e-04\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0993e-04 - val_loss: 9.1674e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1306e-04 - val_loss: 9.3859e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.2009e-04 - val_loss: 9.1571e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0890e-04 - val_loss: 9.1291e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.1265e-04 - val_loss: 9.2074e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0978e-04 - val_loss: 9.2464e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.0946e-04 - val_loss: 9.2170e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0727e-04 - val_loss: 9.2419e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.1385e-04 - val_loss: 9.0206e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0777e-04 - val_loss: 9.0590e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0537e-04 - val_loss: 9.3013e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0143e-04 - val_loss: 9.0054e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0396e-04 - val_loss: 8.9543e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.1228e-04 - val_loss: 1.0479e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 3.9999e-04 - val_loss: 8.9257e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0357e-04 - val_loss: 8.9552e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0052e-04 - val_loss: 9.3713e-05\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0642e-04 - val_loss: 9.2929e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.0919e-04 - val_loss: 8.8667e-05\n",
      "Thời gian huấn luyện:  59.689687728881836\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_28 (GRU)                (None, 3, 125)            48000     \n",
      "                                                                 \n",
      " flatten_115 (Flatten)       (None, 375)               0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 1)                 376       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,376\n",
      "Trainable params: 48,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 1s 7ms/step - loss: 0.0722 - val_loss: 0.0367\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0284\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0222\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0170\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0117\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0083\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.7957e-04 - val_loss: 7.7202e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.1771e-04 - val_loss: 5.4772e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.8368e-04 - val_loss: 4.2162e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.6605e-04 - val_loss: 3.3684e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.5809e-04 - val_loss: 2.9045e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.5673e-04 - val_loss: 2.6324e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.4877e-04 - val_loss: 2.5725e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.4384e-04 - val_loss: 2.6338e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.4645e-04 - val_loss: 2.2927e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.4272e-04 - val_loss: 2.0728e-04\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step - loss: 7.3946e-04 - val_loss: 2.2817e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.3923e-04 - val_loss: 2.1997e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.3732e-04 - val_loss: 2.1326e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.3536e-04 - val_loss: 2.1166e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.3381e-04 - val_loss: 1.9962e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.3149e-04 - val_loss: 2.0480e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.3305e-04 - val_loss: 2.0329e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.2745e-04 - val_loss: 1.9680e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.2652e-04 - val_loss: 1.9613e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.2526e-04 - val_loss: 1.9536e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.2756e-04 - val_loss: 1.8743e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.2366e-04 - val_loss: 1.8482e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.2141e-04 - val_loss: 1.8942e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.2406e-04 - val_loss: 1.7469e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.1695e-04 - val_loss: 1.7826e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.1389e-04 - val_loss: 1.7618e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.1146e-04 - val_loss: 1.8248e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0965e-04 - val_loss: 1.8070e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0747e-04 - val_loss: 1.7219e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.0751e-04 - val_loss: 1.8391e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.0876e-04 - val_loss: 1.7857e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.0857e-04 - val_loss: 1.7116e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.0059e-04 - val_loss: 1.7012e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.0133e-04 - val_loss: 1.7089e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.9857e-04 - val_loss: 1.7446e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.9696e-04 - val_loss: 1.7856e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.9539e-04 - val_loss: 1.7260e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.9081e-04 - val_loss: 1.6459e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.8740e-04 - val_loss: 1.6420e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8284e-04 - val_loss: 1.6425e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8191e-04 - val_loss: 1.5843e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.8059e-04 - val_loss: 1.6293e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.7716e-04 - val_loss: 1.5810e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.7802e-04 - val_loss: 1.6005e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.7425e-04 - val_loss: 1.5541e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.7175e-04 - val_loss: 1.6402e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.7438e-04 - val_loss: 1.5315e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.6609e-04 - val_loss: 1.6541e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.6726e-04 - val_loss: 1.5339e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.6201e-04 - val_loss: 1.7002e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.6899e-04 - val_loss: 1.4911e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.6418e-04 - val_loss: 1.6602e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.5730e-04 - val_loss: 1.4787e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.4995e-04 - val_loss: 1.5814e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.5113e-04 - val_loss: 1.4669e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.5279e-04 - val_loss: 1.5570e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.4663e-04 - val_loss: 1.4571e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.4158e-04 - val_loss: 1.4698e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.4092e-04 - val_loss: 1.4635e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.4067e-04 - val_loss: 1.5379e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.3943e-04 - val_loss: 1.4531e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.3070e-04 - val_loss: 1.4532e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.2787e-04 - val_loss: 1.4702e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.2669e-04 - val_loss: 1.4149e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.2389e-04 - val_loss: 1.4162e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.2203e-04 - val_loss: 1.4083e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.1947e-04 - val_loss: 1.3837e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.2163e-04 - val_loss: 1.4936e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.1402e-04 - val_loss: 1.4034e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.1036e-04 - val_loss: 1.3762e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.0869e-04 - val_loss: 1.4070e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.0624e-04 - val_loss: 1.3426e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.0087e-04 - val_loss: 1.3393e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.0260e-04 - val_loss: 1.3776e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9410e-04 - val_loss: 1.4522e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9040e-04 - val_loss: 1.3180e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9064e-04 - val_loss: 1.3226e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9419e-04 - val_loss: 1.3049e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.8913e-04 - val_loss: 1.3048e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.8758e-04 - val_loss: 1.3197e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.7721e-04 - val_loss: 1.3780e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.8405e-04 - val_loss: 1.3049e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.7562e-04 - val_loss: 1.3453e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.7169e-04 - val_loss: 1.2688e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.6869e-04 - val_loss: 1.2704e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.6693e-04 - val_loss: 1.3316e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.6386e-04 - val_loss: 1.3274e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6302e-04 - val_loss: 1.2423e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6218e-04 - val_loss: 1.2380e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5955e-04 - val_loss: 1.2501e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5421e-04 - val_loss: 1.2563e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5171e-04 - val_loss: 1.2672e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4720e-04 - val_loss: 1.2313e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5274e-04 - val_loss: 1.3006e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4750e-04 - val_loss: 1.2057e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.4538e-04 - val_loss: 1.2431e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4120e-04 - val_loss: 1.2362e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.3813e-04 - val_loss: 1.1971e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3260e-04 - val_loss: 1.2622e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3696e-04 - val_loss: 1.2348e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.2553e-04 - val_loss: 1.1941e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.2562e-04 - val_loss: 1.1693e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2810e-04 - val_loss: 1.1675e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.2115e-04 - val_loss: 1.1570e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2371e-04 - val_loss: 1.1807e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1636e-04 - val_loss: 1.1461e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.1599e-04 - val_loss: 1.2399e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.1336e-04 - val_loss: 1.1917e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.1136e-04 - val_loss: 1.3719e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1065e-04 - val_loss: 1.1915e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.0835e-04 - val_loss: 1.1650e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.0141e-04 - val_loss: 1.1891e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0388e-04 - val_loss: 1.2422e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0016e-04 - val_loss: 1.2274e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0093e-04 - val_loss: 1.1013e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9651e-04 - val_loss: 1.1443e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9306e-04 - val_loss: 1.1944e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9222e-04 - val_loss: 1.1778e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9209e-04 - val_loss: 1.2368e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8945e-04 - val_loss: 1.2285e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8566e-04 - val_loss: 1.1254e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.8115e-04 - val_loss: 1.0918e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.8210e-04 - val_loss: 1.0783e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.8326e-04 - val_loss: 1.1472e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7977e-04 - val_loss: 1.0714e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7846e-04 - val_loss: 1.1195e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.7227e-04 - val_loss: 1.0749e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7878e-04 - val_loss: 1.0520e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7469e-04 - val_loss: 1.0574e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.6702e-04 - val_loss: 1.0635e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6501e-04 - val_loss: 1.2341e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6396e-04 - val_loss: 1.0406e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6253e-04 - val_loss: 1.1251e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6330e-04 - val_loss: 1.0597e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6494e-04 - val_loss: 1.0776e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5775e-04 - val_loss: 1.1175e-04\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.5670e-04 - val_loss: 1.0302e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.5418e-04 - val_loss: 1.0625e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.5247e-04 - val_loss: 1.1015e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5433e-04 - val_loss: 1.0223e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5228e-04 - val_loss: 1.0185e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5003e-04 - val_loss: 1.0831e-04\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4669e-04 - val_loss: 1.1378e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4599e-04 - val_loss: 1.2095e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5001e-04 - val_loss: 1.0286e-04\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4510e-04 - val_loss: 1.0290e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4830e-04 - val_loss: 1.0095e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4181e-04 - val_loss: 9.9133e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3810e-04 - val_loss: 1.0952e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3898e-04 - val_loss: 1.2482e-04\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4239e-04 - val_loss: 1.0040e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3701e-04 - val_loss: 1.0421e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3526e-04 - val_loss: 1.0598e-04\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3512e-04 - val_loss: 1.1214e-04\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3967e-04 - val_loss: 1.1087e-04\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.3296e-04 - val_loss: 1.0214e-04\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3308e-04 - val_loss: 1.1153e-04\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.3518e-04 - val_loss: 9.6425e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3045e-04 - val_loss: 1.0121e-04\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2749e-04 - val_loss: 9.8101e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2569e-04 - val_loss: 9.8696e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2899e-04 - val_loss: 1.0170e-04\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2770e-04 - val_loss: 1.2735e-04\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2777e-04 - val_loss: 9.8070e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2929e-04 - val_loss: 9.6670e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2629e-04 - val_loss: 9.8645e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2220e-04 - val_loss: 9.5468e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2160e-04 - val_loss: 1.0319e-04\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2550e-04 - val_loss: 9.6476e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1861e-04 - val_loss: 1.0053e-04\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1727e-04 - val_loss: 9.3592e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1587e-04 - val_loss: 9.4503e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1631e-04 - val_loss: 9.9301e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1379e-04 - val_loss: 9.4453e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1777e-04 - val_loss: 9.4348e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1395e-04 - val_loss: 1.0316e-04\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1423e-04 - val_loss: 9.7992e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1064e-04 - val_loss: 9.3900e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1115e-04 - val_loss: 9.2251e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0894e-04 - val_loss: 9.2814e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.0842e-04 - val_loss: 9.4774e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0704e-04 - val_loss: 9.1647e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0727e-04 - val_loss: 9.1659e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0653e-04 - val_loss: 1.0056e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.0587e-04 - val_loss: 1.0081e-04\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0741e-04 - val_loss: 9.1338e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.0544e-04 - val_loss: 1.0834e-04\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1164e-04 - val_loss: 9.3013e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.0645e-04 - val_loss: 9.4121e-05\n",
      "Thời gian huấn luyện:  28.587796449661255\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_145 (Dense)           (None, 5, 125)            250       \n",
      "                                                                 \n",
      " flatten_116 (Flatten)       (None, 625)               0         \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 1)                 626       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876\n",
      "Trainable params: 876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 3s 15ms/step - loss: 0.0641 - val_loss: 8.6312e-04\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 3.1098e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 2.5260e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 2.4535e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.3350e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.3274e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.3164e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.3043e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.2324e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.2325e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.2030e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.1331e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.1636e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 2.1147e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 2.0435e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.9196e-04 - val_loss: 2.0182e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 9.7629e-04 - val_loss: 2.0036e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 9.5593e-04 - val_loss: 1.9851e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 9.3910e-04 - val_loss: 1.9325e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.2362e-04 - val_loss: 1.9031e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.0554e-04 - val_loss: 1.8596e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.9547e-04 - val_loss: 1.8223e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.8254e-04 - val_loss: 1.8141e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.6366e-04 - val_loss: 1.7721e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.4822e-04 - val_loss: 1.7518e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.3703e-04 - val_loss: 1.8048e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.3304e-04 - val_loss: 1.7144e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.1227e-04 - val_loss: 1.7007e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.0194e-04 - val_loss: 1.6271e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.8917e-04 - val_loss: 1.6167e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.8178e-04 - val_loss: 1.6382e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.5956e-04 - val_loss: 1.5719e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.5796e-04 - val_loss: 1.5525e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4403e-04 - val_loss: 1.5545e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2711e-04 - val_loss: 1.5139e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1453e-04 - val_loss: 1.4944e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1888e-04 - val_loss: 1.5080e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9298e-04 - val_loss: 1.4688e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0719e-04 - val_loss: 1.4551e-04\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0214e-04 - val_loss: 1.5407e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.7027e-04 - val_loss: 1.4320e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6458e-04 - val_loss: 1.4091e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6342e-04 - val_loss: 1.4117e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5824e-04 - val_loss: 1.3858e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.6526e-04 - val_loss: 1.3716e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5270e-04 - val_loss: 1.3575e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.5111e-04 - val_loss: 1.3777e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4388e-04 - val_loss: 1.3425e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.4026e-04 - val_loss: 1.3180e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.1581e-04 - val_loss: 1.3179e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.2777e-04 - val_loss: 1.3577e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0666e-04 - val_loss: 1.2882e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.1658e-04 - val_loss: 1.2803e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0496e-04 - val_loss: 1.2835e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0172e-04 - val_loss: 1.3357e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1901e-04 - val_loss: 1.2427e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.8100e-04 - val_loss: 1.2438e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8056e-04 - val_loss: 1.2412e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9564e-04 - val_loss: 1.2316e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.8628e-04 - val_loss: 1.2174e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.6198e-04 - val_loss: 1.2095e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.7484e-04 - val_loss: 1.1919e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.5654e-04 - val_loss: 1.2003e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.5724e-04 - val_loss: 1.1923e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4685e-04 - val_loss: 1.1961e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4663e-04 - val_loss: 1.1698e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.5156e-04 - val_loss: 1.1751e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.4353e-04 - val_loss: 1.1473e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.6581e-04 - val_loss: 1.1397e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.4473e-04 - val_loss: 1.1359e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.3440e-04 - val_loss: 1.1256e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.2475e-04 - val_loss: 1.1137e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.2967e-04 - val_loss: 1.1146e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.1710e-04 - val_loss: 1.1004e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1086e-04 - val_loss: 1.1474e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.3083e-04 - val_loss: 1.0925e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2783e-04 - val_loss: 1.0813e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.3334e-04 - val_loss: 1.0629e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2735e-04 - val_loss: 1.0723e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1557e-04 - val_loss: 1.1093e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1100e-04 - val_loss: 1.0569e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0518e-04 - val_loss: 1.0529e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1641e-04 - val_loss: 1.0579e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.2408e-04 - val_loss: 1.1008e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.0706e-04 - val_loss: 1.0273e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9590e-04 - val_loss: 1.0418e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0110e-04 - val_loss: 1.0263e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8989e-04 - val_loss: 1.1887e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0798e-04 - val_loss: 1.0353e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7390e-04 - val_loss: 9.9899e-05\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.8649e-04 - val_loss: 1.0943e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.6944e-04 - val_loss: 1.0057e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7513e-04 - val_loss: 1.0199e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7379e-04 - val_loss: 9.7443e-05\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7406e-04 - val_loss: 1.0051e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6299e-04 - val_loss: 9.6749e-05\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7017e-04 - val_loss: 9.6379e-05\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.6783e-04 - val_loss: 9.6771e-05\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5162e-04 - val_loss: 9.8176e-05\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4729e-04 - val_loss: 9.7590e-05\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5877e-04 - val_loss: 9.6364e-05\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4571e-04 - val_loss: 9.9770e-05\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5695e-04 - val_loss: 1.0791e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.6222e-04 - val_loss: 9.7531e-05\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.6820e-04 - val_loss: 9.4937e-05\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.4434e-04 - val_loss: 9.4285e-05\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.6108e-04 - val_loss: 9.3721e-05\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.5249e-04 - val_loss: 9.4529e-05\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.5213e-04 - val_loss: 9.2106e-05\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.6366e-04 - val_loss: 9.0495e-05\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.4120e-04 - val_loss: 9.9520e-05\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.2835e-04 - val_loss: 9.0355e-05\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.3134e-04 - val_loss: 8.9315e-05\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.5062e-04 - val_loss: 9.1136e-05\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.5068e-04 - val_loss: 1.0531e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2111e-04 - val_loss: 9.1300e-05\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6840e-04 - val_loss: 9.1292e-05\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.5678e-04 - val_loss: 8.7790e-05\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.2952e-04 - val_loss: 8.9560e-05\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2852e-04 - val_loss: 9.0810e-05\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3369e-04 - val_loss: 8.8858e-05\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1481e-04 - val_loss: 9.4049e-05\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2024e-04 - val_loss: 8.6136e-05\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.1183e-04 - val_loss: 9.0536e-05\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.3782e-04 - val_loss: 8.8358e-05\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.4394e-04 - val_loss: 9.0503e-05\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2032e-04 - val_loss: 8.5022e-05\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.3103e-04 - val_loss: 8.4900e-05\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.6034e-04 - val_loss: 8.4123e-05\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9713e-04 - val_loss: 1.0285e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2684e-04 - val_loss: 8.4625e-05\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.1166e-04 - val_loss: 8.4553e-05\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.9939e-04 - val_loss: 8.3418e-05\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0819e-04 - val_loss: 8.7500e-05\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2667e-04 - val_loss: 8.3137e-05\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1158e-04 - val_loss: 8.1868e-05\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 3.9985e-04 - val_loss: 9.3489e-05\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0989e-04 - val_loss: 8.3148e-05\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1820e-04 - val_loss: 8.1239e-05\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 3.9223e-04 - val_loss: 9.3136e-05\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.2290e-04 - val_loss: 8.4681e-05\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 3.9391e-04 - val_loss: 8.6696e-05\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8872e-04 - val_loss: 8.3500e-05\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9221e-04 - val_loss: 8.1055e-05\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0396e-04 - val_loss: 8.0538e-05\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8470e-04 - val_loss: 7.9991e-05\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9054e-04 - val_loss: 8.5463e-05\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8986e-04 - val_loss: 7.9759e-05\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9261e-04 - val_loss: 8.3426e-05\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8297e-04 - val_loss: 8.2966e-05\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0331e-04 - val_loss: 7.9039e-05\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8690e-04 - val_loss: 8.4446e-05\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0351e-04 - val_loss: 8.3345e-05\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8547e-04 - val_loss: 9.1543e-05\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1253e-04 - val_loss: 7.9003e-05\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8934e-04 - val_loss: 7.8316e-05\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7902e-04 - val_loss: 8.1197e-05\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1943e-04 - val_loss: 7.7515e-05\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0858e-04 - val_loss: 8.0528e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9356e-04 - val_loss: 7.8208e-05\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.9192e-04 - val_loss: 7.8332e-05\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7840e-04 - val_loss: 8.0606e-05\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7593e-04 - val_loss: 8.0465e-05\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7672e-04 - val_loss: 7.9153e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.8461e-04 - val_loss: 7.7798e-05\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9414e-04 - val_loss: 7.6836e-05\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.8662e-04 - val_loss: 7.7751e-05\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7708e-04 - val_loss: 7.7442e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7680e-04 - val_loss: 8.0398e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7534e-04 - val_loss: 7.7390e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7760e-04 - val_loss: 7.6062e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7373e-04 - val_loss: 7.6230e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9063e-04 - val_loss: 9.9496e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7924e-04 - val_loss: 7.6331e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7235e-04 - val_loss: 7.6849e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8419e-04 - val_loss: 7.8502e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7646e-04 - val_loss: 7.5549e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0387e-04 - val_loss: 7.8090e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7713e-04 - val_loss: 8.3844e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7393e-04 - val_loss: 7.9804e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7230e-04 - val_loss: 7.9923e-05\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8759e-04 - val_loss: 7.5498e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8475e-04 - val_loss: 7.7900e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9456e-04 - val_loss: 7.6474e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7873e-04 - val_loss: 7.6253e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7006e-04 - val_loss: 8.1881e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9295e-04 - val_loss: 8.0208e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9301e-04 - val_loss: 8.4326e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7237e-04 - val_loss: 7.5301e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 3.6497e-04 - val_loss: 7.7230e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8097e-04 - val_loss: 7.7708e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7821e-04 - val_loss: 8.3090e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7986e-04 - val_loss: 1.0585e-04\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.9138e-04 - val_loss: 7.4761e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.6656e-04 - val_loss: 7.5454e-05\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7303e-04 - val_loss: 7.4749e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7977e-04 - val_loss: 7.7771e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7189e-04 - val_loss: 7.6400e-05\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.9238e-04 - val_loss: 7.6500e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7307e-04 - val_loss: 7.6624e-05\n",
      "Thời gian huấn luyện:  49.69938349723816\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_29 (SimpleRNN)   (None, 5, 125)            15875     \n",
      "                                                                 \n",
      " flatten_117 (Flatten)       (None, 625)               0         \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 1)                 626       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,501\n",
      "Trainable params: 16,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 4s 17ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Thời gian huấn luyện:  75.19581723213196\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_29 (LSTM)              (None, 5, 125)            63500     \n",
      "                                                                 \n",
      " flatten_118 (Flatten)       (None, 625)               0         \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 1)                 626       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,126\n",
      "Trainable params: 64,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 4s 16ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1994 - val_loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1994 - val_loss: 0.0094\n",
      "Thời gian huấn luyện:  68.50012016296387\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_29 (GRU)                (None, 5, 125)            48000     \n",
      "                                                                 \n",
      " flatten_119 (Flatten)       (None, 625)               0         \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1)                 626       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,626\n",
      "Trainable params: 48,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 1s 5ms/step - loss: 0.0515 - val_loss: 0.0288\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0161\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0105\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 7.1832e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 6.2798e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.6300e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 4.3120e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 3.3853e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 3.3630e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 3.2320e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 3.2715e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.0812e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.1565e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 3.2636e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 2.8711e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.0786e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 2.8435e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 2.7866e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 2.8496e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 2.6737e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 2.4941e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 2.7825e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.5166e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.5764e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.3871e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.4212e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.5856e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.5097e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.4147e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.1975e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.4316e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.3447e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.4313e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.5083e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.2865e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.1674e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.1299e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.2912e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.1743e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.0535e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.1333e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.0288e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.0981e-04\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.1855e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.9933e-04 - val_loss: 1.9744e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.9346e-04 - val_loss: 2.0011e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.7845e-04 - val_loss: 1.8938e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.6523e-04 - val_loss: 1.8733e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.5849e-04 - val_loss: 2.1888e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.4250e-04 - val_loss: 1.8248e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.3295e-04 - val_loss: 1.8304e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.1811e-04 - val_loss: 1.7579e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.0994e-04 - val_loss: 1.7351e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.0149e-04 - val_loss: 1.7761e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.8924e-04 - val_loss: 1.7502e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.8375e-04 - val_loss: 1.8606e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.7022e-04 - val_loss: 1.8802e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.6248e-04 - val_loss: 1.8017e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.4349e-04 - val_loss: 1.6823e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.3405e-04 - val_loss: 1.7592e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.2724e-04 - val_loss: 1.6631e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.2279e-04 - val_loss: 1.6587e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.0707e-04 - val_loss: 1.6449e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.9853e-04 - val_loss: 1.5691e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.9627e-04 - val_loss: 1.7273e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.8206e-04 - val_loss: 1.6213e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.7066e-04 - val_loss: 1.6298e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.5859e-04 - val_loss: 1.6298e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.5316e-04 - val_loss: 1.6387e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.3705e-04 - val_loss: 1.4836e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.3652e-04 - val_loss: 1.4762e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.3071e-04 - val_loss: 1.5775e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.1651e-04 - val_loss: 1.4570e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.1361e-04 - val_loss: 1.4458e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.0473e-04 - val_loss: 1.4941e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.9636e-04 - val_loss: 1.4773e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.8716e-04 - val_loss: 1.4396e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.7801e-04 - val_loss: 1.4726e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.7031e-04 - val_loss: 1.3858e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.6295e-04 - val_loss: 1.3988e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.5744e-04 - val_loss: 1.5263e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.5066e-04 - val_loss: 1.5562e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.4269e-04 - val_loss: 1.3495e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.3894e-04 - val_loss: 1.4100e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.3315e-04 - val_loss: 1.3813e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.2547e-04 - val_loss: 1.3692e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.2268e-04 - val_loss: 1.3208e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.1241e-04 - val_loss: 1.4115e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.1271e-04 - val_loss: 1.2961e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.1449e-04 - val_loss: 1.4504e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9995e-04 - val_loss: 1.4326e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9491e-04 - val_loss: 1.3678e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9590e-04 - val_loss: 1.3021e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.8618e-04 - val_loss: 1.3570e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.8357e-04 - val_loss: 1.3543e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7525e-04 - val_loss: 1.4872e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7109e-04 - val_loss: 1.3100e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6841e-04 - val_loss: 1.3620e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7242e-04 - val_loss: 1.5701e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6188e-04 - val_loss: 1.2527e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6034e-04 - val_loss: 1.2682e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5885e-04 - val_loss: 1.3443e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5119e-04 - val_loss: 1.2614e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4460e-04 - val_loss: 1.3252e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4268e-04 - val_loss: 1.2856e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3793e-04 - val_loss: 1.3626e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3370e-04 - val_loss: 1.2867e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3327e-04 - val_loss: 1.2622e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3853e-04 - val_loss: 1.2796e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2630e-04 - val_loss: 1.1958e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2493e-04 - val_loss: 1.2362e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2293e-04 - val_loss: 1.2685e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1828e-04 - val_loss: 1.1920e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1782e-04 - val_loss: 1.2975e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2133e-04 - val_loss: 1.3573e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2442e-04 - val_loss: 1.2393e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1581e-04 - val_loss: 1.1601e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1879e-04 - val_loss: 1.2169e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2334e-04 - val_loss: 1.1697e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0580e-04 - val_loss: 1.2454e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0872e-04 - val_loss: 1.2969e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0744e-04 - val_loss: 1.1558e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0383e-04 - val_loss: 1.2237e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1500e-04 - val_loss: 1.1799e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0661e-04 - val_loss: 1.1472e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9354e-04 - val_loss: 1.2249e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9399e-04 - val_loss: 1.2074e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9261e-04 - val_loss: 1.1486e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9823e-04 - val_loss: 1.1579e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8901e-04 - val_loss: 1.2411e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8530e-04 - val_loss: 1.1422e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8399e-04 - val_loss: 1.1876e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8435e-04 - val_loss: 1.1647e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8466e-04 - val_loss: 1.1564e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8437e-04 - val_loss: 1.1150e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8495e-04 - val_loss: 1.1529e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8361e-04 - val_loss: 1.1122e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8064e-04 - val_loss: 1.1682e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7574e-04 - val_loss: 1.1385e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7405e-04 - val_loss: 1.3347e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7651e-04 - val_loss: 1.1322e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7355e-04 - val_loss: 1.1339e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7422e-04 - val_loss: 1.1929e-04\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6958e-04 - val_loss: 1.1047e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7444e-04 - val_loss: 1.1313e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6783e-04 - val_loss: 1.2148e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6513e-04 - val_loss: 1.1607e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6627e-04 - val_loss: 1.2531e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6542e-04 - val_loss: 1.0884e-04\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6400e-04 - val_loss: 1.1814e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6495e-04 - val_loss: 1.1198e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6099e-04 - val_loss: 1.0823e-04\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6124e-04 - val_loss: 1.2723e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6129e-04 - val_loss: 1.0784e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6195e-04 - val_loss: 1.0828e-04\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6494e-04 - val_loss: 1.0747e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6101e-04 - val_loss: 1.0718e-04\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5212e-04 - val_loss: 1.2385e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5423e-04 - val_loss: 1.1729e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6247e-04 - val_loss: 1.0811e-04\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5483e-04 - val_loss: 1.2333e-04\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5273e-04 - val_loss: 1.2244e-04\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5046e-04 - val_loss: 1.0813e-04\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4905e-04 - val_loss: 1.0678e-04\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5196e-04 - val_loss: 1.0711e-04\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4502e-04 - val_loss: 1.0525e-04\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5759e-04 - val_loss: 1.0929e-04\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4295e-04 - val_loss: 1.0602e-04\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4504e-04 - val_loss: 1.0624e-04\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4975e-04 - val_loss: 1.0888e-04\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5161e-04 - val_loss: 1.1239e-04\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4500e-04 - val_loss: 1.0697e-04\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4279e-04 - val_loss: 1.2693e-04\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5112e-04 - val_loss: 1.0811e-04\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4166e-04 - val_loss: 1.2354e-04\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4692e-04 - val_loss: 1.0408e-04\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3784e-04 - val_loss: 1.0594e-04\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3993e-04 - val_loss: 1.0756e-04\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3551e-04 - val_loss: 1.0839e-04\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3982e-04 - val_loss: 1.0939e-04\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4329e-04 - val_loss: 1.0397e-04\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4068e-04 - val_loss: 1.0339e-04\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3320e-04 - val_loss: 1.0945e-04\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3477e-04 - val_loss: 1.0985e-04\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3756e-04 - val_loss: 1.0803e-04\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3587e-04 - val_loss: 1.1727e-04\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3989e-04 - val_loss: 1.2126e-04\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3843e-04 - val_loss: 1.1339e-04\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2831e-04 - val_loss: 1.2554e-04\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3504e-04 - val_loss: 1.0723e-04\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3288e-04 - val_loss: 1.1881e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2785e-04 - val_loss: 1.0334e-04\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2857e-04 - val_loss: 1.0146e-04\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3743e-04 - val_loss: 1.1388e-04\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2411e-04 - val_loss: 1.0278e-04\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2795e-04 - val_loss: 1.0915e-04\n",
      "Thời gian huấn luyện:  21.85492491722107\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_150 (Dense)           (None, 10, 125)           250       \n",
      "                                                                 \n",
      " flatten_120 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,501\n",
      "Trainable params: 1,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 892us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 1s 8ms/step - loss: 0.0119 - val_loss: 3.5244e-04\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 3.4945e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 2.8538e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.2808e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.0385e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 1.9814e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.3505e-04 - val_loss: 1.8239e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.9881e-04 - val_loss: 1.7595e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.6313e-04 - val_loss: 1.7218e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.3174e-04 - val_loss: 1.7068e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 9.0770e-04 - val_loss: 1.6986e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.0180e-04 - val_loss: 1.6411e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.9058e-04 - val_loss: 1.6464e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.2853e-04 - val_loss: 1.6283e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.7435e-04 - val_loss: 1.8585e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.1698e-04 - val_loss: 1.6085e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3905e-04 - val_loss: 1.7553e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4661e-04 - val_loss: 1.5367e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3066e-04 - val_loss: 1.5856e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1442e-04 - val_loss: 1.5949e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0404e-04 - val_loss: 1.4994e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0817e-04 - val_loss: 1.5090e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0607e-04 - val_loss: 1.7446e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1575e-04 - val_loss: 1.7368e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0875e-04 - val_loss: 1.4619e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2103e-04 - val_loss: 1.4134e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6499e-04 - val_loss: 1.3881e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6140e-04 - val_loss: 1.4246e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4578e-04 - val_loss: 1.3984e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8129e-04 - val_loss: 1.5149e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3351e-04 - val_loss: 1.4559e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2268e-04 - val_loss: 1.4488e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7406e-04 - val_loss: 1.3710e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1958e-04 - val_loss: 1.3189e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2327e-04 - val_loss: 1.3924e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4544e-04 - val_loss: 1.3245e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0272e-04 - val_loss: 1.3009e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0205e-04 - val_loss: 1.3262e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7823e-04 - val_loss: 1.4429e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9956e-04 - val_loss: 1.2645e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0100e-04 - val_loss: 1.2586e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8029e-04 - val_loss: 1.2407e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9575e-04 - val_loss: 1.2282e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7381e-04 - val_loss: 1.2194e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7008e-04 - val_loss: 1.2083e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1772e-04 - val_loss: 1.2164e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.5915e-04 - val_loss: 1.2200e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4661e-04 - val_loss: 1.2112e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.5091e-04 - val_loss: 1.2948e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.6913e-04 - val_loss: 1.1755e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.6249e-04 - val_loss: 1.2189e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2560e-04 - val_loss: 1.1529e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7038e-04 - val_loss: 1.2294e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4426e-04 - val_loss: 1.1334e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.2796e-04 - val_loss: 1.1233e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.3410e-04 - val_loss: 1.2375e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.6885e-04 - val_loss: 1.1390e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4079e-04 - val_loss: 1.1776e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1791e-04 - val_loss: 1.1097e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1117e-04 - val_loss: 1.1065e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1988e-04 - val_loss: 1.0935e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.3503e-04 - val_loss: 1.1072e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9596e-04 - val_loss: 1.1022e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9061e-04 - val_loss: 1.0853e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8684e-04 - val_loss: 1.0932e-04\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0616e-04 - val_loss: 1.0654e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1653e-04 - val_loss: 1.0472e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0809e-04 - val_loss: 1.0582e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2490e-04 - val_loss: 1.0343e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.9162e-04 - val_loss: 1.0545e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2574e-04 - val_loss: 1.1237e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9943e-04 - val_loss: 1.0296e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7747e-04 - val_loss: 1.0299e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9070e-04 - val_loss: 1.0096e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6244e-04 - val_loss: 1.0041e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6109e-04 - val_loss: 1.0006e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5497e-04 - val_loss: 1.0209e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6989e-04 - val_loss: 1.0035e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7484e-04 - val_loss: 1.0017e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7956e-04 - val_loss: 9.7367e-05\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7118e-04 - val_loss: 1.0074e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7360e-04 - val_loss: 1.0051e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6873e-04 - val_loss: 9.7947e-05\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6728e-04 - val_loss: 9.7051e-05\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6082e-04 - val_loss: 1.0429e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1833e-04 - val_loss: 9.4548e-05\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7243e-04 - val_loss: 9.4176e-05\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7214e-04 - val_loss: 1.0138e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4697e-04 - val_loss: 9.2982e-05\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4667e-04 - val_loss: 9.4395e-05\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9309e-04 - val_loss: 9.2819e-05\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5600e-04 - val_loss: 9.4197e-05\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4348e-04 - val_loss: 9.2083e-05\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3680e-04 - val_loss: 9.3168e-05\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3962e-04 - val_loss: 9.2741e-05\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3804e-04 - val_loss: 9.1137e-05\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2687e-04 - val_loss: 9.4594e-05\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1781e-04 - val_loss: 9.3215e-05\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.4237e-04 - val_loss: 9.1262e-05\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2218e-04 - val_loss: 9.4945e-05\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4279e-04 - val_loss: 9.3717e-05\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3244e-04 - val_loss: 8.9932e-05\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3129e-04 - val_loss: 8.8560e-05\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4128e-04 - val_loss: 9.2555e-05\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2967e-04 - val_loss: 9.1727e-05\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1704e-04 - val_loss: 8.8995e-05\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0709e-04 - val_loss: 8.9191e-05\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.3267e-04 - val_loss: 8.7381e-05\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2985e-04 - val_loss: 8.7586e-05\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0484e-04 - val_loss: 9.1343e-05\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0657e-04 - val_loss: 8.6985e-05\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3586e-04 - val_loss: 8.6263e-05\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1475e-04 - val_loss: 8.5762e-05\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0879e-04 - val_loss: 8.5611e-05\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3084e-04 - val_loss: 8.5619e-05\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.3267e-04 - val_loss: 8.6056e-05\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0516e-04 - val_loss: 8.5167e-05\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0596e-04 - val_loss: 8.4811e-05\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1215e-04 - val_loss: 8.6274e-05\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1690e-04 - val_loss: 8.4683e-05\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.1530e-04 - val_loss: 8.4035e-05\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0092e-04 - val_loss: 8.4880e-05\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9346e-04 - val_loss: 8.6263e-05\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9683e-04 - val_loss: 8.6064e-05\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1731e-04 - val_loss: 8.4243e-05\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0597e-04 - val_loss: 8.3558e-05\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.1193e-04 - val_loss: 8.2755e-05\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.9031e-04 - val_loss: 8.3403e-05\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8568e-04 - val_loss: 8.7873e-05\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0422e-04 - val_loss: 8.2183e-05\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1824e-04 - val_loss: 8.1442e-05\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8596e-04 - val_loss: 9.5254e-05\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.9762e-04 - val_loss: 8.2809e-05\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1996e-04 - val_loss: 8.1472e-05\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.9202e-04 - val_loss: 8.5401e-05\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9452e-04 - val_loss: 8.9718e-05\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1370e-04 - val_loss: 8.0935e-05\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1748e-04 - val_loss: 8.1409e-05\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9511e-04 - val_loss: 8.1502e-05\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8786e-04 - val_loss: 8.4003e-05\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.8697e-04 - val_loss: 8.1199e-05\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9152e-04 - val_loss: 9.4507e-05\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0215e-04 - val_loss: 8.2865e-05\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9652e-04 - val_loss: 8.0622e-05\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9244e-04 - val_loss: 8.0563e-05\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8090e-04 - val_loss: 8.1112e-05\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9209e-04 - val_loss: 8.1279e-05\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7408e-04 - val_loss: 8.2400e-05\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0009e-04 - val_loss: 8.0884e-05\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.8329e-04 - val_loss: 7.9640e-05\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7889e-04 - val_loss: 7.9953e-05\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7795e-04 - val_loss: 7.9966e-05\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9257e-04 - val_loss: 8.5786e-05\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8764e-04 - val_loss: 8.2334e-05\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7365e-04 - val_loss: 7.9634e-05\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9327e-04 - val_loss: 7.9374e-05\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.8900e-04 - val_loss: 7.9224e-05\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6972e-04 - val_loss: 7.9083e-05\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7945e-04 - val_loss: 8.4545e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7854e-04 - val_loss: 7.9812e-05\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6978e-04 - val_loss: 9.4853e-05\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8597e-04 - val_loss: 8.2002e-05\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.8364e-04 - val_loss: 9.8508e-05\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8147e-04 - val_loss: 8.7688e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7512e-04 - val_loss: 7.8501e-05\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8935e-04 - val_loss: 7.7930e-05\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8122e-04 - val_loss: 7.8989e-05\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7172e-04 - val_loss: 7.8661e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.8310e-04 - val_loss: 7.7876e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0350e-04 - val_loss: 8.0105e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8876e-04 - val_loss: 7.8289e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8196e-04 - val_loss: 8.0859e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6979e-04 - val_loss: 7.7947e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0077e-04 - val_loss: 7.7977e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6427e-04 - val_loss: 7.8044e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6692e-04 - val_loss: 7.8729e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.8153e-04 - val_loss: 7.7327e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6900e-04 - val_loss: 8.1607e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9336e-04 - val_loss: 7.7411e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7052e-04 - val_loss: 8.0650e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6828e-04 - val_loss: 8.7238e-05\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7507e-04 - val_loss: 7.6834e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.6522e-04 - val_loss: 8.1230e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7411e-04 - val_loss: 7.7551e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7186e-04 - val_loss: 8.3551e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6315e-04 - val_loss: 7.7263e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7118e-04 - val_loss: 7.8851e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6896e-04 - val_loss: 7.7664e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6672e-04 - val_loss: 7.7361e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7064e-04 - val_loss: 7.6786e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.6512e-04 - val_loss: 8.0655e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.6779e-04 - val_loss: 7.6210e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7820e-04 - val_loss: 7.6881e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7274e-04 - val_loss: 7.7207e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.5830e-04 - val_loss: 8.6545e-05\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.8278e-04 - val_loss: 7.6597e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.6805e-04 - val_loss: 7.5970e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7134e-04 - val_loss: 7.6720e-05\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6990e-04 - val_loss: 8.0545e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7357e-04 - val_loss: 8.2605e-05\n",
      "Thời gian huấn luyện:  46.952919244766235\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_30 (SimpleRNN)   (None, 10, 125)           15875     \n",
      "                                                                 \n",
      " flatten_121 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,126\n",
      "Trainable params: 17,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 4s 22ms/step - loss: 0.0516 - val_loss: 0.0037\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 5.1937e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 4.0789e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 4.2559e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 3.7396e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 3.8212e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 4.3689e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 4.2343e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 4.2127e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 4.1508e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 3.6807e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 4.4926e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 4.0492e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 4.0978e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 4.1141e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 3.4273e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 3.3002e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0015 - val_loss: 3.4199e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 3.9920e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 3.3975e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 4.0634e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 2.9347e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 3.6665e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 2.5317e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 3.5101e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 2.8129e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 3.0878e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 2.6514e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.8171e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.6744e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 2.8356e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.4580e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.6051e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.4290e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.4902e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.3090e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.5301e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.1290e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.3204e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.2240e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 2.1275e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 2.2435e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.0874e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 2.1316e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 2.2850e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 2.1075e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.6485e-04 - val_loss: 2.0938e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.6857e-04 - val_loss: 2.0579e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.4838e-04 - val_loss: 2.1679e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.9863e-04 - val_loss: 2.3359e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.5761e-04 - val_loss: 2.0161e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.8610e-04 - val_loss: 2.0336e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.5327e-04 - val_loss: 1.9997e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.3055e-04 - val_loss: 2.0029e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.3435e-04 - val_loss: 1.9587e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.4702e-04 - val_loss: 1.9945e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.2211e-04 - val_loss: 1.9725e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.2101e-04 - val_loss: 1.9861e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.0087e-04 - val_loss: 1.9444e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.3757e-04 - val_loss: 1.9650e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.8959e-04 - val_loss: 1.9992e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.8666e-04 - val_loss: 1.9296e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.8545e-04 - val_loss: 1.9151e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.7595e-04 - val_loss: 1.9710e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.6902e-04 - val_loss: 1.9034e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.8598e-04 - val_loss: 2.0086e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.8898e-04 - val_loss: 1.9952e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.5427e-04 - val_loss: 1.8677e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 8.8711e-04 - val_loss: 1.8957e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.4723e-04 - val_loss: 1.8773e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.5698e-04 - val_loss: 2.0159e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.5185e-04 - val_loss: 1.9300e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.3494e-04 - val_loss: 1.8968e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.4863e-04 - val_loss: 1.8276e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.3513e-04 - val_loss: 1.8151e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.3121e-04 - val_loss: 1.8285e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.1862e-04 - val_loss: 1.8599e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.2093e-04 - val_loss: 1.8902e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.1465e-04 - val_loss: 1.9386e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.2616e-04 - val_loss: 1.8186e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.9854e-04 - val_loss: 1.7722e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.0813e-04 - val_loss: 1.9532e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 8.0854e-04 - val_loss: 1.7601e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.1219e-04 - val_loss: 1.7779e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.3350e-04 - val_loss: 1.7973e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.1501e-04 - val_loss: 2.0139e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.7934e-04 - val_loss: 1.9249e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.9029e-04 - val_loss: 1.8953e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.8149e-04 - val_loss: 1.7420e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.7695e-04 - val_loss: 1.7367e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.6161e-04 - val_loss: 2.0230e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.8405e-04 - val_loss: 1.7184e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.9203e-04 - val_loss: 1.9173e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.5598e-04 - val_loss: 1.7817e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.5623e-04 - val_loss: 1.7853e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 7.4501e-04 - val_loss: 1.6800e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.7319e-04 - val_loss: 1.6956e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.5768e-04 - val_loss: 1.8381e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.4417e-04 - val_loss: 1.7961e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.5465e-04 - val_loss: 1.8268e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.3755e-04 - val_loss: 1.6959e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.2026e-04 - val_loss: 1.6664e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.1978e-04 - val_loss: 1.7946e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.1230e-04 - val_loss: 1.7495e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.2756e-04 - val_loss: 1.6899e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.2213e-04 - val_loss: 1.8128e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.1835e-04 - val_loss: 1.6091e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.9969e-04 - val_loss: 1.7352e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.1139e-04 - val_loss: 1.9197e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.9527e-04 - val_loss: 1.7433e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.9976e-04 - val_loss: 1.6052e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.0555e-04 - val_loss: 1.9246e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.1087e-04 - val_loss: 1.6057e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.8011e-04 - val_loss: 1.7831e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.9047e-04 - val_loss: 1.6681e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.7002e-04 - val_loss: 1.5394e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.7676e-04 - val_loss: 1.6148e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.6481e-04 - val_loss: 1.5752e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.8980e-04 - val_loss: 1.7494e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.8269e-04 - val_loss: 1.6475e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.6689e-04 - val_loss: 1.6477e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.7780e-04 - val_loss: 1.8780e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.5876e-04 - val_loss: 1.4889e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.7921e-04 - val_loss: 1.5332e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.4544e-04 - val_loss: 1.6042e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.8876e-04 - val_loss: 1.7570e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.6732e-04 - val_loss: 1.5233e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.3814e-04 - val_loss: 1.4818e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.3747e-04 - val_loss: 1.6420e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.6237e-04 - val_loss: 1.6880e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.3956e-04 - val_loss: 1.4746e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.2899e-04 - val_loss: 1.5407e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.3325e-04 - val_loss: 1.5778e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.6477e-04 - val_loss: 1.5716e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.3651e-04 - val_loss: 1.4870e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.1788e-04 - val_loss: 1.4626e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.1427e-04 - val_loss: 1.4376e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.1538e-04 - val_loss: 1.4089e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.1050e-04 - val_loss: 1.5179e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.1513e-04 - val_loss: 1.6444e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.0135e-04 - val_loss: 1.5814e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.9825e-04 - val_loss: 1.4674e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.3072e-04 - val_loss: 1.4011e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.9940e-04 - val_loss: 1.4189e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.0248e-04 - val_loss: 1.5254e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.8585e-04 - val_loss: 1.4362e-04\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.8369e-04 - val_loss: 1.7016e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.4592e-04 - val_loss: 1.4897e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.3470e-04 - val_loss: 1.7203e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.8272e-04 - val_loss: 1.4295e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.8187e-04 - val_loss: 1.3467e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.9627e-04 - val_loss: 1.5864e-04\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.7340e-04 - val_loss: 1.3394e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.8370e-04 - val_loss: 1.3377e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.9809e-04 - val_loss: 1.4627e-04\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.7152e-04 - val_loss: 1.5194e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.6662e-04 - val_loss: 1.4144e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.6604e-04 - val_loss: 1.4487e-04\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 9ms/step - loss: 5.6393e-04 - val_loss: 1.3878e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.5195e-04 - val_loss: 1.4592e-04\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.4011e-04 - val_loss: 1.4138e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.4976e-04 - val_loss: 1.5065e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.5321e-04 - val_loss: 1.3066e-04\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.6331e-04 - val_loss: 1.5304e-04\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.6962e-04 - val_loss: 1.4340e-04\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3911e-04 - val_loss: 1.2819e-04\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.4043e-04 - val_loss: 1.4125e-04\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2577e-04 - val_loss: 1.2543e-04\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.4760e-04 - val_loss: 1.6878e-04\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2960e-04 - val_loss: 1.3187e-04\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.3125e-04 - val_loss: 1.2726e-04\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.3591e-04 - val_loss: 1.2445e-04\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.5872e-04 - val_loss: 1.2569e-04\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2951e-04 - val_loss: 1.4914e-04\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.2028e-04 - val_loss: 1.4422e-04\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.1357e-04 - val_loss: 1.3436e-04\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1341e-04 - val_loss: 1.2777e-04\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1619e-04 - val_loss: 1.3930e-04\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.1683e-04 - val_loss: 1.2290e-04\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1182e-04 - val_loss: 1.3320e-04\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2546e-04 - val_loss: 1.4773e-04\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.1407e-04 - val_loss: 1.3764e-04\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.0561e-04 - val_loss: 1.2431e-04\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.0106e-04 - val_loss: 1.4176e-04\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2106e-04 - val_loss: 1.2725e-04\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.9216e-04 - val_loss: 1.2543e-04\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.9949e-04 - val_loss: 1.1983e-04\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8047e-04 - val_loss: 1.2603e-04\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.8408e-04 - val_loss: 1.3165e-04\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8872e-04 - val_loss: 1.1789e-04\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.9520e-04 - val_loss: 1.1838e-04\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8756e-04 - val_loss: 1.4357e-04\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.9616e-04 - val_loss: 1.1762e-04\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2035e-04 - val_loss: 1.4779e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.9213e-04 - val_loss: 1.2176e-04\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7062e-04 - val_loss: 1.1869e-04\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7881e-04 - val_loss: 1.1343e-04\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8236e-04 - val_loss: 1.1634e-04\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.6936e-04 - val_loss: 1.2083e-04\n",
      "Thời gian huấn luyện:  99.78106212615967\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_30 (LSTM)              (None, 10, 125)           63500     \n",
      "                                                                 \n",
      " flatten_122 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,751\n",
      "Trainable params: 64,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 3s 16ms/step - loss: 0.0218 - val_loss: 0.0021\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 4.1654e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 3.0539e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 2.7289e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 2.9183e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 2.6289e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0014 - val_loss: 2.5532e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 0.0014 - val_loss: 2.5935e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 2.5935e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0013 - val_loss: 2.3776e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 2.3511e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.2319e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 2.3089e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.2335e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.1804e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.3499e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.2846e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.1387e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.4098e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.1355e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 1.9845e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 1.9326e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.9771e-04 - val_loss: 1.8996e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.7713e-04 - val_loss: 1.9722e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.5169e-04 - val_loss: 1.8637e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 9.2713e-04 - val_loss: 1.8366e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 9.1353e-04 - val_loss: 1.9830e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.9820e-04 - val_loss: 1.8006e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.6440e-04 - val_loss: 1.8574e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.5129e-04 - val_loss: 1.8007e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.5615e-04 - val_loss: 1.7851e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.2136e-04 - val_loss: 1.7930e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.2704e-04 - val_loss: 1.9901e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.0672e-04 - val_loss: 1.7601e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.8775e-04 - val_loss: 1.7535e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.8431e-04 - val_loss: 1.7278e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.8480e-04 - val_loss: 1.7096e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.5985e-04 - val_loss: 1.7049e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.4939e-04 - val_loss: 1.7547e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.7952e-04 - val_loss: 1.7144e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.3879e-04 - val_loss: 1.6895e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.1961e-04 - val_loss: 1.7317e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.1874e-04 - val_loss: 1.6496e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.1912e-04 - val_loss: 1.7603e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.0786e-04 - val_loss: 1.6787e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.0339e-04 - val_loss: 1.6763e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.9933e-04 - val_loss: 1.6921e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.0389e-04 - val_loss: 1.7593e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.9495e-04 - val_loss: 1.6524e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.7765e-04 - val_loss: 1.7407e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.7723e-04 - val_loss: 1.7296e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.7439e-04 - val_loss: 1.5980e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.8409e-04 - val_loss: 1.5841e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.6513e-04 - val_loss: 1.5824e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.7517e-04 - val_loss: 1.5528e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.5023e-04 - val_loss: 1.5321e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.4852e-04 - val_loss: 1.5333e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.4662e-04 - val_loss: 1.5358e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.5294e-04 - val_loss: 1.5655e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.3554e-04 - val_loss: 1.5993e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.2532e-04 - val_loss: 1.5128e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.3084e-04 - val_loss: 1.5743e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.2202e-04 - val_loss: 1.4679e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.2313e-04 - val_loss: 1.5309e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.1344e-04 - val_loss: 1.5068e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.2724e-04 - val_loss: 1.4832e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.1300e-04 - val_loss: 1.4516e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.9888e-04 - val_loss: 1.4395e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.0956e-04 - val_loss: 1.5576e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.9295e-04 - val_loss: 1.4051e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.0723e-04 - val_loss: 1.5571e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.9056e-04 - val_loss: 1.5039e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.9049e-04 - val_loss: 1.3867e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.7494e-04 - val_loss: 1.5133e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.7344e-04 - val_loss: 1.4071e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.6788e-04 - val_loss: 1.3806e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 5.9778e-04 - val_loss: 1.3545e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 5.6719e-04 - val_loss: 1.3569e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.6301e-04 - val_loss: 1.3359e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.7973e-04 - val_loss: 1.3612e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.5592e-04 - val_loss: 1.3320e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.5540e-04 - val_loss: 1.3629e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.5697e-04 - val_loss: 1.3282e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.9991e-04 - val_loss: 1.3408e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.4093e-04 - val_loss: 1.3078e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.4315e-04 - val_loss: 1.2804e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.4580e-04 - val_loss: 1.2982e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3754e-04 - val_loss: 1.4459e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.4976e-04 - val_loss: 1.2978e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.4660e-04 - val_loss: 1.3058e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.2827e-04 - val_loss: 1.2676e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2287e-04 - val_loss: 1.2454e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2543e-04 - val_loss: 1.3010e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1699e-04 - val_loss: 1.2421e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.2453e-04 - val_loss: 1.4684e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.1320e-04 - val_loss: 1.3283e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.1564e-04 - val_loss: 1.2174e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1498e-04 - val_loss: 1.2089e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.0813e-04 - val_loss: 1.2001e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.0563e-04 - val_loss: 1.1939e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.2097e-04 - val_loss: 1.4263e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.3403e-04 - val_loss: 1.1813e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.9721e-04 - val_loss: 1.2148e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 5.0064e-04 - val_loss: 1.2397e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.9758e-04 - val_loss: 1.1793e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.9708e-04 - val_loss: 1.1692e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8581e-04 - val_loss: 1.1674e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 4.8009e-04 - val_loss: 1.1605e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8815e-04 - val_loss: 1.2627e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7914e-04 - val_loss: 1.1466e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7903e-04 - val_loss: 1.1725e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8099e-04 - val_loss: 1.1995e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 4.8231e-04 - val_loss: 1.1303e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.7492e-04 - val_loss: 1.1184e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 4.8627e-04 - val_loss: 1.2925e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8476e-04 - val_loss: 1.1705e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.6367e-04 - val_loss: 1.1105e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.8210e-04 - val_loss: 1.1370e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.6810e-04 - val_loss: 1.1005e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.6707e-04 - val_loss: 1.1173e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.6146e-04 - val_loss: 1.1180e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5492e-04 - val_loss: 1.1225e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.6241e-04 - val_loss: 1.0855e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5903e-04 - val_loss: 1.0800e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.5685e-04 - val_loss: 1.1130e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.6191e-04 - val_loss: 1.0728e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.4542e-04 - val_loss: 1.1047e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.6726e-04 - val_loss: 1.1308e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.4964e-04 - val_loss: 1.0553e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.4837e-04 - val_loss: 1.0982e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.4258e-04 - val_loss: 1.0689e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.5370e-04 - val_loss: 1.1131e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3388e-04 - val_loss: 1.0762e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.5429e-04 - val_loss: 1.1024e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.4616e-04 - val_loss: 1.0612e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5615e-04 - val_loss: 1.0259e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7808e-04 - val_loss: 1.2271e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.4637e-04 - val_loss: 1.0531e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3343e-04 - val_loss: 1.0392e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.3506e-04 - val_loss: 1.0098e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3119e-04 - val_loss: 1.0013e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.4101e-04 - val_loss: 1.1106e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3762e-04 - val_loss: 1.0135e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3221e-04 - val_loss: 1.0085e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2879e-04 - val_loss: 1.0161e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3254e-04 - val_loss: 1.0020e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1662e-04 - val_loss: 9.9755e-05\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1490e-04 - val_loss: 1.0049e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2435e-04 - val_loss: 9.8557e-05\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1112e-04 - val_loss: 1.0067e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2193e-04 - val_loss: 9.8765e-05\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2443e-04 - val_loss: 9.9302e-05\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0887e-04 - val_loss: 9.8257e-05\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1003e-04 - val_loss: 9.6542e-05\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2605e-04 - val_loss: 1.0762e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1144e-04 - val_loss: 1.1522e-04\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2014e-04 - val_loss: 1.0920e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2306e-04 - val_loss: 1.1447e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1640e-04 - val_loss: 9.9230e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0386e-04 - val_loss: 1.0023e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1220e-04 - val_loss: 9.5430e-05\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2847e-04 - val_loss: 9.8497e-05\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0086e-04 - val_loss: 9.9861e-05\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1779e-04 - val_loss: 9.4072e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0373e-04 - val_loss: 9.4375e-05\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9599e-04 - val_loss: 9.3245e-05\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.0070e-04 - val_loss: 9.8815e-05\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.0235e-04 - val_loss: 9.3674e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.0460e-04 - val_loss: 9.2950e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9963e-04 - val_loss: 9.3470e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.0766e-04 - val_loss: 9.3789e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1241e-04 - val_loss: 9.7719e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9190e-04 - val_loss: 9.1054e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9111e-04 - val_loss: 1.0078e-04\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2115e-04 - val_loss: 1.0043e-04\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9415e-04 - val_loss: 1.0086e-04\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9406e-04 - val_loss: 9.3193e-05\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9657e-04 - val_loss: 9.6263e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8773e-04 - val_loss: 9.4679e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9144e-04 - val_loss: 9.0414e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9394e-04 - val_loss: 8.9930e-05\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8543e-04 - val_loss: 8.9630e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8527e-04 - val_loss: 9.1871e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8804e-04 - val_loss: 9.5318e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8658e-04 - val_loss: 1.1621e-04\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1155e-04 - val_loss: 8.9836e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9074e-04 - val_loss: 8.8554e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8231e-04 - val_loss: 9.2753e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7923e-04 - val_loss: 9.9946e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8500e-04 - val_loss: 8.9082e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8504e-04 - val_loss: 8.7767e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8653e-04 - val_loss: 8.7604e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7898e-04 - val_loss: 9.0769e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8818e-04 - val_loss: 8.6926e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8907e-04 - val_loss: 8.6729e-05\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0093e-04 - val_loss: 8.9853e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8556e-04 - val_loss: 8.6989e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9870e-04 - val_loss: 8.9253e-05\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7886e-04 - val_loss: 8.5431e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7981e-04 - val_loss: 8.9209e-05\n",
      "Thời gian huấn luyện:  95.60324573516846\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_30 (GRU)                (None, 10, 125)           48000     \n",
      "                                                                 \n",
      " flatten_123 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,251\n",
      "Trainable params: 49,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 1s 5ms/step - loss: 0.0937 - val_loss: 0.0240\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0083\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 8.5496e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 7.5673e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 6.4776e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 5.7611e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 5.7370e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 4.8578e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 5.0441e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 4.6764e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 4.2985e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 3.6989e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 4.1753e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 3.8690e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 3.4207e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 3.8908e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 3.5272e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 3.6164e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 3.2275e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 3.0448e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 3.0562e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 2.6627e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.1861e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 2.8488e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 2.6654e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.7173e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.5083e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.6798e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.4033e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.2586e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.4262e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.1827e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.9906e-04 - val_loss: 2.4021e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.7674e-04 - val_loss: 2.2294e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.5322e-04 - val_loss: 2.3070e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.2651e-04 - val_loss: 2.1136e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.1323e-04 - val_loss: 1.9232e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.9379e-04 - val_loss: 2.1352e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.7813e-04 - val_loss: 2.5927e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.7501e-04 - val_loss: 2.0824e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.3918e-04 - val_loss: 1.8357e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.2485e-04 - val_loss: 1.7613e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.1422e-04 - val_loss: 2.1617e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.0759e-04 - val_loss: 1.8086e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.0390e-04 - val_loss: 1.8111e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.7363e-04 - val_loss: 2.1223e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.6897e-04 - val_loss: 1.8877e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.5727e-04 - val_loss: 1.8965e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.4525e-04 - val_loss: 1.6838e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.3580e-04 - val_loss: 1.9893e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.3417e-04 - val_loss: 1.6535e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.2038e-04 - val_loss: 1.5946e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.1539e-04 - val_loss: 1.8343e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.0763e-04 - val_loss: 1.7125e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.9578e-04 - val_loss: 1.6841e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.8540e-04 - val_loss: 1.7318e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.8242e-04 - val_loss: 1.6335e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.7322e-04 - val_loss: 1.5301e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.8102e-04 - val_loss: 1.6010e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.6511e-04 - val_loss: 1.5850e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.5376e-04 - val_loss: 2.0412e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.5660e-04 - val_loss: 1.7084e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.4735e-04 - val_loss: 1.6194e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.4007e-04 - val_loss: 1.6695e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.3978e-04 - val_loss: 1.5106e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.3997e-04 - val_loss: 1.7025e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.3899e-04 - val_loss: 1.6312e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.1840e-04 - val_loss: 1.6760e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.3466e-04 - val_loss: 1.4391e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.0631e-04 - val_loss: 1.4714e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.0187e-04 - val_loss: 1.4704e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.0318e-04 - val_loss: 1.5973e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9565e-04 - val_loss: 1.6010e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9100e-04 - val_loss: 1.4177e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.0034e-04 - val_loss: 1.3770e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.1941e-04 - val_loss: 1.3713e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.8124e-04 - val_loss: 1.4351e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.8101e-04 - val_loss: 1.5110e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7626e-04 - val_loss: 1.4019e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7437e-04 - val_loss: 1.4101e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6763e-04 - val_loss: 1.4017e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6738e-04 - val_loss: 1.4101e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6681e-04 - val_loss: 1.4330e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5881e-04 - val_loss: 1.3816e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6857e-04 - val_loss: 1.3364e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5406e-04 - val_loss: 1.3757e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6645e-04 - val_loss: 1.3956e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4485e-04 - val_loss: 1.4310e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4511e-04 - val_loss: 1.3735e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4104e-04 - val_loss: 1.3664e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3346e-04 - val_loss: 1.4300e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4429e-04 - val_loss: 1.5042e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3314e-04 - val_loss: 1.3800e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2842e-04 - val_loss: 1.3695e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2932e-04 - val_loss: 1.5362e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3323e-04 - val_loss: 1.4061e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2853e-04 - val_loss: 1.4301e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1627e-04 - val_loss: 1.4133e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1649e-04 - val_loss: 1.3657e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1570e-04 - val_loss: 1.4738e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1185e-04 - val_loss: 1.2674e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3395e-04 - val_loss: 1.2684e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1189e-04 - val_loss: 1.3012e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0763e-04 - val_loss: 1.3365e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1516e-04 - val_loss: 1.2763e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1145e-04 - val_loss: 1.5557e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.1256e-04 - val_loss: 1.4366e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0269e-04 - val_loss: 1.2767e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9706e-04 - val_loss: 1.3032e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0129e-04 - val_loss: 1.2681e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9908e-04 - val_loss: 1.3857e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9406e-04 - val_loss: 1.3152e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0163e-04 - val_loss: 1.2981e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9519e-04 - val_loss: 1.3142e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9324e-04 - val_loss: 1.3459e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8980e-04 - val_loss: 1.2511e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9722e-04 - val_loss: 1.3775e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.8675e-04 - val_loss: 1.2374e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8591e-04 - val_loss: 1.2356e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7760e-04 - val_loss: 1.2910e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8721e-04 - val_loss: 1.2146e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7489e-04 - val_loss: 1.2729e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7683e-04 - val_loss: 1.2147e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9168e-04 - val_loss: 1.3710e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8664e-04 - val_loss: 1.2352e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.7277e-04 - val_loss: 1.3511e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8173e-04 - val_loss: 1.2002e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7830e-04 - val_loss: 1.2044e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7451e-04 - val_loss: 1.3541e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6770e-04 - val_loss: 1.3095e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6940e-04 - val_loss: 1.1994e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7417e-04 - val_loss: 1.2122e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6644e-04 - val_loss: 1.2320e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.6721e-04 - val_loss: 1.2044e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6573e-04 - val_loss: 1.2797e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6848e-04 - val_loss: 1.1935e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5826e-04 - val_loss: 1.2622e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6884e-04 - val_loss: 1.3499e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5829e-04 - val_loss: 1.2516e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5592e-04 - val_loss: 1.1748e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6387e-04 - val_loss: 1.1679e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7757e-04 - val_loss: 1.1622e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5254e-04 - val_loss: 1.3284e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6476e-04 - val_loss: 1.3056e-04\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5837e-04 - val_loss: 1.2330e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4963e-04 - val_loss: 1.1622e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5198e-04 - val_loss: 1.2109e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4920e-04 - val_loss: 1.1517e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6849e-04 - val_loss: 1.2905e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4821e-04 - val_loss: 1.1469e-04\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4636e-04 - val_loss: 1.1946e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4803e-04 - val_loss: 1.2310e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4083e-04 - val_loss: 1.1727e-04\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4819e-04 - val_loss: 1.3085e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4338e-04 - val_loss: 1.1318e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4282e-04 - val_loss: 1.1258e-04\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4234e-04 - val_loss: 1.1304e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4330e-04 - val_loss: 1.1244e-04\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4772e-04 - val_loss: 1.1217e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4367e-04 - val_loss: 1.1282e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3497e-04 - val_loss: 1.1558e-04\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3852e-04 - val_loss: 1.2373e-04\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.4060e-04 - val_loss: 1.1931e-04\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3920e-04 - val_loss: 1.1773e-04\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4233e-04 - val_loss: 1.1484e-04\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3474e-04 - val_loss: 1.2031e-04\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3801e-04 - val_loss: 1.1049e-04\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3320e-04 - val_loss: 1.1070e-04\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5260e-04 - val_loss: 1.2306e-04\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3309e-04 - val_loss: 1.1401e-04\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3418e-04 - val_loss: 1.1358e-04\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2866e-04 - val_loss: 1.1562e-04\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2992e-04 - val_loss: 1.2292e-04\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3391e-04 - val_loss: 1.2596e-04\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2571e-04 - val_loss: 1.1508e-04\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3711e-04 - val_loss: 1.1438e-04\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4655e-04 - val_loss: 1.1444e-04\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4182e-04 - val_loss: 1.1029e-04\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2988e-04 - val_loss: 1.0871e-04\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3640e-04 - val_loss: 1.1524e-04\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3004e-04 - val_loss: 1.1160e-04\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2184e-04 - val_loss: 1.1452e-04\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2007e-04 - val_loss: 1.1067e-04\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1922e-04 - val_loss: 1.0763e-04\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2331e-04 - val_loss: 1.1210e-04\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1922e-04 - val_loss: 1.1440e-04\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2295e-04 - val_loss: 1.1955e-04\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2333e-04 - val_loss: 1.0747e-04\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2232e-04 - val_loss: 1.1233e-04\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3251e-04 - val_loss: 1.2033e-04\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1580e-04 - val_loss: 1.0707e-04\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2134e-04 - val_loss: 1.1380e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1953e-04 - val_loss: 1.0703e-04\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1471e-04 - val_loss: 1.1150e-04\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1637e-04 - val_loss: 1.1189e-04\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1918e-04 - val_loss: 1.0934e-04\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1403e-04 - val_loss: 1.0872e-04\n",
      "Thời gian huấn luyện:  24.38548517227173\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_155 (Dense)           (None, 20, 124)           248       \n",
      "                                                                 \n",
      " flatten_124 (Flatten)       (None, 2480)              0         \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 1)                 2481      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,729\n",
      "Trainable params: 2,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 6.3285e-04\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 4.0113e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 2.9120e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 2.5494e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 2.5060e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 3.1864e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 2.3789e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 2.7301e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 2.1872e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 3.1072e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 2.2502e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 2.1322e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 3.1713e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 9.8789e-04 - val_loss: 2.0467e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 9.3718e-04 - val_loss: 1.8323e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 9.7649e-04 - val_loss: 1.9648e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 8.9630e-04 - val_loss: 1.8942e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 8.7584e-04 - val_loss: 2.2399e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 8.6441e-04 - val_loss: 2.0325e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 8.4807e-04 - val_loss: 1.7593e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 8.5227e-04 - val_loss: 1.8921e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 8.6201e-04 - val_loss: 1.8986e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 8.5129e-04 - val_loss: 1.8080e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 8.0426e-04 - val_loss: 1.6790e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 8.1510e-04 - val_loss: 1.5868e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 8.2465e-04 - val_loss: 1.6059e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.5906e-04 - val_loss: 1.6359e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.7927e-04 - val_loss: 1.5302e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.5759e-04 - val_loss: 1.5680e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.4118e-04 - val_loss: 1.7463e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.2253e-04 - val_loss: 1.5714e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.2305e-04 - val_loss: 1.5047e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.0969e-04 - val_loss: 1.5176e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.1619e-04 - val_loss: 1.9372e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.4090e-04 - val_loss: 1.5635e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.7166e-04 - val_loss: 1.4220e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.8492e-04 - val_loss: 1.7365e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.7729e-04 - val_loss: 1.4220e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.8019e-04 - val_loss: 1.5168e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.7371e-04 - val_loss: 1.3415e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.5324e-04 - val_loss: 1.3662e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.7250e-04 - val_loss: 1.3875e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.4362e-04 - val_loss: 1.2877e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.3281e-04 - val_loss: 1.4056e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.0475e-04 - val_loss: 1.3203e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.1904e-04 - val_loss: 1.3422e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.1386e-04 - val_loss: 1.3171e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.9340e-04 - val_loss: 1.2496e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.1878e-04 - val_loss: 1.2862e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.0073e-04 - val_loss: 1.5485e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.1693e-04 - val_loss: 1.5201e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 5.7723e-04 - val_loss: 1.4040e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.7630e-04 - val_loss: 1.2748e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.7021e-04 - val_loss: 1.2443e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.7097e-04 - val_loss: 1.2915e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.7922e-04 - val_loss: 1.3297e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.0605e-04 - val_loss: 1.4864e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.0766e-04 - val_loss: 1.1633e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.7705e-04 - val_loss: 1.2179e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.3577e-04 - val_loss: 1.1637e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.4317e-04 - val_loss: 1.1777e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.7248e-04 - val_loss: 1.2005e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.4338e-04 - val_loss: 1.1453e-04\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 6ms/step - loss: 5.4241e-04 - val_loss: 1.2763e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.4139e-04 - val_loss: 1.1336e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.6217e-04 - val_loss: 1.2091e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.3732e-04 - val_loss: 1.0869e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.3916e-04 - val_loss: 1.1927e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.3654e-04 - val_loss: 1.0747e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.0270e-04 - val_loss: 1.3446e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.4437e-04 - val_loss: 1.1836e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.9913e-04 - val_loss: 1.0648e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.9666e-04 - val_loss: 1.0917e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.9836e-04 - val_loss: 1.1059e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.8813e-04 - val_loss: 1.0959e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.0249e-04 - val_loss: 1.2134e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.0483e-04 - val_loss: 1.0628e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.0016e-04 - val_loss: 1.0302e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.8978e-04 - val_loss: 1.2065e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.0867e-04 - val_loss: 1.0941e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.1030e-04 - val_loss: 1.0428e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.8396e-04 - val_loss: 1.0159e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.9618e-04 - val_loss: 1.0696e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.7500e-04 - val_loss: 9.9885e-05\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.7160e-04 - val_loss: 9.9484e-05\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.6371e-04 - val_loss: 9.9195e-05\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.8532e-04 - val_loss: 9.9470e-05\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.6770e-04 - val_loss: 9.7694e-05\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.6951e-04 - val_loss: 1.0102e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.7106e-04 - val_loss: 1.0233e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.7151e-04 - val_loss: 1.1243e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.5276e-04 - val_loss: 9.5739e-05\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.5128e-04 - val_loss: 9.8570e-05\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.7356e-04 - val_loss: 9.4950e-05\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.6444e-04 - val_loss: 1.0204e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.4652e-04 - val_loss: 9.5058e-05\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.5373e-04 - val_loss: 1.0130e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.9702e-04 - val_loss: 1.1648e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.5200e-04 - val_loss: 9.2948e-05\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.5142e-04 - val_loss: 1.2370e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.3877e-04 - val_loss: 9.2755e-05\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.3264e-04 - val_loss: 9.3429e-05\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.4596e-04 - val_loss: 9.3157e-05\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.5348e-04 - val_loss: 1.0275e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.4537e-04 - val_loss: 9.0635e-05\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.6070e-04 - val_loss: 9.1056e-05\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.4162e-04 - val_loss: 9.3655e-05\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.4166e-04 - val_loss: 9.2712e-05\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.3599e-04 - val_loss: 9.9951e-05\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1771e-04 - val_loss: 1.0190e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.5354e-04 - val_loss: 9.6862e-05\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.4138e-04 - val_loss: 8.7840e-05\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1314e-04 - val_loss: 8.8163e-05\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1382e-04 - val_loss: 8.9807e-05\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1681e-04 - val_loss: 8.9777e-05\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1235e-04 - val_loss: 9.3796e-05\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1975e-04 - val_loss: 9.7225e-05\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.3952e-04 - val_loss: 9.5547e-05\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.0482e-04 - val_loss: 9.2370e-05\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.0682e-04 - val_loss: 9.1112e-05\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1795e-04 - val_loss: 9.0807e-05\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.3697e-04 - val_loss: 9.0627e-05\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.2095e-04 - val_loss: 8.4517e-05\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.4370e-04 - val_loss: 8.5657e-05\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.2338e-04 - val_loss: 8.6726e-05\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1281e-04 - val_loss: 9.7557e-05\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.0089e-04 - val_loss: 8.4576e-05\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1451e-04 - val_loss: 8.3803e-05\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9496e-04 - val_loss: 8.5755e-05\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9600e-04 - val_loss: 8.5655e-05\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8768e-04 - val_loss: 9.3706e-05\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.0033e-04 - val_loss: 8.4866e-05\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9621e-04 - val_loss: 8.9514e-05\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.0781e-04 - val_loss: 8.5902e-05\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.0570e-04 - val_loss: 8.6542e-05\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.2503e-04 - val_loss: 9.3101e-05\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9259e-04 - val_loss: 8.2995e-05\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9531e-04 - val_loss: 1.0516e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8762e-04 - val_loss: 8.5181e-05\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.0291e-04 - val_loss: 9.7225e-05\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1831e-04 - val_loss: 8.2942e-05\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.2772e-04 - val_loss: 8.1336e-05\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1566e-04 - val_loss: 8.3530e-05\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9753e-04 - val_loss: 8.2413e-05\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9807e-04 - val_loss: 8.4659e-05\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.3890e-04 - val_loss: 8.6804e-05\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7867e-04 - val_loss: 8.2355e-05\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9093e-04 - val_loss: 8.0436e-05\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8138e-04 - val_loss: 8.0358e-05\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7962e-04 - val_loss: 8.0226e-05\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8379e-04 - val_loss: 8.0683e-05\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8224e-04 - val_loss: 9.3380e-05\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1160e-04 - val_loss: 8.2346e-05\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8743e-04 - val_loss: 8.7275e-05\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1159e-04 - val_loss: 7.9100e-05\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7655e-04 - val_loss: 7.9059e-05\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9065e-04 - val_loss: 7.9937e-05\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7379e-04 - val_loss: 8.0250e-05\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7214e-04 - val_loss: 8.2533e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9260e-04 - val_loss: 7.8803e-05\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8303e-04 - val_loss: 7.8775e-05\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9636e-04 - val_loss: 7.8376e-05\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7475e-04 - val_loss: 8.3029e-05\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7069e-04 - val_loss: 7.8930e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8294e-04 - val_loss: 7.8162e-05\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8434e-04 - val_loss: 7.9425e-05\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7800e-04 - val_loss: 7.8175e-05\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7192e-04 - val_loss: 7.8178e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8269e-04 - val_loss: 7.7060e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.4666e-04 - val_loss: 8.1080e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7553e-04 - val_loss: 8.5126e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7019e-04 - val_loss: 7.7443e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9814e-04 - val_loss: 7.7818e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8808e-04 - val_loss: 7.7419e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9382e-04 - val_loss: 7.7331e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7178e-04 - val_loss: 8.0374e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.6394e-04 - val_loss: 7.7885e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7024e-04 - val_loss: 7.7768e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.6648e-04 - val_loss: 7.6897e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8334e-04 - val_loss: 9.3095e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7330e-04 - val_loss: 8.4014e-05\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.6761e-04 - val_loss: 8.1140e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8644e-04 - val_loss: 7.6829e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7647e-04 - val_loss: 8.5808e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8994e-04 - val_loss: 7.6626e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7402e-04 - val_loss: 7.7980e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7300e-04 - val_loss: 7.7086e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.6835e-04 - val_loss: 7.8416e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.0740e-04 - val_loss: 7.6809e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7262e-04 - val_loss: 7.6737e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7385e-04 - val_loss: 7.7920e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7315e-04 - val_loss: 7.7280e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.6774e-04 - val_loss: 7.6328e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8068e-04 - val_loss: 8.2732e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9113e-04 - val_loss: 7.7918e-05\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.5563e-04 - val_loss: 8.1002e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8298e-04 - val_loss: 7.8747e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.7270e-04 - val_loss: 7.7456e-05\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.6647e-04 - val_loss: 7.7439e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.6480e-04 - val_loss: 8.3535e-05\n",
      "Thời gian huấn luyện:  65.25830578804016\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_31 (SimpleRNN)   (None, 20, 124)           15624     \n",
      "                                                                 \n",
      " flatten_125 (Flatten)       (None, 2480)              0         \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 1)                 2481      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,105\n",
      "Trainable params: 18,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 3ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 5s 28ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 15ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.1960 - val_loss: 0.0094\n",
      "Thời gian huấn luyện:  171.06846117973328\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_31 (LSTM)              (None, 20, 124)           62496     \n",
      "                                                                 \n",
      " flatten_126 (Flatten)       (None, 2480)              0         \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 1)                 2481      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,977\n",
      "Trainable params: 64,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 6ms/step\n",
      "15/15 [==============================] - 0s 6ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 4s 23ms/step - loss: 0.0155 - val_loss: 3.7560e-04\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0026 - val_loss: 3.6669e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0024 - val_loss: 3.8248e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0022 - val_loss: 3.5147e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0021 - val_loss: 3.2167e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0020 - val_loss: 3.0333e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 0.0018 - val_loss: 3.3115e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0017 - val_loss: 2.9801e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 2.8860e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.5844e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.5947e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 2.8160e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 0.0013 - val_loss: 2.4300e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0013 - val_loss: 2.2891e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0012 - val_loss: 2.2456e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0012 - val_loss: 2.3445e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 0.0012 - val_loss: 2.3003e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 2.4701e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 2.1966e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 2.1670e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 2.0390e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 0.0010 - val_loss: 2.0528e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 9.9921e-04 - val_loss: 2.0213e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 9.9248e-04 - val_loss: 1.9574e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 9.5803e-04 - val_loss: 1.9372e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 9.4370e-04 - val_loss: 2.0932e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 9.2282e-04 - val_loss: 1.9042e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 8.9929e-04 - val_loss: 1.8829e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 9.0019e-04 - val_loss: 1.8566e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 8.6764e-04 - val_loss: 1.8576e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 8.6165e-04 - val_loss: 1.8854e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 8.4400e-04 - val_loss: 1.8568e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 8.2498e-04 - val_loss: 1.8239e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 8.4379e-04 - val_loss: 1.7696e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 8.1028e-04 - val_loss: 1.7715e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 8.0047e-04 - val_loss: 1.7649e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 7.8788e-04 - val_loss: 1.7675e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 7.9083e-04 - val_loss: 1.8044e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 7.6968e-04 - val_loss: 1.7228e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 7.6722e-04 - val_loss: 1.6932e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 7.4065e-04 - val_loss: 1.6947e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 7.4355e-04 - val_loss: 1.6942e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 7.5640e-04 - val_loss: 1.6703e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 7.1895e-04 - val_loss: 1.6387e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 7.1488e-04 - val_loss: 1.6847e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 7.2149e-04 - val_loss: 1.6348e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 7.1139e-04 - val_loss: 1.6064e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 7.2911e-04 - val_loss: 1.6450e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 6.8716e-04 - val_loss: 1.7863e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 6.7238e-04 - val_loss: 1.6388e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 6.6983e-04 - val_loss: 1.5791e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 6.7067e-04 - val_loss: 1.5490e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 6.6100e-04 - val_loss: 1.5291e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 6.5606e-04 - val_loss: 1.5177e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 6.6441e-04 - val_loss: 1.4892e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 6.6380e-04 - val_loss: 1.6934e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 6.4427e-04 - val_loss: 1.4731e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 6.5366e-04 - val_loss: 1.5015e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 6.4348e-04 - val_loss: 1.5131e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 6.2756e-04 - val_loss: 1.5097e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 6.2414e-04 - val_loss: 1.5220e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 6.3228e-04 - val_loss: 1.4336e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.9975e-04 - val_loss: 1.4171e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 6.1757e-04 - val_loss: 1.4381e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 6.4828e-04 - val_loss: 1.4316e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 6.1254e-04 - val_loss: 1.4988e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.9231e-04 - val_loss: 1.4035e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.9097e-04 - val_loss: 1.4988e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.9014e-04 - val_loss: 1.3682e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.8837e-04 - val_loss: 1.4147e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 6.0442e-04 - val_loss: 1.3682e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.6821e-04 - val_loss: 1.3410e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.5363e-04 - val_loss: 1.3598e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.6018e-04 - val_loss: 1.3300e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 5.4895e-04 - val_loss: 1.3142e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.4760e-04 - val_loss: 1.3436e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 5.6938e-04 - val_loss: 1.3289e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.5532e-04 - val_loss: 1.2979e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.6735e-04 - val_loss: 1.2989e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.4083e-04 - val_loss: 1.2776e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 5.3342e-04 - val_loss: 1.2727e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 5.2644e-04 - val_loss: 1.3007e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.3465e-04 - val_loss: 1.2538e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.2024e-04 - val_loss: 1.2665e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 5.1847e-04 - val_loss: 1.2779e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.1925e-04 - val_loss: 1.2579e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.1112e-04 - val_loss: 1.3023e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.4337e-04 - val_loss: 1.2734e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.0482e-04 - val_loss: 1.2301e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 5.1175e-04 - val_loss: 1.2968e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.1888e-04 - val_loss: 1.2086e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 5.6032e-04 - val_loss: 1.2129e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 5.0788e-04 - val_loss: 1.1902e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 4.9315e-04 - val_loss: 1.1836e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 4.8720e-04 - val_loss: 1.1816e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 4.9935e-04 - val_loss: 1.1901e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 4.9241e-04 - val_loss: 1.3509e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.8259e-04 - val_loss: 1.1664e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 4.8378e-04 - val_loss: 1.2440e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.9126e-04 - val_loss: 1.1980e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.8181e-04 - val_loss: 1.1712e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.7243e-04 - val_loss: 1.1495e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.6947e-04 - val_loss: 1.1509e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.6971e-04 - val_loss: 1.1509e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.7096e-04 - val_loss: 1.1614e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.6541e-04 - val_loss: 1.1182e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.7254e-04 - val_loss: 1.1297e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.6476e-04 - val_loss: 1.0967e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.6408e-04 - val_loss: 1.1094e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.6034e-04 - val_loss: 1.0860e-04\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 15ms/step - loss: 4.5933e-04 - val_loss: 1.0898e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.6110e-04 - val_loss: 1.0802e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.6285e-04 - val_loss: 1.1534e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.7254e-04 - val_loss: 1.0665e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.6197e-04 - val_loss: 1.1111e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.8307e-04 - val_loss: 1.0753e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.6199e-04 - val_loss: 1.0899e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.4701e-04 - val_loss: 1.3377e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.4890e-04 - val_loss: 1.0464e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.4376e-04 - val_loss: 1.1076e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.5348e-04 - val_loss: 1.0412e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.4503e-04 - val_loss: 1.1100e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.3683e-04 - val_loss: 1.0476e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.4372e-04 - val_loss: 1.0628e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.3743e-04 - val_loss: 1.0305e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 4.4727e-04 - val_loss: 1.0484e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.4284e-04 - val_loss: 1.0685e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 4.2935e-04 - val_loss: 1.0066e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.3301e-04 - val_loss: 1.0090e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.3380e-04 - val_loss: 1.0607e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.2809e-04 - val_loss: 1.1112e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.2914e-04 - val_loss: 1.0518e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.2754e-04 - val_loss: 1.0531e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.3239e-04 - val_loss: 1.0339e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.3241e-04 - val_loss: 1.0129e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.1837e-04 - val_loss: 9.9763e-05\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.2582e-04 - val_loss: 9.8472e-05\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.3299e-04 - val_loss: 9.8929e-05\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.3304e-04 - val_loss: 1.0060e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.1106e-04 - val_loss: 1.0436e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.0742e-04 - val_loss: 9.8067e-05\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.1980e-04 - val_loss: 1.0828e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.2517e-04 - val_loss: 9.5055e-05\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.1115e-04 - val_loss: 1.0447e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.0196e-04 - val_loss: 9.5030e-05\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.0956e-04 - val_loss: 9.7453e-05\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.0249e-04 - val_loss: 9.8439e-05\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.9796e-04 - val_loss: 9.6996e-05\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.0151e-04 - val_loss: 9.4810e-05\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.0854e-04 - val_loss: 9.5925e-05\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.9611e-04 - val_loss: 1.0629e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.9386e-04 - val_loss: 9.3780e-05\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.9635e-04 - val_loss: 9.7971e-05\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.9973e-04 - val_loss: 9.2874e-05\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.9370e-04 - val_loss: 1.0471e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.1095e-04 - val_loss: 9.7691e-05\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.9590e-04 - val_loss: 1.0041e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.1109e-04 - val_loss: 9.9938e-05\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.0273e-04 - val_loss: 9.3717e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.9520e-04 - val_loss: 1.0020e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.9565e-04 - val_loss: 9.0644e-05\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.0614e-04 - val_loss: 9.0346e-05\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.8672e-04 - val_loss: 1.0123e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.8678e-04 - val_loss: 9.0482e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.8820e-04 - val_loss: 8.9489e-05\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.9215e-04 - val_loss: 8.9500e-05\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.8660e-04 - val_loss: 9.2756e-05\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.8732e-04 - val_loss: 9.8261e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.9440e-04 - val_loss: 9.3327e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.8021e-04 - val_loss: 9.5497e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.8891e-04 - val_loss: 8.8326e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.8577e-04 - val_loss: 1.0615e-04\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.0911e-04 - val_loss: 8.8847e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.9828e-04 - val_loss: 8.9906e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.7477e-04 - val_loss: 8.7907e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.0489e-04 - val_loss: 8.8171e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.7821e-04 - val_loss: 9.3188e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.8076e-04 - val_loss: 8.6364e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.7882e-04 - val_loss: 8.6739e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.7761e-04 - val_loss: 9.1117e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.7453e-04 - val_loss: 8.6391e-05\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.9085e-04 - val_loss: 8.7292e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.7209e-04 - val_loss: 8.6897e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.7864e-04 - val_loss: 1.0095e-04\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.1019e-04 - val_loss: 8.8909e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.7922e-04 - val_loss: 9.4323e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.7567e-04 - val_loss: 9.3834e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 4.2181e-04 - val_loss: 8.6897e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.8143e-04 - val_loss: 8.9213e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.9960e-04 - val_loss: 9.3157e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 4.1703e-04 - val_loss: 1.0072e-04\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.8657e-04 - val_loss: 8.7108e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.6829e-04 - val_loss: 1.0218e-04\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.6927e-04 - val_loss: 8.9037e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.6604e-04 - val_loss: 1.0254e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.7353e-04 - val_loss: 8.3743e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.6808e-04 - val_loss: 9.5688e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.7057e-04 - val_loss: 1.0484e-04\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 3.6498e-04 - val_loss: 8.4398e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 3.7816e-04 - val_loss: 8.7905e-05\n",
      "Thời gian huấn luyện:  158.3217785358429\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_31 (GRU)                (None, 20, 124)           47244     \n",
      "                                                                 \n",
      " flatten_127 (Flatten)       (None, 2480)              0         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 1)                 2481      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,725\n",
      "Trainable params: 49,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 5ms/step\n",
      "15/15 [==============================] - 0s 5ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 1s 6ms/step - loss: 0.0488 - val_loss: 0.0109\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 8.3683e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 7.4315e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 6.7031e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 6.6696e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 5.7705e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 5.8568e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 5.1751e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 5.7119e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 4.9951e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 4.2913e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 5.0418e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 4.3140e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 4.1037e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 4.2518e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 4.1118e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 4.1884e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 3.3528e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 3.9187e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 3.2004e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 3.3703e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 2.9090e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 2.8236e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 3.0018e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 2.9196e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 3.0355e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.0892e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 2.8929e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 2.4607e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 2.4575e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.7278e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 2.4826e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.5751e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.5525e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.3198e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.9615e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.4948e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 2.6009e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.1122e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 9.9469e-04 - val_loss: 2.3482e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.7230e-04 - val_loss: 2.2696e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.6791e-04 - val_loss: 2.6988e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.6154e-04 - val_loss: 2.0396e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.4037e-04 - val_loss: 2.2795e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.2284e-04 - val_loss: 1.8487e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.0708e-04 - val_loss: 2.0126e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.8734e-04 - val_loss: 2.0960e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.8201e-04 - val_loss: 2.3665e-04\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 3ms/step - loss: 8.7120e-04 - val_loss: 1.7953e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.5694e-04 - val_loss: 1.8924e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.3732e-04 - val_loss: 1.9577e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.3438e-04 - val_loss: 2.0315e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.1978e-04 - val_loss: 1.8090e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.0874e-04 - val_loss: 1.7734e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.0300e-04 - val_loss: 1.8228e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.8683e-04 - val_loss: 1.7560e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.7905e-04 - val_loss: 1.6381e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.7085e-04 - val_loss: 1.6102e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.0251e-04 - val_loss: 1.7426e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.6654e-04 - val_loss: 1.6889e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.4519e-04 - val_loss: 1.7558e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.3698e-04 - val_loss: 1.6727e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.2117e-04 - val_loss: 1.6193e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.2282e-04 - val_loss: 1.5135e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.1172e-04 - val_loss: 1.8056e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.1466e-04 - val_loss: 1.6366e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.9917e-04 - val_loss: 1.6542e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.9725e-04 - val_loss: 1.6766e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9257e-04 - val_loss: 1.5307e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.8188e-04 - val_loss: 1.6580e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9071e-04 - val_loss: 1.6023e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.6745e-04 - val_loss: 1.7122e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.6130e-04 - val_loss: 1.4422e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5399e-04 - val_loss: 1.6695e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5703e-04 - val_loss: 1.4360e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.6223e-04 - val_loss: 1.6314e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.4754e-04 - val_loss: 1.5469e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.3418e-04 - val_loss: 1.5565e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.2888e-04 - val_loss: 1.4355e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.3216e-04 - val_loss: 1.7942e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.2552e-04 - val_loss: 1.3654e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.2746e-04 - val_loss: 1.4526e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.1300e-04 - val_loss: 1.3535e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.2423e-04 - val_loss: 1.3333e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.0270e-04 - val_loss: 1.3498e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.0348e-04 - val_loss: 1.3513e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9831e-04 - val_loss: 1.6174e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.0431e-04 - val_loss: 1.4125e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9028e-04 - val_loss: 1.4349e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.8884e-04 - val_loss: 1.3027e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9862e-04 - val_loss: 1.3973e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.8498e-04 - val_loss: 1.2955e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.8443e-04 - val_loss: 1.4768e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.8655e-04 - val_loss: 1.3389e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.7974e-04 - val_loss: 1.4621e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6776e-04 - val_loss: 1.3731e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6304e-04 - val_loss: 1.3112e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.0215e-04 - val_loss: 1.4414e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.9181e-04 - val_loss: 1.5660e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.6943e-04 - val_loss: 1.4103e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5161e-04 - val_loss: 1.4692e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5437e-04 - val_loss: 1.3666e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5862e-04 - val_loss: 1.3543e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4897e-04 - val_loss: 1.4112e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4223e-04 - val_loss: 1.2632e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4570e-04 - val_loss: 1.4296e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.4976e-04 - val_loss: 1.3889e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.3546e-04 - val_loss: 1.3420e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3906e-04 - val_loss: 1.4542e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3322e-04 - val_loss: 1.3287e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3448e-04 - val_loss: 1.3529e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.4877e-04 - val_loss: 1.2653e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2645e-04 - val_loss: 1.2308e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2836e-04 - val_loss: 1.2808e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1980e-04 - val_loss: 1.3002e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.2178e-04 - val_loss: 1.3409e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3069e-04 - val_loss: 1.2929e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1407e-04 - val_loss: 1.3188e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1327e-04 - val_loss: 1.3083e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.1824e-04 - val_loss: 1.3618e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.1622e-04 - val_loss: 1.2606e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.0470e-04 - val_loss: 1.2384e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.0388e-04 - val_loss: 1.2480e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1118e-04 - val_loss: 1.3094e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0470e-04 - val_loss: 1.3507e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0484e-04 - val_loss: 1.3079e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1214e-04 - val_loss: 1.2542e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0395e-04 - val_loss: 1.2657e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.9406e-04 - val_loss: 1.4555e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0637e-04 - val_loss: 1.1964e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0522e-04 - val_loss: 1.2766e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.9474e-04 - val_loss: 1.2957e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8712e-04 - val_loss: 1.1938e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9935e-04 - val_loss: 1.4248e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9448e-04 - val_loss: 1.1838e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9689e-04 - val_loss: 1.2843e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8627e-04 - val_loss: 1.2713e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8179e-04 - val_loss: 1.2230e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9373e-04 - val_loss: 1.2013e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8545e-04 - val_loss: 1.2146e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8109e-04 - val_loss: 1.2495e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8277e-04 - val_loss: 1.3565e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9153e-04 - val_loss: 1.2620e-04\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7451e-04 - val_loss: 1.1860e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8776e-04 - val_loss: 1.3918e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8000e-04 - val_loss: 1.1916e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8678e-04 - val_loss: 1.1652e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8387e-04 - val_loss: 1.5190e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9418e-04 - val_loss: 1.3188e-04\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.7238e-04 - val_loss: 1.2636e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6445e-04 - val_loss: 1.2021e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6822e-04 - val_loss: 1.3340e-04\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7537e-04 - val_loss: 1.1581e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7304e-04 - val_loss: 1.4919e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6299e-04 - val_loss: 1.3913e-04\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6904e-04 - val_loss: 1.1810e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6720e-04 - val_loss: 1.1646e-04\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6267e-04 - val_loss: 1.2102e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7209e-04 - val_loss: 1.1714e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.5836e-04 - val_loss: 1.3221e-04\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7178e-04 - val_loss: 1.2320e-04\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6044e-04 - val_loss: 1.2602e-04\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6076e-04 - val_loss: 1.2375e-04\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5925e-04 - val_loss: 1.1702e-04\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5511e-04 - val_loss: 1.2122e-04\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5587e-04 - val_loss: 1.1685e-04\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7240e-04 - val_loss: 1.3842e-04\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5360e-04 - val_loss: 1.1545e-04\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5682e-04 - val_loss: 1.3105e-04\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5881e-04 - val_loss: 1.1999e-04\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4838e-04 - val_loss: 1.2550e-04\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5227e-04 - val_loss: 1.1416e-04\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5117e-04 - val_loss: 1.1344e-04\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4995e-04 - val_loss: 1.1974e-04\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4606e-04 - val_loss: 1.1821e-04\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4515e-04 - val_loss: 1.1684e-04\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6214e-04 - val_loss: 1.2519e-04\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4608e-04 - val_loss: 1.2193e-04\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4315e-04 - val_loss: 1.1661e-04\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5067e-04 - val_loss: 1.2883e-04\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5192e-04 - val_loss: 1.3016e-04\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5499e-04 - val_loss: 1.1210e-04\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5524e-04 - val_loss: 1.1374e-04\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4163e-04 - val_loss: 1.2915e-04\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4122e-04 - val_loss: 1.1185e-04\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5397e-04 - val_loss: 1.3430e-04\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3924e-04 - val_loss: 1.1745e-04\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4107e-04 - val_loss: 1.1152e-04\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4571e-04 - val_loss: 1.1692e-04\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3234e-04 - val_loss: 1.1875e-04\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3466e-04 - val_loss: 1.1278e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3726e-04 - val_loss: 1.1333e-04\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3415e-04 - val_loss: 1.1426e-04\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2934e-04 - val_loss: 1.3744e-04\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4778e-04 - val_loss: 1.4120e-04\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4704e-04 - val_loss: 1.1904e-04\n",
      "Thời gian huấn luyện:  26.461910009384155\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_160 (Dense)           (None, 30, 124)           248       \n",
      "                                                                 \n",
      " flatten_128 (Flatten)       (None, 3720)              0         \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 1)                 3721      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,969\n",
      "Trainable params: 3,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0078 - val_loss: 5.8560e-04\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 3.4441e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 2.8611e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 3.2770e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 2.9291e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 3.4369e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 2.4308e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.5353e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 2.3010e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 2.4892e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 1.9509e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 2.0202e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 2.2623e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 9.3771e-04 - val_loss: 1.8201e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 9.1526e-04 - val_loss: 2.1670e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.9858e-04 - val_loss: 2.1928e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 9.4136e-04 - val_loss: 1.8208e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 8.5318e-04 - val_loss: 1.9443e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 8.4171e-04 - val_loss: 1.9003e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 8.0645e-04 - val_loss: 2.0189e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 8.1069e-04 - val_loss: 1.8048e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.8050e-04 - val_loss: 1.7230e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.7664e-04 - val_loss: 1.5622e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.9615e-04 - val_loss: 1.6404e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.5633e-04 - val_loss: 1.9035e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.1495e-04 - val_loss: 1.6794e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.8075e-04 - val_loss: 1.4749e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.1499e-04 - val_loss: 1.5993e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.3313e-04 - val_loss: 1.6902e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.2922e-04 - val_loss: 1.4324e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.8728e-04 - val_loss: 1.5462e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.6055e-04 - val_loss: 1.3905e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.9619e-04 - val_loss: 1.5090e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.6399e-04 - val_loss: 1.4445e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.4719e-04 - val_loss: 1.3585e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.1599e-04 - val_loss: 1.3395e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.2975e-04 - val_loss: 1.4003e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.2643e-04 - val_loss: 1.4861e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.4787e-04 - val_loss: 1.8665e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.8546e-04 - val_loss: 1.5724e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.0386e-04 - val_loss: 1.4277e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.0557e-04 - val_loss: 1.5634e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.8366e-04 - val_loss: 1.3226e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.9811e-04 - val_loss: 1.2717e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 5.9096e-04 - val_loss: 1.4713e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.9486e-04 - val_loss: 1.2897e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.1400e-04 - val_loss: 1.2109e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 5.9848e-04 - val_loss: 1.3151e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.7936e-04 - val_loss: 1.2039e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 5.6048e-04 - val_loss: 1.2067e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.4686e-04 - val_loss: 1.2065e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.4352e-04 - val_loss: 1.1975e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.2972e-04 - val_loss: 1.2811e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.5793e-04 - val_loss: 1.3119e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.6124e-04 - val_loss: 1.5270e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.5515e-04 - val_loss: 1.1483e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.3153e-04 - val_loss: 1.1896e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 5.4386e-04 - val_loss: 1.1442e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.5157e-04 - val_loss: 1.2315e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.2396e-04 - val_loss: 1.1520e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.2412e-04 - val_loss: 1.0848e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.2229e-04 - val_loss: 1.3307e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.5454e-04 - val_loss: 1.0686e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.5659e-04 - val_loss: 1.2686e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.9892e-04 - val_loss: 1.1055e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.3602e-04 - val_loss: 1.1225e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.2440e-04 - val_loss: 1.1937e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.9898e-04 - val_loss: 1.4561e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 5.2425e-04 - val_loss: 1.2057e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 5.0928e-04 - val_loss: 1.1955e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 5.1544e-04 - val_loss: 1.0549e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.9776e-04 - val_loss: 1.0162e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.3003e-04 - val_loss: 1.0129e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.9252e-04 - val_loss: 1.0215e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.8814e-04 - val_loss: 1.0384e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.6983e-04 - val_loss: 1.0537e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.6085e-04 - val_loss: 1.1728e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.6700e-04 - val_loss: 1.0188e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.1087e-04 - val_loss: 9.7874e-05\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.7832e-04 - val_loss: 1.2250e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.7103e-04 - val_loss: 1.0021e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.8192e-04 - val_loss: 1.2019e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.6033e-04 - val_loss: 1.0492e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.4490e-04 - val_loss: 9.5960e-05\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.7883e-04 - val_loss: 1.0154e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.6100e-04 - val_loss: 9.4954e-05\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.4301e-04 - val_loss: 1.0963e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.7355e-04 - val_loss: 1.3534e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.7983e-04 - val_loss: 9.8017e-05\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.3407e-04 - val_loss: 1.1718e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.3305e-04 - val_loss: 9.2785e-05\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2961e-04 - val_loss: 9.8958e-05\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.4165e-04 - val_loss: 9.8833e-05\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.4472e-04 - val_loss: 1.0611e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.2475e-04 - val_loss: 9.1402e-05\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.2288e-04 - val_loss: 1.0751e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.7286e-04 - val_loss: 8.9656e-05\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.3029e-04 - val_loss: 1.0211e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.3009e-04 - val_loss: 1.0679e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2717e-04 - val_loss: 9.2300e-05\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1088e-04 - val_loss: 1.0347e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.1296e-04 - val_loss: 9.0323e-05\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.7524e-04 - val_loss: 8.7476e-05\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1750e-04 - val_loss: 9.8106e-05\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2289e-04 - val_loss: 9.1274e-05\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1712e-04 - val_loss: 8.6778e-05\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.4828e-04 - val_loss: 8.9624e-05\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1193e-04 - val_loss: 9.2343e-05\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.0896e-04 - val_loss: 8.9230e-05\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.0257e-04 - val_loss: 8.9252e-05\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.0442e-04 - val_loss: 8.7367e-05\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.0923e-04 - val_loss: 8.5763e-05\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.1463e-04 - val_loss: 8.6382e-05\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.1607e-04 - val_loss: 8.8648e-05\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 3.9649e-04 - val_loss: 9.0433e-05\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1003e-04 - val_loss: 9.5981e-05\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.0236e-04 - val_loss: 8.9144e-05\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1110e-04 - val_loss: 8.6636e-05\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.5631e-04 - val_loss: 8.9417e-05\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.1472e-04 - val_loss: 9.5611e-05\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9774e-04 - val_loss: 8.7222e-05\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.3257e-04 - val_loss: 8.8627e-05\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2113e-04 - val_loss: 9.3904e-05\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.3696e-04 - val_loss: 1.2766e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9753e-04 - val_loss: 8.9297e-05\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2576e-04 - val_loss: 8.9032e-05\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9561e-04 - val_loss: 8.3822e-05\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2661e-04 - val_loss: 8.5552e-05\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.0881e-04 - val_loss: 8.9724e-05\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.3478e-04 - val_loss: 1.1268e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2547e-04 - val_loss: 9.3471e-05\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9679e-04 - val_loss: 8.1287e-05\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8971e-04 - val_loss: 8.7413e-05\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.0516e-04 - val_loss: 8.1947e-05\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8776e-04 - val_loss: 8.5299e-05\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9160e-04 - val_loss: 8.6025e-05\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8623e-04 - val_loss: 8.1345e-05\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1100e-04 - val_loss: 8.9283e-05\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7600e-04 - val_loss: 8.7988e-05\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.0896e-04 - val_loss: 9.4279e-05\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.0440e-04 - val_loss: 8.1380e-05\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8436e-04 - val_loss: 8.5487e-05\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.0382e-04 - val_loss: 7.9381e-05\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0593e-04 - val_loss: 8.8215e-05\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9127e-04 - val_loss: 9.8778e-05\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8991e-04 - val_loss: 8.1947e-05\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8689e-04 - val_loss: 8.0131e-05\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8493e-04 - val_loss: 7.9151e-05\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.4538e-04 - val_loss: 8.1283e-05\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8569e-04 - val_loss: 8.0702e-05\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9110e-04 - val_loss: 7.9066e-05\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8375e-04 - val_loss: 8.9108e-05\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7912e-04 - val_loss: 8.0847e-05\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9330e-04 - val_loss: 7.9576e-05\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0935e-04 - val_loss: 1.1095e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7116e-04 - val_loss: 9.9804e-05\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8363e-04 - val_loss: 9.1496e-05\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7714e-04 - val_loss: 7.9631e-05\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8222e-04 - val_loss: 9.6595e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8118e-04 - val_loss: 8.1475e-05\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8189e-04 - val_loss: 7.8797e-05\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7379e-04 - val_loss: 1.1058e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7020e-04 - val_loss: 9.0062e-05\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7479e-04 - val_loss: 7.7672e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7423e-04 - val_loss: 9.2195e-05\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.6727e-04 - val_loss: 1.1290e-04\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9722e-04 - val_loss: 8.2488e-05\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8862e-04 - val_loss: 7.7446e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7408e-04 - val_loss: 8.2390e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8608e-04 - val_loss: 7.8099e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7784e-04 - val_loss: 7.7580e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8404e-04 - val_loss: 8.5551e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.6724e-04 - val_loss: 8.0683e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.6970e-04 - val_loss: 8.6435e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.6798e-04 - val_loss: 8.7348e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7784e-04 - val_loss: 8.7515e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.6750e-04 - val_loss: 8.1992e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7042e-04 - val_loss: 8.4926e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9999e-04 - val_loss: 7.9473e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.6939e-04 - val_loss: 9.4922e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9061e-04 - val_loss: 7.6910e-05\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8586e-04 - val_loss: 7.7227e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7895e-04 - val_loss: 8.1009e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9413e-04 - val_loss: 8.7305e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9181e-04 - val_loss: 8.0822e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7213e-04 - val_loss: 7.7769e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9782e-04 - val_loss: 7.7112e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1069e-04 - val_loss: 7.8074e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7702e-04 - val_loss: 7.6264e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.6571e-04 - val_loss: 8.2162e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9511e-04 - val_loss: 8.3858e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7137e-04 - val_loss: 8.1331e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9346e-04 - val_loss: 7.7033e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.5307e-04 - val_loss: 7.6753e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.6721e-04 - val_loss: 7.7782e-05\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8527e-04 - val_loss: 7.6768e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.0431e-04 - val_loss: 7.5200e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.6614e-04 - val_loss: 8.1266e-05\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.6311e-04 - val_loss: 7.8425e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.6101e-04 - val_loss: 7.6259e-05\n",
      "Thời gian huấn luyện:  84.08534336090088\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_32 (SimpleRNN)   (None, 30, 124)           15624     \n",
      "                                                                 \n",
      " flatten_129 (Flatten)       (None, 3720)              0         \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 1)                 3721      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,345\n",
      "Trainable params: 19,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 4s 33ms/step - loss: 0.0177 - val_loss: 5.2388e-04\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0036 - val_loss: 4.9182e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0034 - val_loss: 4.9298e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.0031 - val_loss: 4.9302e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0029 - val_loss: 4.0000e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.0028 - val_loss: 3.8206e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0026 - val_loss: 4.3771e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0024 - val_loss: 3.8971e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 3.6063e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 0.0022 - val_loss: 3.9148e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0021 - val_loss: 4.4562e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0021 - val_loss: 3.7814e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.0019 - val_loss: 3.3133e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0019 - val_loss: 3.0995e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0019 - val_loss: 2.9963e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 3.2936e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0018 - val_loss: 2.9686e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.0017 - val_loss: 2.8291e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0017 - val_loss: 2.6899e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 2.8213e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 2.6240e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.0016 - val_loss: 2.6050e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0015 - val_loss: 2.5505e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 2.6110e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.0015 - val_loss: 2.7199e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 2.4772e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0014 - val_loss: 2.5733e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 2.4502e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0013 - val_loss: 2.4013e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0013 - val_loss: 2.4268e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.0013 - val_loss: 2.3663e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 2.4815e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.0012 - val_loss: 2.2968e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 2.2644e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 2.3132e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.0012 - val_loss: 2.2760e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 2.1764e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 2.1585e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 2.1677e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 2.2829e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 2.1402e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 2.1933e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 2.1517e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 2.2592e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 2.0567e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 2.0569e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 9.9267e-04 - val_loss: 2.1483e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 2.1679e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 9.8491e-04 - val_loss: 1.9880e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 2.1601e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 9.5568e-04 - val_loss: 1.9786e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 9.5054e-04 - val_loss: 2.1580e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 9.5270e-04 - val_loss: 1.9592e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 9.2653e-04 - val_loss: 1.9343e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 9.3586e-04 - val_loss: 1.9420e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 9.2705e-04 - val_loss: 2.0078e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 9.1835e-04 - val_loss: 2.0370e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 9.0745e-04 - val_loss: 1.8999e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 8.7226e-04 - val_loss: 1.9232e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 9.1123e-04 - val_loss: 1.9170e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 8.8875e-04 - val_loss: 1.9256e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 8.6966e-04 - val_loss: 1.8673e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 8.7485e-04 - val_loss: 1.9608e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 9.1144e-04 - val_loss: 1.8754e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 8.2651e-04 - val_loss: 1.8461e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 8.6731e-04 - val_loss: 1.9970e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 8.4592e-04 - val_loss: 1.8664e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 8.3383e-04 - val_loss: 1.9388e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 8.1771e-04 - val_loss: 1.9694e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 8.1591e-04 - val_loss: 2.0069e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.9805e-04 - val_loss: 1.8503e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 8.3150e-04 - val_loss: 2.0880e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 8.2471e-04 - val_loss: 1.7769e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 8.5740e-04 - val_loss: 1.7773e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.8883e-04 - val_loss: 1.9904e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.9431e-04 - val_loss: 1.8118e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.9404e-04 - val_loss: 1.8368e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.9464e-04 - val_loss: 1.8585e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.6124e-04 - val_loss: 1.7699e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.6083e-04 - val_loss: 1.7350e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.7213e-04 - val_loss: 1.7110e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.8847e-04 - val_loss: 2.0590e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.4336e-04 - val_loss: 1.8772e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.4605e-04 - val_loss: 1.7346e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.5280e-04 - val_loss: 1.8437e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.6248e-04 - val_loss: 1.6973e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.4220e-04 - val_loss: 1.8386e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.3167e-04 - val_loss: 1.7160e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.1684e-04 - val_loss: 1.6666e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.1045e-04 - val_loss: 1.7211e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.2009e-04 - val_loss: 1.8955e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.3034e-04 - val_loss: 1.6432e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.1546e-04 - val_loss: 1.6790e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.2084e-04 - val_loss: 1.6938e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.0087e-04 - val_loss: 1.7468e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.4045e-04 - val_loss: 1.8471e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.0367e-04 - val_loss: 1.7745e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.8710e-04 - val_loss: 1.6539e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.1213e-04 - val_loss: 1.6162e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.0035e-04 - val_loss: 1.7680e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 6.8922e-04 - val_loss: 1.6882e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 6.8856e-04 - val_loss: 1.6814e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 6.8330e-04 - val_loss: 1.6087e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 6.6265e-04 - val_loss: 1.5994e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 6.7857e-04 - val_loss: 1.6047e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 6.6574e-04 - val_loss: 1.6331e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 6.5340e-04 - val_loss: 1.5502e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 6.5096e-04 - val_loss: 1.5271e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 6.6244e-04 - val_loss: 1.5702e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 6.4714e-04 - val_loss: 1.7783e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 6.5807e-04 - val_loss: 1.5893e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 6.5677e-04 - val_loss: 1.5521e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 6.2820e-04 - val_loss: 1.5144e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 6.3195e-04 - val_loss: 1.8658e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 6.5603e-04 - val_loss: 1.4859e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 6.4911e-04 - val_loss: 1.8334e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.0452e-04 - val_loss: 1.5463e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 6.1377e-04 - val_loss: 1.6507e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 6.4696e-04 - val_loss: 1.8481e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 6.1961e-04 - val_loss: 1.4749e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 6.0302e-04 - val_loss: 1.4353e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 6.2253e-04 - val_loss: 1.4839e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 5.9357e-04 - val_loss: 1.5572e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 6.0279e-04 - val_loss: 1.4257e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.9190e-04 - val_loss: 1.4907e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 5.9106e-04 - val_loss: 1.6234e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 6.6696e-04 - val_loss: 1.8066e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 6.4306e-04 - val_loss: 1.4093e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 5.9374e-04 - val_loss: 1.4720e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.7817e-04 - val_loss: 1.4733e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.7127e-04 - val_loss: 1.4805e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.9360e-04 - val_loss: 1.5859e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.6579e-04 - val_loss: 1.4639e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 5.6834e-04 - val_loss: 1.4527e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.9371e-04 - val_loss: 1.3493e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.8923e-04 - val_loss: 1.4137e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 5.7802e-04 - val_loss: 1.5528e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.5645e-04 - val_loss: 1.3989e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.4196e-04 - val_loss: 1.3421e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.6237e-04 - val_loss: 1.3351e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.4636e-04 - val_loss: 1.3012e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.3646e-04 - val_loss: 1.4397e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.3265e-04 - val_loss: 1.3316e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 5.5849e-04 - val_loss: 1.3348e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.4116e-04 - val_loss: 1.7587e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.4412e-04 - val_loss: 1.3167e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.3047e-04 - val_loss: 1.3865e-04\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.4913e-04 - val_loss: 1.4782e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.1822e-04 - val_loss: 1.5131e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.3102e-04 - val_loss: 1.4000e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.3728e-04 - val_loss: 1.2418e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.2030e-04 - val_loss: 1.2840e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 5.1434e-04 - val_loss: 1.6062e-04\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.1262e-04 - val_loss: 1.5185e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.3069e-04 - val_loss: 1.3084e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 5.2598e-04 - val_loss: 1.2549e-04\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.9755e-04 - val_loss: 1.3020e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.0524e-04 - val_loss: 1.2807e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.8503e-04 - val_loss: 1.2738e-04\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.8903e-04 - val_loss: 1.1852e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.9348e-04 - val_loss: 1.1792e-04\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 5.3219e-04 - val_loss: 1.1743e-04\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 21ms/step - loss: 5.0339e-04 - val_loss: 1.2091e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.9980e-04 - val_loss: 1.2372e-04\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.8953e-04 - val_loss: 1.2254e-04\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.6891e-04 - val_loss: 1.2783e-04\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.7646e-04 - val_loss: 1.2102e-04\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.7693e-04 - val_loss: 1.1636e-04\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.8786e-04 - val_loss: 1.2126e-04\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.1865e-04 - val_loss: 1.7043e-04\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.8042e-04 - val_loss: 1.6384e-04\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.1867e-04 - val_loss: 1.7483e-04\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.6730e-04 - val_loss: 1.1751e-04\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.5393e-04 - val_loss: 1.1741e-04\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.6079e-04 - val_loss: 1.3070e-04\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.7148e-04 - val_loss: 1.3752e-04\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.5388e-04 - val_loss: 1.2511e-04\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.4761e-04 - val_loss: 1.3361e-04\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.3888e-04 - val_loss: 1.3971e-04\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.4098e-04 - val_loss: 1.2171e-04\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.4264e-04 - val_loss: 1.1343e-04\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.3331e-04 - val_loss: 1.3597e-04\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.4108e-04 - val_loss: 1.4645e-04\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.4829e-04 - val_loss: 1.0612e-04\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.3245e-04 - val_loss: 1.2486e-04\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.3343e-04 - val_loss: 1.0537e-04\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.4661e-04 - val_loss: 1.1264e-04\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.3635e-04 - val_loss: 1.0648e-04\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.2468e-04 - val_loss: 1.3389e-04\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.1991e-04 - val_loss: 1.0581e-04\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 4.4191e-04 - val_loss: 1.0360e-04\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.1655e-04 - val_loss: 1.1729e-04\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.3758e-04 - val_loss: 1.0593e-04\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.2128e-04 - val_loss: 1.5561e-04\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.6483e-04 - val_loss: 1.1810e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.1283e-04 - val_loss: 1.0745e-04\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.1391e-04 - val_loss: 1.0114e-04\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.3408e-04 - val_loss: 1.1507e-04\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.1484e-04 - val_loss: 1.0190e-04\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.1288e-04 - val_loss: 1.0797e-04\n",
      "Thời gian huấn luyện:  239.06766963005066\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_32 (LSTM)              (None, 30, 124)           62496     \n",
      "                                                                 \n",
      " flatten_130 (Flatten)       (None, 3720)              0         \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 1)                 3721      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,217\n",
      "Trainable params: 66,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 8ms/step\n",
      "14/14 [==============================] - 0s 8ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 4s 27ms/step - loss: 0.0190 - val_loss: 4.6037e-04\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0031 - val_loss: 3.8646e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0027 - val_loss: 3.8586e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0025 - val_loss: 3.5402e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0022 - val_loss: 3.2876e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0021 - val_loss: 3.4149e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 2.9143e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0018 - val_loss: 3.0567e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 2.5975e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0016 - val_loss: 3.0670e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 2.4685e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0015 - val_loss: 2.6345e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0014 - val_loss: 2.3941e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 2.4769e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0013 - val_loss: 2.2913e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 2.3496e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 2.0210e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 2.2166e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 2.0324e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 1.9030e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 1.9240e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 9.9747e-04 - val_loss: 1.9616e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 9.5712e-04 - val_loss: 1.8937e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 9.7460e-04 - val_loss: 1.9759e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 9.3073e-04 - val_loss: 1.8978e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 9.0351e-04 - val_loss: 1.7799e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 9.1000e-04 - val_loss: 1.7694e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 8.6287e-04 - val_loss: 1.7420e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 8.4938e-04 - val_loss: 1.7537e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 8.2494e-04 - val_loss: 1.7693e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 8.0270e-04 - val_loss: 1.6759e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 7.8878e-04 - val_loss: 1.8172e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 7.6754e-04 - val_loss: 1.6763e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 7.6266e-04 - val_loss: 1.6204e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 7.8937e-04 - val_loss: 1.6371e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 7.4901e-04 - val_loss: 1.5932e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 7.4030e-04 - val_loss: 1.6070e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 7.4220e-04 - val_loss: 1.5840e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 7.2899e-04 - val_loss: 1.5629e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 7.0679e-04 - val_loss: 1.5465e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 7.0306e-04 - val_loss: 1.5496e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 7.5259e-04 - val_loss: 1.6088e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 7.5939e-04 - val_loss: 1.5202e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 6.6733e-04 - val_loss: 1.5020e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 6.6812e-04 - val_loss: 1.5438e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 6.6341e-04 - val_loss: 1.5078e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 7.0739e-04 - val_loss: 1.6606e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 6.6812e-04 - val_loss: 1.4681e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 6.3321e-04 - val_loss: 1.4579e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 7.5480e-04 - val_loss: 1.5654e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 6.7217e-04 - val_loss: 1.4312e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 6.4914e-04 - val_loss: 1.4296e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 6.2712e-04 - val_loss: 1.4300e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 6.1255e-04 - val_loss: 1.4239e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 6.1276e-04 - val_loss: 1.4201e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 6.3922e-04 - val_loss: 1.4347e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 6.1159e-04 - val_loss: 1.4123e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 6.0855e-04 - val_loss: 1.7065e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 6.1087e-04 - val_loss: 1.3772e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 6.0305e-04 - val_loss: 1.4684e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 6.1900e-04 - val_loss: 1.3703e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.9241e-04 - val_loss: 1.3551e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 5.7435e-04 - val_loss: 1.3418e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.8831e-04 - val_loss: 1.3777e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.7215e-04 - val_loss: 1.3678e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 5.6151e-04 - val_loss: 1.3386e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.5186e-04 - val_loss: 1.3453e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.9994e-04 - val_loss: 1.3709e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.5917e-04 - val_loss: 1.3300e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.6015e-04 - val_loss: 1.3284e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.3803e-04 - val_loss: 1.3360e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.4982e-04 - val_loss: 1.3277e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.3518e-04 - val_loss: 1.2882e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.3395e-04 - val_loss: 1.3019e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.3493e-04 - val_loss: 1.2785e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 5.3050e-04 - val_loss: 1.2633e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.4585e-04 - val_loss: 1.2506e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.1583e-04 - val_loss: 1.3205e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 5.4740e-04 - val_loss: 1.2558e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 5.1539e-04 - val_loss: 1.3425e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.1297e-04 - val_loss: 1.2393e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.0793e-04 - val_loss: 1.2568e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 5.6027e-04 - val_loss: 1.2022e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.1888e-04 - val_loss: 1.3015e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 5.1954e-04 - val_loss: 1.2028e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 5.1642e-04 - val_loss: 1.2769e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 5.0087e-04 - val_loss: 1.1970e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.9424e-04 - val_loss: 1.1727e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 5.0244e-04 - val_loss: 1.1753e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.9528e-04 - val_loss: 1.1928e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.8722e-04 - val_loss: 1.1869e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 4.9331e-04 - val_loss: 1.1459e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.8034e-04 - val_loss: 1.1920e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.8130e-04 - val_loss: 1.1751e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 4.7356e-04 - val_loss: 1.1470e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.7757e-04 - val_loss: 1.1781e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.7952e-04 - val_loss: 1.1262e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.7437e-04 - val_loss: 1.1536e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.8267e-04 - val_loss: 1.1095e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.8672e-04 - val_loss: 1.2678e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 4.8868e-04 - val_loss: 1.1128e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.6255e-04 - val_loss: 1.1514e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.7177e-04 - val_loss: 1.1790e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.7377e-04 - val_loss: 1.0952e-04\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 21ms/step - loss: 4.5467e-04 - val_loss: 1.0696e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.5428e-04 - val_loss: 1.0966e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.4929e-04 - val_loss: 1.0633e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.4634e-04 - val_loss: 1.0619e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.7283e-04 - val_loss: 1.1212e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 4.5230e-04 - val_loss: 1.1678e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.6448e-04 - val_loss: 1.0602e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.4790e-04 - val_loss: 1.0476e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 4.4517e-04 - val_loss: 1.0382e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.5032e-04 - val_loss: 1.0315e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.3913e-04 - val_loss: 1.0327e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 4.2984e-04 - val_loss: 1.0246e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.3408e-04 - val_loss: 1.0813e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.7621e-04 - val_loss: 1.0932e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 4.2984e-04 - val_loss: 1.0111e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.2000e-04 - val_loss: 1.0410e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.2216e-04 - val_loss: 1.0330e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.3093e-04 - val_loss: 1.1241e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.2489e-04 - val_loss: 9.9468e-05\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.4747e-04 - val_loss: 9.9931e-05\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 4.4550e-04 - val_loss: 9.8149e-05\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.0797e-04 - val_loss: 1.0107e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.5778e-04 - val_loss: 1.0516e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 4.2354e-04 - val_loss: 9.7172e-05\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.1276e-04 - val_loss: 9.7614e-05\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.3688e-04 - val_loss: 9.6816e-05\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 4.1605e-04 - val_loss: 9.6911e-05\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.3699e-04 - val_loss: 9.9785e-05\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.5413e-04 - val_loss: 9.5239e-05\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 4.0966e-04 - val_loss: 9.7514e-05\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.2046e-04 - val_loss: 9.5218e-05\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.0770e-04 - val_loss: 9.8520e-05\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 3.9940e-04 - val_loss: 1.0264e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.0296e-04 - val_loss: 9.5321e-05\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.1080e-04 - val_loss: 9.4346e-05\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 4.0932e-04 - val_loss: 9.6223e-05\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.1076e-04 - val_loss: 9.3023e-05\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.9775e-04 - val_loss: 9.3183e-05\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.9797e-04 - val_loss: 1.0521e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.1498e-04 - val_loss: 9.1833e-05\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.8792e-04 - val_loss: 9.1908e-05\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.0855e-04 - val_loss: 9.1771e-05\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 3.8541e-04 - val_loss: 9.2038e-05\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.2402e-04 - val_loss: 9.0371e-05\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.0729e-04 - val_loss: 9.9079e-05\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.9588e-04 - val_loss: 9.0499e-05\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.9269e-04 - val_loss: 8.9906e-05\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 4.0029e-04 - val_loss: 9.2956e-05\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.8389e-04 - val_loss: 8.9317e-05\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.8499e-04 - val_loss: 9.1233e-05\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.9491e-04 - val_loss: 9.3685e-05\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 3.8472e-04 - val_loss: 8.9387e-05\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.9778e-04 - val_loss: 8.8766e-05\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.7578e-04 - val_loss: 9.3572e-05\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 3.9360e-04 - val_loss: 8.7909e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.9208e-04 - val_loss: 9.1885e-05\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.8696e-04 - val_loss: 8.8703e-05\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 3.9685e-04 - val_loss: 1.0343e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.8047e-04 - val_loss: 1.0483e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.7805e-04 - val_loss: 8.8118e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 3.7432e-04 - val_loss: 9.0094e-05\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.7743e-04 - val_loss: 8.9419e-05\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.7190e-04 - val_loss: 8.6171e-05\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 4.8180e-04 - val_loss: 9.2097e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 3.8177e-04 - val_loss: 8.5991e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 3.7683e-04 - val_loss: 8.5677e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 3.7979e-04 - val_loss: 9.4512e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 3.7763e-04 - val_loss: 8.5298e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.6957e-04 - val_loss: 8.6143e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.7461e-04 - val_loss: 9.3513e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.7559e-04 - val_loss: 9.1738e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 3.7014e-04 - val_loss: 8.9663e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.7297e-04 - val_loss: 8.5464e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 3.6525e-04 - val_loss: 8.4597e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 3.6786e-04 - val_loss: 8.4888e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.7427e-04 - val_loss: 8.5621e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.8672e-04 - val_loss: 8.5707e-05\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 3.6932e-04 - val_loss: 8.7186e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.7074e-04 - val_loss: 8.3518e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.7967e-04 - val_loss: 8.5685e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 3.8075e-04 - val_loss: 8.3358e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.6361e-04 - val_loss: 8.4236e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.6536e-04 - val_loss: 8.2858e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 3.8371e-04 - val_loss: 8.3585e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.7622e-04 - val_loss: 9.0430e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.6819e-04 - val_loss: 9.2964e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.6707e-04 - val_loss: 9.3397e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 3.7696e-04 - val_loss: 8.2706e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.8777e-04 - val_loss: 8.2810e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.6728e-04 - val_loss: 8.2389e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.6483e-04 - val_loss: 8.3920e-05\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.5972e-04 - val_loss: 8.3013e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.7855e-04 - val_loss: 9.9471e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 3.7245e-04 - val_loss: 8.1526e-05\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.8675e-04 - val_loss: 8.3642e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 3.8263e-04 - val_loss: 8.2285e-05\n",
      "Thời gian huấn luyện:  221.78729796409607\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_32 (GRU)                (None, 30, 124)           47244     \n",
      "                                                                 \n",
      " flatten_131 (Flatten)       (None, 3720)              0         \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 1)                 3721      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,965\n",
      "Trainable params: 50,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 7ms/step\n",
      "14/14 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "rmse_bag = [] # Ex: rmse_bag[1] == [0.9, 0.8, 0.9, 0.9] --> FFNN, RNN, LSTM, GRU\n",
    "\n",
    "for look_back in [1, 3, 5, 10, 20, 30]:\n",
    "    FFNN_data, FFNN_params = prepare_best_params(information_FFNN_df,ds, look_back, opt)\n",
    "    FFNN_delta, FFNN_model = create_ffnn_model(*FFNN_params)\n",
    "    FFNN_mse, FFNN_mae, FFNN_mape, FFNN_rmse, FFNN_trainPredict, FFNN_testPredict = create_accuracy(FFNN_model, scaler, *FFNN_data)\n",
    "    \n",
    "    RNN_data, RNN_params = prepare_best_params(information_RNN_df,ds, look_back, opt)\n",
    "    RNN_delta, RNN_model = create_rnn_model(*RNN_params)\n",
    "    RNN_mse, RNN_mae, RNN_mape, RNN_rmse, RNN_trainPredict, RNN_testPredict = create_accuracy(RNN_model, scaler, *RNN_data)\n",
    "    \n",
    "    LSTM_data, LSTM_params = prepare_best_params(information_LSTM_df,ds, look_back, opt)\n",
    "    LSTM_delta, LSTM_model = create_lstm_model(*LSTM_params)\n",
    "    LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse, LSTM_trainPredict, LSTM_testPredict = create_accuracy(LSTM_model, scaler, *LSTM_data)\n",
    "    \n",
    "    GRU_data, GRU_params = prepare_best_params(information_GRU_df,ds, look_back, opt)\n",
    "    GRU_delta, GRU_model = create_gru_model(*GRU_params)\n",
    "    GRU_mse, GRU_mae, GRU_mape, GRU_rmse, GRU_trainPredict, GRU_testPredict = create_accuracy(GRU_model, scaler, *GRU_data)\n",
    "    \n",
    "    # Lưu các RMSE\n",
    "    rmse_bag.append([FFNN_rmse, RNN_rmse, LSTM_rmse, GRU_rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7209307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFNN</th>\n",
       "      <th>RNN</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.304</td>\n",
       "      <td>0.356</td>\n",
       "      <td>8.304</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.387</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.376</td>\n",
       "      <td>0.367</td>\n",
       "      <td>8.290</td>\n",
       "      <td>8.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.388</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.381</td>\n",
       "      <td>0.378</td>\n",
       "      <td>8.220</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.392</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFNN    RNN   LSTM    GRU\n",
       "1   8.304  0.356  8.304  0.358\n",
       "3   0.387  0.357  0.435  0.372\n",
       "5   0.376  0.367  8.290  8.290\n",
       "10  0.388  0.364  0.399  0.362\n",
       "20  0.381  0.378  8.220  0.354\n",
       "30  0.392  0.351  0.374  0.351"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_bag = pd.DataFrame(rmse_bag, index=[1, 3, 5, 10, 20, 30], columns=['FFNN', 'RNN', 'LSTM', 'GRU'])\n",
    "rmse_bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc3d79",
   "metadata": {},
   "source": [
    "### So the chosen look_back is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67a4d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d18bca3",
   "metadata": {},
   "source": [
    "## Chose the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ceb9782",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13103ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "53/53 [==============================] - 1s 8ms/step - loss: 0.0646 - val_loss: 0.0330\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0189\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0118\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0074\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 9.9639e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.0370e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 6.1525e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.8826e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 5.4115e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.2491e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.7665e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.4482e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.1242e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.0532e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 3.8635e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.5293e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.5370e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.3575e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.6331e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.2671e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.0822e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.1823e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 3.3344e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.7491e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.9665e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.9605e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.8707e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.6408e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.8157e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.8650e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.9806e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.7841e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.8581e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.5065e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.4269e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.5556e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 2.4408e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.1883e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.9989e-04 - val_loss: 2.4311e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.9138e-04 - val_loss: 2.4114e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.7911e-04 - val_loss: 2.2474e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.6916e-04 - val_loss: 2.2492e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.6336e-04 - val_loss: 2.2338e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.4829e-04 - val_loss: 2.0544e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 9.3808e-04 - val_loss: 2.1729e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.2789e-04 - val_loss: 2.0068e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.1272e-04 - val_loss: 2.0470e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.0344e-04 - val_loss: 2.1495e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.9361e-04 - val_loss: 1.9812e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.8720e-04 - val_loss: 1.9897e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.7295e-04 - val_loss: 1.8814e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.7018e-04 - val_loss: 1.8999e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.5146e-04 - val_loss: 1.9500e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.3903e-04 - val_loss: 1.8290e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.2937e-04 - val_loss: 1.8453e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.2482e-04 - val_loss: 1.8665e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 8.0647e-04 - val_loss: 1.8198e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 8.0012e-04 - val_loss: 1.8189e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.8632e-04 - val_loss: 1.6630e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.8360e-04 - val_loss: 1.7689e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.6537e-04 - val_loss: 1.8313e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.6672e-04 - val_loss: 1.6450e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.5129e-04 - val_loss: 1.7155e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.3569e-04 - val_loss: 1.6060e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.3385e-04 - val_loss: 1.8949e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.2730e-04 - val_loss: 1.5723e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.1316e-04 - val_loss: 1.7807e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 7.0205e-04 - val_loss: 1.6334e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.9690e-04 - val_loss: 1.5167e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.8734e-04 - val_loss: 1.7783e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.7711e-04 - val_loss: 1.8765e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.7528e-04 - val_loss: 1.5091e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.6802e-04 - val_loss: 1.6908e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.6080e-04 - val_loss: 1.7085e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.4738e-04 - val_loss: 1.4786e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.4559e-04 - val_loss: 1.6010e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.3386e-04 - val_loss: 1.5627e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.3367e-04 - val_loss: 1.4823e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.2417e-04 - val_loss: 1.4765e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.1215e-04 - val_loss: 1.4639e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.1493e-04 - val_loss: 1.4647e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.0304e-04 - val_loss: 1.4399e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9898e-04 - val_loss: 1.4710e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9171e-04 - val_loss: 1.5422e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.9068e-04 - val_loss: 1.4293e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.8746e-04 - val_loss: 1.4370e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.8191e-04 - val_loss: 1.5389e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.7315e-04 - val_loss: 1.4257e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.6700e-04 - val_loss: 1.5072e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.6482e-04 - val_loss: 1.3817e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.6499e-04 - val_loss: 1.3124e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.5277e-04 - val_loss: 1.3155e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.5303e-04 - val_loss: 1.3337e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.5623e-04 - val_loss: 1.3622e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.4446e-04 - val_loss: 1.3054e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3797e-04 - val_loss: 1.3031e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3702e-04 - val_loss: 1.3986e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3176e-04 - val_loss: 1.3144e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.3371e-04 - val_loss: 1.3888e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2626e-04 - val_loss: 1.3032e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2326e-04 - val_loss: 1.3726e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2731e-04 - val_loss: 1.2405e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2670e-04 - val_loss: 1.3016e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.2002e-04 - val_loss: 1.2950e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1251e-04 - val_loss: 1.3327e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1028e-04 - val_loss: 1.2156e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1059e-04 - val_loss: 1.3468e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.1232e-04 - val_loss: 1.3629e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0534e-04 - val_loss: 1.2989e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0934e-04 - val_loss: 1.2880e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0094e-04 - val_loss: 1.2989e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.0208e-04 - val_loss: 1.4562e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9817e-04 - val_loss: 1.2068e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9395e-04 - val_loss: 1.1895e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9226e-04 - val_loss: 1.2682e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9492e-04 - val_loss: 1.2112e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8708e-04 - val_loss: 1.3460e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.9154e-04 - val_loss: 1.2505e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8677e-04 - val_loss: 1.2055e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8850e-04 - val_loss: 1.3229e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8503e-04 - val_loss: 1.2184e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8081e-04 - val_loss: 1.2193e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8237e-04 - val_loss: 1.2222e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7971e-04 - val_loss: 1.4051e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8116e-04 - val_loss: 1.2169e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7733e-04 - val_loss: 1.1815e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7264e-04 - val_loss: 1.1772e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6980e-04 - val_loss: 1.2480e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7031e-04 - val_loss: 1.1484e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7878e-04 - val_loss: 1.1820e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.7399e-04 - val_loss: 1.1566e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6817e-04 - val_loss: 1.2901e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.8675e-04 - val_loss: 1.1351e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6785e-04 - val_loss: 1.3640e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.7063e-04 - val_loss: 1.2489e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.6766e-04 - val_loss: 1.1656e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6188e-04 - val_loss: 1.1889e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6677e-04 - val_loss: 1.2478e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6171e-04 - val_loss: 1.2022e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5815e-04 - val_loss: 1.1482e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5849e-04 - val_loss: 1.1187e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.6120e-04 - val_loss: 1.1744e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5379e-04 - val_loss: 1.1509e-04\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5192e-04 - val_loss: 1.2160e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5231e-04 - val_loss: 1.1399e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5268e-04 - val_loss: 1.1724e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4811e-04 - val_loss: 1.1233e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4771e-04 - val_loss: 1.2198e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4982e-04 - val_loss: 1.1089e-04\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5306e-04 - val_loss: 1.2405e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.5018e-04 - val_loss: 1.1039e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4289e-04 - val_loss: 1.2169e-04\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4605e-04 - val_loss: 1.0915e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4761e-04 - val_loss: 1.0871e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4387e-04 - val_loss: 1.2031e-04\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4071e-04 - val_loss: 1.1652e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4356e-04 - val_loss: 1.1672e-04\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4200e-04 - val_loss: 1.1452e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4264e-04 - val_loss: 1.1847e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3457e-04 - val_loss: 1.0815e-04\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3869e-04 - val_loss: 1.1002e-04\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3805e-04 - val_loss: 1.1178e-04\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4408e-04 - val_loss: 1.1151e-04\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3106e-04 - val_loss: 1.0685e-04\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3436e-04 - val_loss: 1.1897e-04\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3247e-04 - val_loss: 1.1458e-04\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.3479e-04 - val_loss: 1.0828e-04\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2936e-04 - val_loss: 1.0839e-04\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2809e-04 - val_loss: 1.0594e-04\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.3684e-04 - val_loss: 1.1550e-04\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2795e-04 - val_loss: 1.0719e-04\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.4796e-04 - val_loss: 1.1090e-04\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2885e-04 - val_loss: 1.1839e-04\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.3365e-04 - val_loss: 1.0544e-04\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2826e-04 - val_loss: 1.1624e-04\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2585e-04 - val_loss: 1.1232e-04\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2371e-04 - val_loss: 1.0487e-04\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2302e-04 - val_loss: 1.1169e-04\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2202e-04 - val_loss: 1.0868e-04\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2357e-04 - val_loss: 1.1144e-04\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2195e-04 - val_loss: 1.0563e-04\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.3068e-04 - val_loss: 1.0535e-04\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.1975e-04 - val_loss: 1.1363e-04\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 4.2389e-04 - val_loss: 1.1478e-04\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2483e-04 - val_loss: 1.0318e-04\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2250e-04 - val_loss: 1.0710e-04\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1640e-04 - val_loss: 1.1919e-04\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2130e-04 - val_loss: 1.1169e-04\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1506e-04 - val_loss: 1.0685e-04\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1589e-04 - val_loss: 1.0635e-04\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1382e-04 - val_loss: 1.0378e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1211e-04 - val_loss: 1.0266e-04\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2564e-04 - val_loss: 1.1035e-04\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1917e-04 - val_loss: 1.0326e-04\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1446e-04 - val_loss: 1.0181e-04\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.1106e-04 - val_loss: 1.0167e-04\n",
      "Thời gian huấn luyện:  25.06951928138733\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_174 (Dense)           (None, 10, 125)           250       \n",
      "                                                                 \n",
      " flatten_138 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,501\n",
      "Trainable params: 1,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 934us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\datnld\\AppData\\Local\\Temp\\ipykernel_26824\\4175024292.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compare_table.append([FFNN_mse, FFNN_mae, FFNN_mape, FFNN_rmse, FFNN_delta])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FFNN</th>\n",
       "      <td>68.364</td>\n",
       "      <td>7.193</td>\n",
       "      <td>33.716</td>\n",
       "      <td>8.268</td>\n",
       "      <td>23.428540</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>0.124</td>\n",
       "      <td>0.256</td>\n",
       "      <td>1.272</td>\n",
       "      <td>0.352</td>\n",
       "      <td>46.793234</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0.191</td>\n",
       "      <td>0.320</td>\n",
       "      <td>1.583</td>\n",
       "      <td>0.436</td>\n",
       "      <td>109.038889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>0.128</td>\n",
       "      <td>0.260</td>\n",
       "      <td>1.299</td>\n",
       "      <td>0.357</td>\n",
       "      <td>97.000705</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.38400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.08158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSE    MAE    MAPE   RMSE  Training Time         0\n",
       "FFNN  68.364  7.193  33.716  8.268      23.428540       NaN\n",
       "RNN    0.124  0.256   1.272  0.352      46.793234       NaN\n",
       "LSTM   0.191  0.320   1.583  0.436     109.038889       NaN\n",
       "GRU    0.128  0.260   1.299  0.357      97.000705       NaN\n",
       "0        NaN    NaN     NaN    NaN            NaN   0.14700\n",
       "1        NaN    NaN     NaN    NaN            NaN   0.27800\n",
       "2        NaN    NaN     NaN    NaN            NaN   1.38400\n",
       "3        NaN    NaN     NaN    NaN            NaN   0.38400\n",
       "4        NaN    NaN     NaN    NaN            NaN  25.08158"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FFNN_data, FFNN_params = prepare_best_params(information_FFNN_df,ds, look_back, opt)\n",
    "FFNN_delta, FFNN_model = create_ffnn_model(*FFNN_params)\n",
    "FFNN_mse, FFNN_mae, FFNN_mape, FFNN_rmse, FFNN_trainPredict, FFNN_testPredict = create_accuracy(FFNN_model, scaler, *FFNN_data)\n",
    "compare_table.append([FFNN_mse, FFNN_mae, FFNN_mape, FFNN_rmse, FFNN_delta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1f59462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "53/53 [==============================] - 2s 9ms/step - loss: 0.0045 - val_loss: 5.7039e-04\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 3.1963e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 2.5077e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 2.4407e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 2.1339e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 2.1459e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.9015e-04 - val_loss: 1.9833e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.5732e-04 - val_loss: 2.1193e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.3271e-04 - val_loss: 1.8829e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 9.1435e-04 - val_loss: 1.9301e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.7543e-04 - val_loss: 2.0014e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.9499e-04 - val_loss: 1.7632e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.5755e-04 - val_loss: 1.9019e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.2977e-04 - val_loss: 1.7631e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.0689e-04 - val_loss: 1.6830e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.9780e-04 - val_loss: 1.7713e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4772e-04 - val_loss: 1.6374e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.7607e-04 - val_loss: 1.8233e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.1328e-04 - val_loss: 1.5599e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1892e-04 - val_loss: 1.5198e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3778e-04 - val_loss: 1.4764e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2454e-04 - val_loss: 1.4457e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7968e-04 - val_loss: 1.4637e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.9807e-04 - val_loss: 1.5868e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6077e-04 - val_loss: 1.4114e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7955e-04 - val_loss: 1.4603e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4346e-04 - val_loss: 1.3707e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3542e-04 - val_loss: 1.3399e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3547e-04 - val_loss: 1.4119e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2359e-04 - val_loss: 1.3229e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1766e-04 - val_loss: 1.3056e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4347e-04 - val_loss: 1.3341e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2319e-04 - val_loss: 1.2923e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9328e-04 - val_loss: 1.2789e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5715e-04 - val_loss: 1.3695e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0812e-04 - val_loss: 1.3053e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9032e-04 - val_loss: 1.2209e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.7464e-04 - val_loss: 1.2153e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7302e-04 - val_loss: 1.2805e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0706e-04 - val_loss: 1.2023e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.5643e-04 - val_loss: 1.1907e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4650e-04 - val_loss: 1.1902e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.5554e-04 - val_loss: 1.1994e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.3766e-04 - val_loss: 1.1610e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9791e-04 - val_loss: 1.4504e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8363e-04 - val_loss: 1.1936e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.4157e-04 - val_loss: 1.1402e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4181e-04 - val_loss: 1.1596e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4039e-04 - val_loss: 1.1253e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2035e-04 - val_loss: 1.1320e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2300e-04 - val_loss: 1.1090e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1705e-04 - val_loss: 1.1461e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9135e-04 - val_loss: 1.1329e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0958e-04 - val_loss: 1.1797e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1759e-04 - val_loss: 1.1480e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9710e-04 - val_loss: 1.1072e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9267e-04 - val_loss: 1.0818e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9855e-04 - val_loss: 1.0750e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9730e-04 - val_loss: 1.0472e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0504e-04 - val_loss: 1.0487e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.3527e-04 - val_loss: 1.0287e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.1495e-04 - val_loss: 1.0733e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9691e-04 - val_loss: 1.0274e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6696e-04 - val_loss: 1.0262e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6806e-04 - val_loss: 1.0885e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0963e-04 - val_loss: 1.0143e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.9055e-04 - val_loss: 1.0021e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8296e-04 - val_loss: 1.0213e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7252e-04 - val_loss: 9.9790e-05\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.9695e-04 - val_loss: 9.9877e-05\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7365e-04 - val_loss: 9.9260e-05\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5199e-04 - val_loss: 9.9038e-05\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5577e-04 - val_loss: 9.7484e-05\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7619e-04 - val_loss: 9.7455e-05\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6746e-04 - val_loss: 1.0186e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5899e-04 - val_loss: 1.0064e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7503e-04 - val_loss: 9.8329e-05\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4311e-04 - val_loss: 9.7216e-05\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5746e-04 - val_loss: 9.7487e-05\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4368e-04 - val_loss: 9.4817e-05\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4316e-04 - val_loss: 9.4323e-05\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5130e-04 - val_loss: 1.1613e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5320e-04 - val_loss: 9.7154e-05\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4177e-04 - val_loss: 9.5578e-05\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4200e-04 - val_loss: 9.2719e-05\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5111e-04 - val_loss: 9.8198e-05\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4496e-04 - val_loss: 9.3973e-05\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4045e-04 - val_loss: 9.1884e-05\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3422e-04 - val_loss: 9.1986e-05\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3398e-04 - val_loss: 9.5506e-05\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2205e-04 - val_loss: 9.2540e-05\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2724e-04 - val_loss: 9.4676e-05\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.5143e-04 - val_loss: 9.1817e-05\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2531e-04 - val_loss: 9.2888e-05\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2184e-04 - val_loss: 9.0780e-05\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2186e-04 - val_loss: 8.9402e-05\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2279e-04 - val_loss: 9.3139e-05\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3455e-04 - val_loss: 9.0024e-05\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1708e-04 - val_loss: 8.8380e-05\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0611e-04 - val_loss: 9.0505e-05\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1767e-04 - val_loss: 9.0875e-05\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0945e-04 - val_loss: 8.6723e-05\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1226e-04 - val_loss: 8.7012e-05\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3184e-04 - val_loss: 9.5211e-05\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0112e-04 - val_loss: 9.2635e-05\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0431e-04 - val_loss: 8.6760e-05\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0069e-04 - val_loss: 9.3561e-05\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0764e-04 - val_loss: 8.9659e-05\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0425e-04 - val_loss: 8.9501e-05\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2302e-04 - val_loss: 8.5133e-05\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1419e-04 - val_loss: 9.0112e-05\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9430e-04 - val_loss: 8.6973e-05\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0672e-04 - val_loss: 8.5657e-05\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0035e-04 - val_loss: 8.4049e-05\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3861e-04 - val_loss: 8.3775e-05\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8869e-04 - val_loss: 8.7701e-05\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8828e-04 - val_loss: 8.4369e-05\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1828e-04 - val_loss: 8.6437e-05\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0767e-04 - val_loss: 8.7625e-05\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0262e-04 - val_loss: 8.4286e-05\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0119e-04 - val_loss: 8.8761e-05\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8647e-04 - val_loss: 8.1684e-05\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2310e-04 - val_loss: 8.3228e-05\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8795e-04 - val_loss: 8.3677e-05\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.8193e-04 - val_loss: 8.2079e-05\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8555e-04 - val_loss: 8.8139e-05\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.9455e-04 - val_loss: 8.4270e-05\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1254e-04 - val_loss: 8.3667e-05\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8647e-04 - val_loss: 8.6125e-05\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9578e-04 - val_loss: 8.2801e-05\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7084e-04 - val_loss: 8.3132e-05\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0181e-04 - val_loss: 8.1442e-05\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9831e-04 - val_loss: 8.7188e-05\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7771e-04 - val_loss: 8.1694e-05\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7861e-04 - val_loss: 8.0244e-05\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8563e-04 - val_loss: 8.6699e-05\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7362e-04 - val_loss: 8.1777e-05\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9702e-04 - val_loss: 8.1225e-05\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9422e-04 - val_loss: 8.4090e-05\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9553e-04 - val_loss: 7.9795e-05\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7468e-04 - val_loss: 7.9026e-05\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8988e-04 - val_loss: 7.9460e-05\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8121e-04 - val_loss: 8.2238e-05\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7883e-04 - val_loss: 8.1384e-05\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7213e-04 - val_loss: 7.8273e-05\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8158e-04 - val_loss: 7.8306e-05\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8017e-04 - val_loss: 8.1147e-05\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7789e-04 - val_loss: 7.8465e-05\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8021e-04 - val_loss: 7.8789e-05\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8301e-04 - val_loss: 7.8445e-05\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8007e-04 - val_loss: 7.8715e-05\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6895e-04 - val_loss: 7.7768e-05\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6916e-04 - val_loss: 7.9955e-05\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7673e-04 - val_loss: 8.3442e-05\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6432e-04 - val_loss: 8.0209e-05\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6963e-04 - val_loss: 8.1620e-05\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7130e-04 - val_loss: 7.7540e-05\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6997e-04 - val_loss: 8.0697e-05\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7500e-04 - val_loss: 8.4931e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8392e-04 - val_loss: 7.7287e-05\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6542e-04 - val_loss: 7.7597e-05\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8309e-04 - val_loss: 7.8637e-05\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.7000e-04 - val_loss: 7.8048e-05\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6376e-04 - val_loss: 7.7181e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6766e-04 - val_loss: 7.6714e-05\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7802e-04 - val_loss: 7.7740e-05\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7208e-04 - val_loss: 7.6911e-05\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.8306e-04 - val_loss: 7.6158e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8532e-04 - val_loss: 7.6876e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8320e-04 - val_loss: 7.7003e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8771e-04 - val_loss: 7.6919e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6577e-04 - val_loss: 8.1373e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6312e-04 - val_loss: 7.6892e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8289e-04 - val_loss: 8.4410e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7056e-04 - val_loss: 7.7966e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7079e-04 - val_loss: 7.8465e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8494e-04 - val_loss: 8.1646e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0069e-04 - val_loss: 8.5022e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9121e-04 - val_loss: 7.8864e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6715e-04 - val_loss: 7.6931e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.2580e-04 - val_loss: 7.9574e-05\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6839e-04 - val_loss: 7.7134e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6011e-04 - val_loss: 7.7114e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6283e-04 - val_loss: 7.7307e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6343e-04 - val_loss: 8.2840e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8500e-04 - val_loss: 7.7419e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6265e-04 - val_loss: 7.5970e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6938e-04 - val_loss: 7.5716e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6912e-04 - val_loss: 7.6065e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6416e-04 - val_loss: 7.7019e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7429e-04 - val_loss: 7.8383e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6740e-04 - val_loss: 7.6313e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6389e-04 - val_loss: 7.6596e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6555e-04 - val_loss: 7.5659e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.5866e-04 - val_loss: 7.8735e-05\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7592e-04 - val_loss: 7.9685e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7851e-04 - val_loss: 7.5869e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7116e-04 - val_loss: 8.8259e-05\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8125e-04 - val_loss: 7.6061e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7102e-04 - val_loss: 7.7621e-05\n",
      "Thời gian huấn luyện:  46.7831974029541\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_33 (SimpleRNN)   (None, 10, 125)           15875     \n",
      "                                                                 \n",
      " flatten_133 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,126\n",
      "Trainable params: 17,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "RNN_data, RNN_params = prepare_best_params(information_RNN_df,ds, look_back, opt)\n",
    "RNN_delta, RNN_model = create_rnn_model(*RNN_params)\n",
    "RNN_mse, RNN_mae, RNN_mape, RNN_rmse, RNN_trainPredict, RNN_testPredict = create_accuracy(RNN_model, scaler, *RNN_data)\n",
    "compare_table.append([RNN_mse, RNN_mae, RNN_mape, RNN_rmse, RNN_delta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3592e3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "53/53 [==============================] - 4s 20ms/step - loss: 0.0236 - val_loss: 0.0022\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0020 - val_loss: 6.9752e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 3.8586e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 4.2131e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 3.9736e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 4.0994e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 3.3359e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 3.7023e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 3.8908e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 3.3538e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 3.7634e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 3.2161e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 3.4941e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 3.4690e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 3.5633e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 3.2905e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0015 - val_loss: 3.4334e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 4.2549e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 3.8841e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 3.2869e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 3.0486e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0014 - val_loss: 3.3041e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 3.3897e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 3.1817e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 2.7156e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 3.5656e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 3.2535e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 2.5649e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 2.7816e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 2.8533e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 2.7581e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 2.4771e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 2.2875e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 2.7768e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 2.4324e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 2.3260e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 2.2740e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 2.2115e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 2.3670e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 2.1725e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 2.0776e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 2.1280e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 2.1542e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.7009e-04 - val_loss: 2.0581e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.7433e-04 - val_loss: 2.0302e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.6950e-04 - val_loss: 2.0398e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 2.0834e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.3717e-04 - val_loss: 2.0839e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.3670e-04 - val_loss: 2.0759e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.3107e-04 - val_loss: 2.0064e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.1983e-04 - val_loss: 2.0764e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.1772e-04 - val_loss: 2.2795e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.0301e-04 - val_loss: 1.9705e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.2747e-04 - val_loss: 2.0830e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.0663e-04 - val_loss: 2.0671e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.1237e-04 - val_loss: 1.9579e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.1567e-04 - val_loss: 1.9543e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.8493e-04 - val_loss: 1.9134e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 9.0914e-04 - val_loss: 1.9175e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 9.0659e-04 - val_loss: 2.2000e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.9855e-04 - val_loss: 2.0664e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.9081e-04 - val_loss: 1.8887e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.6736e-04 - val_loss: 2.1446e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.9259e-04 - val_loss: 1.9012e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.7754e-04 - val_loss: 1.8646e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.5135e-04 - val_loss: 1.8912e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.4201e-04 - val_loss: 1.9615e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.4696e-04 - val_loss: 1.8482e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.4254e-04 - val_loss: 1.8658e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.3455e-04 - val_loss: 1.8850e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.3815e-04 - val_loss: 1.8589e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.2513e-04 - val_loss: 1.8239e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.4754e-04 - val_loss: 1.9148e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.2094e-04 - val_loss: 1.8409e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.1933e-04 - val_loss: 1.8391e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 8.2125e-04 - val_loss: 1.7963e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.2927e-04 - val_loss: 1.8516e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.0807e-04 - val_loss: 1.7895e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.1834e-04 - val_loss: 2.0024e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.4730e-04 - val_loss: 1.7973e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.0723e-04 - val_loss: 2.0464e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.0699e-04 - val_loss: 1.9710e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 7.7983e-04 - val_loss: 1.8744e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.9616e-04 - val_loss: 1.8994e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.8001e-04 - val_loss: 1.7431e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.1177e-04 - val_loss: 1.7752e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 8.0477e-04 - val_loss: 1.9701e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.6211e-04 - val_loss: 1.7069e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.9393e-04 - val_loss: 2.0510e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 7.8195e-04 - val_loss: 2.0221e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.7235e-04 - val_loss: 1.8464e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.6762e-04 - val_loss: 1.7713e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.8530e-04 - val_loss: 1.8656e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.5298e-04 - val_loss: 1.7361e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.6812e-04 - val_loss: 1.7794e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.6317e-04 - val_loss: 2.0403e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.4612e-04 - val_loss: 1.7783e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.5062e-04 - val_loss: 1.8349e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.4065e-04 - val_loss: 1.7655e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.3880e-04 - val_loss: 1.6476e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.6233e-04 - val_loss: 1.6708e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.2582e-04 - val_loss: 1.7091e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.1774e-04 - val_loss: 1.6340e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.3044e-04 - val_loss: 2.1010e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 7.4064e-04 - val_loss: 1.6940e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.0227e-04 - val_loss: 1.7732e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.2278e-04 - val_loss: 1.6721e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.9504e-04 - val_loss: 1.7446e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 7.1086e-04 - val_loss: 1.6959e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.0106e-04 - val_loss: 1.6227e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.1731e-04 - val_loss: 1.5964e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.9785e-04 - val_loss: 1.5842e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.8653e-04 - val_loss: 1.6420e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.7764e-04 - val_loss: 1.6144e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.8340e-04 - val_loss: 1.9066e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.8261e-04 - val_loss: 1.5374e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.9850e-04 - val_loss: 1.7782e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 6.7652e-04 - val_loss: 1.7539e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.7498e-04 - val_loss: 1.7008e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.7840e-04 - val_loss: 1.8522e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 6.6143e-04 - val_loss: 1.6350e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 6.5776e-04 - val_loss: 1.5730e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.8317e-04 - val_loss: 1.5083e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 6.5033e-04 - val_loss: 1.5281e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.4462e-04 - val_loss: 1.6845e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.6008e-04 - val_loss: 1.6336e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.4016e-04 - val_loss: 1.5627e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.5089e-04 - val_loss: 1.4789e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.3779e-04 - val_loss: 1.4924e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.2650e-04 - val_loss: 1.6747e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.5413e-04 - val_loss: 1.5689e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.2768e-04 - val_loss: 1.5770e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.2733e-04 - val_loss: 1.5090e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.1896e-04 - val_loss: 1.6212e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.2486e-04 - val_loss: 1.4986e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 6.2217e-04 - val_loss: 1.4704e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.6263e-04 - val_loss: 1.8011e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.3628e-04 - val_loss: 1.4317e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.1583e-04 - val_loss: 1.6128e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.1927e-04 - val_loss: 1.6162e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.1735e-04 - val_loss: 1.4579e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.1676e-04 - val_loss: 1.4578e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.9935e-04 - val_loss: 1.4782e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.0774e-04 - val_loss: 1.5867e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.9690e-04 - val_loss: 1.4266e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.0523e-04 - val_loss: 1.5385e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 5.8872e-04 - val_loss: 1.5774e-04\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 5.9632e-04 - val_loss: 1.4823e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.0377e-04 - val_loss: 1.3742e-04\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.8916e-04 - val_loss: 1.4907e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.7854e-04 - val_loss: 1.6234e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 5.7808e-04 - val_loss: 1.4904e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.7479e-04 - val_loss: 1.3843e-04\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 5.8120e-04 - val_loss: 1.4039e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.7449e-04 - val_loss: 1.6511e-04\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 5.7614e-04 - val_loss: 1.3921e-04\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.6760e-04 - val_loss: 1.3895e-04\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 5.8357e-04 - val_loss: 1.4381e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.6398e-04 - val_loss: 1.5763e-04\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 5.6117e-04 - val_loss: 1.3964e-04\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.8371e-04 - val_loss: 1.7046e-04\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 5.6443e-04 - val_loss: 1.3293e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.6236e-04 - val_loss: 1.8015e-04\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 5.6446e-04 - val_loss: 1.3188e-04\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.9029e-04 - val_loss: 1.5145e-04\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 5.5265e-04 - val_loss: 1.4889e-04\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.4541e-04 - val_loss: 1.5017e-04\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 5.4946e-04 - val_loss: 1.5089e-04\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 5.7496e-04 - val_loss: 1.3104e-04\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.4408e-04 - val_loss: 1.5228e-04\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.5718e-04 - val_loss: 1.4006e-04\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.3682e-04 - val_loss: 1.2643e-04\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.5248e-04 - val_loss: 1.3829e-04\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.4138e-04 - val_loss: 1.3426e-04\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.5283e-04 - val_loss: 1.3276e-04\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.3250e-04 - val_loss: 1.4721e-04\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.2829e-04 - val_loss: 1.2469e-04\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.7705e-04 - val_loss: 1.2482e-04\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.2624e-04 - val_loss: 1.4146e-04\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.1720e-04 - val_loss: 1.2805e-04\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.3382e-04 - val_loss: 1.5050e-04\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.2450e-04 - val_loss: 1.3966e-04\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.1484e-04 - val_loss: 1.2770e-04\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.1805e-04 - val_loss: 1.5248e-04\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.3205e-04 - val_loss: 1.4502e-04\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.2204e-04 - val_loss: 1.2066e-04\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.2421e-04 - val_loss: 1.3046e-04\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2194e-04 - val_loss: 1.3468e-04\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.4452e-04 - val_loss: 1.2158e-04\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 5.2551e-04 - val_loss: 1.3091e-04\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.9385e-04 - val_loss: 1.3348e-04\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.9717e-04 - val_loss: 1.3944e-04\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.9472e-04 - val_loss: 1.4499e-04\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.9232e-04 - val_loss: 1.2654e-04\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.9251e-04 - val_loss: 1.2141e-04\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.8500e-04 - val_loss: 1.2915e-04\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.9307e-04 - val_loss: 1.3334e-04\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.8249e-04 - val_loss: 1.2372e-04\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.9758e-04 - val_loss: 1.4239e-04\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.8304e-04 - val_loss: 1.1647e-04\n",
      "Thời gian huấn luyện:  109.02882933616638\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_33 (LSTM)              (None, 10, 125)           63500     \n",
      "                                                                 \n",
      " flatten_134 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,751\n",
      "Trainable params: 64,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "LSTM_data, LSTM_params = prepare_best_params(information_LSTM_df,ds, look_back, opt)\n",
    "LSTM_delta, LSTM_model = create_lstm_model(*LSTM_params)\n",
    "LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse, LSTM_trainPredict, LSTM_testPredict = create_accuracy(LSTM_model, scaler, *LSTM_data)\n",
    "compare_table.append([LSTM_mse, LSTM_mae, LSTM_mape, LSTM_rmse, LSTM_delta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b9668db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "53/53 [==============================] - 4s 18ms/step - loss: 0.0535 - val_loss: 0.0034\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 6.6056e-04\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 2.9085e-04\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 2.8217e-04\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 2.7075e-04\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 3.2035e-04\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 2.6088e-04\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 2.8492e-04\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 2.8997e-04\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 2.6894e-04\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 2.5837e-04\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 2.4425e-04\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 2.4019e-04\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 2.7116e-04\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.4874e-04\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.3266e-04\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 2.2892e-04\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.1918e-04\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.3178e-04\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 2.2232e-04\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 2.2346e-04\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.1703e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.1336e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 2.2337e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 1.9816e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 1.9502e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 2.0527e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.8266e-04 - val_loss: 2.0098e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.5753e-04 - val_loss: 1.8876e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 9.4552e-04 - val_loss: 1.8791e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.2229e-04 - val_loss: 1.8653e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 9.1094e-04 - val_loss: 1.8807e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.7528e-04 - val_loss: 1.8260e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.5052e-04 - val_loss: 1.8185e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.3900e-04 - val_loss: 1.7929e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.3007e-04 - val_loss: 1.8516e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.1261e-04 - val_loss: 1.7909e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.9578e-04 - val_loss: 1.7973e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 8.1282e-04 - val_loss: 1.7550e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.8200e-04 - val_loss: 1.7726e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.6452e-04 - val_loss: 1.7696e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.6430e-04 - val_loss: 1.7365e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.5427e-04 - val_loss: 1.7766e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.7175e-04 - val_loss: 1.7282e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.5600e-04 - val_loss: 1.7238e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.3057e-04 - val_loss: 1.7091e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.3252e-04 - val_loss: 1.7465e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.1603e-04 - val_loss: 1.7296e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.2158e-04 - val_loss: 1.7012e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.1187e-04 - val_loss: 1.7997e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 7.0589e-04 - val_loss: 1.6482e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 7.0329e-04 - val_loss: 1.8116e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.9716e-04 - val_loss: 1.6493e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.9059e-04 - val_loss: 1.7372e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.7620e-04 - val_loss: 1.6162e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.9469e-04 - val_loss: 1.6379e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.8622e-04 - val_loss: 1.6128e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.6030e-04 - val_loss: 1.6206e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.6059e-04 - val_loss: 1.5885e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.5477e-04 - val_loss: 1.5874e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.5556e-04 - val_loss: 1.5345e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.4904e-04 - val_loss: 1.5909e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.4715e-04 - val_loss: 1.5657e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.5364e-04 - val_loss: 1.6411e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.3389e-04 - val_loss: 1.6367e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.5555e-04 - val_loss: 1.5171e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.2342e-04 - val_loss: 1.5980e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 6.1651e-04 - val_loss: 1.4805e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.2601e-04 - val_loss: 1.4622e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.2395e-04 - val_loss: 1.4676e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.1288e-04 - val_loss: 1.4597e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.0742e-04 - val_loss: 1.5151e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.0007e-04 - val_loss: 1.4438e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.0274e-04 - val_loss: 1.6275e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.0591e-04 - val_loss: 1.4230e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.0448e-04 - val_loss: 1.4128e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.8567e-04 - val_loss: 1.4069e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.9631e-04 - val_loss: 1.3744e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.9365e-04 - val_loss: 1.4828e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.7648e-04 - val_loss: 1.3991e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.8877e-04 - val_loss: 1.5386e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.7013e-04 - val_loss: 1.3511e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.7364e-04 - val_loss: 1.3845e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.8198e-04 - val_loss: 1.3533e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.7576e-04 - val_loss: 1.3881e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.7031e-04 - val_loss: 1.3971e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.7461e-04 - val_loss: 1.3059e-04\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.5355e-04 - val_loss: 1.3137e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.4291e-04 - val_loss: 1.3668e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.4102e-04 - val_loss: 1.2924e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.3841e-04 - val_loss: 1.3176e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3212e-04 - val_loss: 1.2825e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3282e-04 - val_loss: 1.2971e-04\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3732e-04 - val_loss: 1.2951e-04\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2958e-04 - val_loss: 1.3264e-04\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3106e-04 - val_loss: 1.2545e-04\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.2729e-04 - val_loss: 1.3218e-04\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.2275e-04 - val_loss: 1.3278e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.1361e-04 - val_loss: 1.2293e-04\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1263e-04 - val_loss: 1.2174e-04\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1854e-04 - val_loss: 1.3248e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1643e-04 - val_loss: 1.2724e-04\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.3399e-04 - val_loss: 1.2681e-04\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1128e-04 - val_loss: 1.2128e-04\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.3230e-04 - val_loss: 1.2169e-04\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.0161e-04 - val_loss: 1.2247e-04\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 5.1667e-04 - val_loss: 1.2350e-04\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.0541e-04 - val_loss: 1.1755e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8950e-04 - val_loss: 1.2517e-04\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.9870e-04 - val_loss: 1.1830e-04\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 5.1098e-04 - val_loss: 1.1888e-04\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.9588e-04 - val_loss: 1.1917e-04\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8556e-04 - val_loss: 1.1481e-04\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.9049e-04 - val_loss: 1.1660e-04\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7832e-04 - val_loss: 1.1661e-04\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7636e-04 - val_loss: 1.1512e-04\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 4.8234e-04 - val_loss: 1.1846e-04\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7380e-04 - val_loss: 1.1404e-04\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8104e-04 - val_loss: 1.1570e-04\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 5.0131e-04 - val_loss: 1.1152e-04\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.6513e-04 - val_loss: 1.1438e-04\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.6032e-04 - val_loss: 1.1027e-04\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.6360e-04 - val_loss: 1.4770e-04\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.7382e-04 - val_loss: 1.0886e-04\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5668e-04 - val_loss: 1.0966e-04\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.4991e-04 - val_loss: 1.1296e-04\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5232e-04 - val_loss: 1.1066e-04\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5303e-04 - val_loss: 1.0941e-04\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 4.4345e-04 - val_loss: 1.1829e-04\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.8568e-04 - val_loss: 1.0634e-04\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.4777e-04 - val_loss: 1.1450e-04\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5712e-04 - val_loss: 1.0638e-04\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.5817e-04 - val_loss: 1.1109e-04\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3633e-04 - val_loss: 1.0489e-04\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3650e-04 - val_loss: 1.0437e-04\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 4.3589e-04 - val_loss: 1.0403e-04\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.4657e-04 - val_loss: 1.1521e-04\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.4927e-04 - val_loss: 1.0361e-04\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3156e-04 - val_loss: 1.0232e-04\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3969e-04 - val_loss: 1.1939e-04\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.4281e-04 - val_loss: 1.1045e-04\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.4286e-04 - val_loss: 1.0204e-04\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3171e-04 - val_loss: 1.1014e-04\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.3778e-04 - val_loss: 1.0506e-04\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2542e-04 - val_loss: 1.0346e-04\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2631e-04 - val_loss: 1.0294e-04\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1789e-04 - val_loss: 9.8808e-05\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.2261e-04 - val_loss: 1.0384e-04\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2446e-04 - val_loss: 9.8464e-05\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2255e-04 - val_loss: 1.0943e-04\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2047e-04 - val_loss: 1.0549e-04\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1902e-04 - val_loss: 1.0435e-04\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0872e-04 - val_loss: 9.6812e-05\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1203e-04 - val_loss: 1.0066e-04\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1919e-04 - val_loss: 9.7953e-05\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2432e-04 - val_loss: 9.5558e-05\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1139e-04 - val_loss: 9.5145e-05\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1424e-04 - val_loss: 1.0228e-04\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1693e-04 - val_loss: 9.4932e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0335e-04 - val_loss: 9.8788e-05\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9397e-04 - val_loss: 1.0201e-04\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.1613e-04 - val_loss: 1.0050e-04\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 4.0945e-04 - val_loss: 9.2943e-05\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1167e-04 - val_loss: 9.8287e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9408e-04 - val_loss: 9.3312e-05\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0248e-04 - val_loss: 9.7383e-05\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0595e-04 - val_loss: 1.0847e-04\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.1111e-04 - val_loss: 9.7680e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.9802e-04 - val_loss: 9.2471e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9561e-04 - val_loss: 9.0583e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.2664e-04 - val_loss: 9.1135e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8948e-04 - val_loss: 9.0509e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9043e-04 - val_loss: 9.0537e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9628e-04 - val_loss: 9.0783e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 4.0177e-04 - val_loss: 8.9946e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8919e-04 - val_loss: 9.1235e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8187e-04 - val_loss: 9.0650e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9411e-04 - val_loss: 9.1110e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7679e-04 - val_loss: 8.9053e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.7908e-04 - val_loss: 8.9022e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8582e-04 - val_loss: 8.8143e-05\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7912e-04 - val_loss: 9.0708e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8137e-04 - val_loss: 9.0060e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8858e-04 - val_loss: 9.5394e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.9378e-04 - val_loss: 8.7705e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8566e-04 - val_loss: 8.8656e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8027e-04 - val_loss: 9.1604e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8526e-04 - val_loss: 8.6506e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7759e-04 - val_loss: 8.6368e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 3.8085e-04 - val_loss: 8.8007e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7411e-04 - val_loss: 9.1618e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7104e-04 - val_loss: 8.6007e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7067e-04 - val_loss: 8.5768e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7326e-04 - val_loss: 8.7309e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7967e-04 - val_loss: 8.5643e-05\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7036e-04 - val_loss: 8.9171e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.8088e-04 - val_loss: 9.3155e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7569e-04 - val_loss: 8.6440e-05\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7146e-04 - val_loss: 9.1945e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 3.7274e-04 - val_loss: 8.6892e-05\n",
      "Thời gian huấn luyện:  96.98914647102356\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_33 (GRU)                (None, 10, 125)           48000     \n",
      "                                                                 \n",
      " flatten_135 (Flatten)       (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 1)                 1251      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,251\n",
      "Trainable params: 49,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "GRU_data, GRU_params = prepare_best_params(information_GRU_df,ds, look_back, opt)\n",
    "GRU_delta, GRU_model = create_gru_model(*GRU_params)\n",
    "GRU_mse, GRU_mae, GRU_mape, GRU_rmse, GRU_trainPredict, GRU_testPredict = create_accuracy(GRU_model, scaler, *GRU_data)\n",
    "compare_table.append([GRU_mse, GRU_mae, GRU_mape, GRU_rmse, GRU_delta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "911fde1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FFNN</th>\n",
       "      <td>0.147</td>\n",
       "      <td>0.278</td>\n",
       "      <td>1.384</td>\n",
       "      <td>0.384</td>\n",
       "      <td>25.081580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>0.124</td>\n",
       "      <td>0.256</td>\n",
       "      <td>1.272</td>\n",
       "      <td>0.352</td>\n",
       "      <td>46.793234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0.191</td>\n",
       "      <td>0.320</td>\n",
       "      <td>1.583</td>\n",
       "      <td>0.436</td>\n",
       "      <td>109.038889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>0.128</td>\n",
       "      <td>0.260</td>\n",
       "      <td>1.299</td>\n",
       "      <td>0.357</td>\n",
       "      <td>97.000705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSE    MAE   MAPE   RMSE  Training Time\n",
       "FFNN  0.147  0.278  1.384  0.384      25.081580\n",
       "RNN   0.124  0.256  1.272  0.352      46.793234\n",
       "LSTM  0.191  0.320  1.583  0.436     109.038889\n",
       "GRU   0.128  0.260  1.299  0.357      97.000705"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_table = pd.DataFrame(compare_table, index=[\"FFNN\", \"RNN\", \"LSTM\", \"GRU\"], columns=[\"MSE\", \"MAE\", \"MAPE\", \"RMSE\", \"Training Time\"])\n",
    "compare_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439069e2",
   "metadata": {},
   "source": [
    "## So the best model in this case is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da7f1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RNN_model\n",
    "trainPredict = RNN_trainPredict\n",
    "testPredict = RNN_testPredict\n",
    "model_name = \"RNN\"\n",
    "mse, mae, mape, rmse = RNN_mse, RNN_mae, RNN_mape, RNN_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e64dbe3",
   "metadata": {},
   "source": [
    "## Trực quan hóa kết quả dự đoán của best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51247994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1430x770 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>0.124</td>\n",
       "      <td>0.256</td>\n",
       "      <td>1.272</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MSE    MAE   MAPE   RMSE\n",
       "RNN  0.124  0.256  1.272  0.352"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_plot(ds, trainPredict, testPredict, scaler, look_back, model_name, stock_name)\n",
    "pd.DataFrame([[mse, mae, mape, rmse]], index=[model_name], columns=[\"MSE\", \"MAE\", \"MAPE\", \"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1945ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
